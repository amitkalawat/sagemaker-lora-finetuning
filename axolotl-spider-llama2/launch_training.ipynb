{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This example notebook uses Axolotl to fine-tune large foundation models\n",
    "\n",
    "[Axolotl](https://github.com/OpenAccess-AI-Collective/axolotl) is a tool designed to streamline the fine-tuning of various AI models, offering support for multiple configurations and architectures.\n",
    "\n",
    "Features:\n",
    "\n",
    "- Train various Huggingface models such as llama, pythia, falcon, mpt\n",
    "- Supports fullfinetune, lora, qlora, relora, and gptq\n",
    "- Customize configurations using a simple yaml file or CLI overwrite\n",
    "- Load different dataset formats, use custom formats, or bring your own tokenized datasets\n",
    "- Integrated with xformer, flash attention, rope scaling, and multipacking\n",
    "- Works with single GPU or multiple GPUs via FSDP or Deepspeed\n",
    "- Easily run with Docker locally or on the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (1.11.1)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scipy) (1.24.4)\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq sagemaker\n",
    "%pip install -Uq datasets\n",
    "!pip install -Uq transformers==4.33.1 \n",
    "!pip install -Uq bitsandbytes peft accelerate\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import json\n",
    "from sagemaker import Model, image_uris, serializers, deserializers\n",
    "from sagemaker.local import LocalSession\n",
    "import time\n",
    "from pathlib import Path\n",
    "from utils import download_model\n",
    "\n",
    "boto3_session=boto3.session.Session()\n",
    "# boto3_session=boto3.session.Session()\n",
    "\n",
    "smr = boto3_session.client(\"sagemaker-runtime\") # sagemaker runtime client for invoking the endpoint\n",
    "sm = boto3_session.client(\"sagemaker\") \n",
    "s3_rsr = boto3_session.resource(\"s3\")\n",
    "role = sagemaker.get_execution_role()  \n",
    "\n",
    "sess = sagemaker.session.Session(boto3_session, sagemaker_client=sm, sagemaker_runtime_client=smr)  # sagemaker session for interacting with different AWS APIs\n",
    "bucket = sess.default_bucket()  # sagemaker session for interacting with different AWS APIs\n",
    "region = sess._region_name  # region name of the current SageMaker Studio environment\n",
    "s3_prefix = \"llama2-7b-spider\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3ecce4044064e878227455ea2763eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d26bf92d3ab7450286890eeaeb6a17e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00002-of-00002.bin:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abbf7281d0942d3aafb193f2489331c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)9903c2ebf7d09970a973ef44d1402239/LICENSE:   0%|          | 0.00/7.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa53547d927342e08a27db03b8aa6c0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)ebf7d09970a973ef44d1402239/USE_POLICY.md:   0%|          | 0.00/4.77k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19d4765077994c30baf33821797a91df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)bf7d09970a973ef44d1402239/.gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fb53e7247fa435096fe633366ec86ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)0a973ef44d1402239/generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b755ad0f7b545b49df59d78701baa81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)39903c2ebf7d09970a973ef44d1402239/Notice:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e98fd453f084752b19805c833e67092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)c2ebf7d09970a973ef44d1402239/config.json:   0%|          | 0.00/554 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cd05e0cd3784572b673ed2838fa136c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)a973ef44d1402239/special_tokens_map.json:   0%|          | 0.00/411 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9dbabc9ddeb415a9e38b72a42977520",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)f44d1402239/pytorch_model.bin.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69f07ca478e42a9963396e1d4dcd36f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)bf7d09970a973ef44d1402239/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54714de42634175ba4443d915643b97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)70a973ef44d1402239/tokenizer_config.json:   0%|          | 0.00/727 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2464c8ef9c0141a8a8ade5241b4f646c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model-00001-of-00002.bin:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35bc65ae62b347219c2c21a8d87dcde8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# uncomment to download model\n",
    "local_model_path = download_model(\"TheBloke/Llama-2-7B-fp16\", \"Llama-2-7B-fp16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if list(s3_rsr.Bucket(bucket).objects.filter(Prefix=s3_prefix)) :\n",
    "    print(\"Model already exists on the S3 bucket\")\n",
    "    print(f\"If you want to upload a new model, please delete the existing model from the S3 bucket with the following command: \\n !aws s3 rm --recursive s3://{bucket}/{s3_prefix}\")\n",
    "    s3_model_location = f\"s3://{bucket}/{s3_prefix}\"\n",
    "else:\n",
    "    s3_model_location = sess.upload_data(path=local_model_path.as_posix(), bucket=bucket, key_prefix=s3_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data and upload to S3\n",
    "[Spider dataset with schema](https://huggingface.co/datasets/b-mc2/sql-create-context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33ffb03313af4021b6ce5ff55b04632b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/3.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfa4c24048ed42a5b1fd5a830b38bd8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3e75deb791a433caf70cab6405bd4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac94ee895ebb4e1fae25df30bc1d7504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52186948ac394fcc88d571ac7f6aee79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['question', 'context', 'answer'],\n",
      "        num_rows: 78577\n",
      "    })\n",
      "})\n",
      "Uploaded training data file to s3://sagemaker-us-west-2-376678947624/llama2-7b-spider/data/spider_create_context_train.json\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# download the training data mhenrichsen/alpaca_2k_test using the HuggingFace datasets library and save output as json\n",
    "dataset = datasets.load_dataset(\"b-mc2/sql-create-context\")\n",
    "print(dataset)\n",
    "\n",
    "data_path = Path(\"data\")\n",
    "data_path.mkdir(exist_ok=True)\n",
    "\n",
    "dataset[\"train\"].to_pandas().to_json(\"data/spider_create_context_train.json\", orient=\"records\", lines=True)\n",
    "s3_data = sess.upload_data(path=\"data/spider_create_context_train.json\", bucket=bucket, key_prefix=f\"{s3_prefix}/data\")\n",
    "\n",
    "print(f\"Uploaded training data file to {s3_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-28 13:16:56   19871585 spider_create_context_train.json\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.debugger import TensorBoardOutputConfig\n",
    "import time\n",
    "\n",
    "str_time = time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.localtime())\n",
    "\n",
    "tb_output_config = TensorBoardOutputConfig(s3_output_path=f\"s3://{bucket}/{s3_prefix}/tensorboard/{str_time}\",\n",
    "    container_local_output_path=\"/opt/ml/output/tensorboard\")\n",
    "\n",
    "hyperparameters = {\n",
    "    \"config\": \"llama2-7b-qlora.yml\",\n",
    "    \"deepspeed\": \"axolotl/deepspeed/zero2.json\"\n",
    "}\n",
    "\n",
    "# local_sess = LocalSession()\n",
    "# local_sess.config = {'local': {'local_code': True}}\n",
    "\n",
    "\n",
    "estimator = PyTorch(\n",
    "    source_dir = \"src\",\n",
    "    entry_point=\"axolotl/src/axolotl/cli/train.py\",\n",
    "    sagemaker_session=sess,\n",
    "    role=role,\n",
    "    instance_count=1, \n",
    "    hyperparameters=hyperparameters,\n",
    "    instance_type=\"ml.g5.2xlarge\", \n",
    "    framework_version=\"2.0.1\",\n",
    "    py_version=\"py310\",\n",
    "    disable_profiler=True,\n",
    "    max_run=60*60*24*2,\n",
    "    keep_alive_period_in_seconds=3600,\n",
    "    tensorboard_output_config=tb_output_config,\n",
    "    environment = {\"HUGGINGFACE_HUB_CACHE\": \"/tmp\", \n",
    "                    \"LIBRARY_PATH\": \"/opt/conda/lib/\",\n",
    "                    \"TRANSFORMERS_CACHE\": \"/tmp\",\n",
    "                    \"NCCL_P2P_LEVEL\": \"NVL\"},\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}} \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using provided s3_resource\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-10-28-16-34-30-833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-28 16:34:31 Starting - Starting the training job...\n",
      "2023-10-28 16:34:47 Starting - Preparing the instances for training......\n",
      "2023-10-28 16:35:54 Downloading - Downloading input data...........................................................\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-10-28 16:45:39,563 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-10-28 16:45:39,576 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-28 16:45:39,585 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-10-28 16:45:39,588 sagemaker_pytorch_container.training INFO     Invoking TorchDistributed...\u001b[0m\n",
      "\u001b[34m2023-10-28 16:45:39,588 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-10-28 16:45:41,243 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.10 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mProcessing ./deepspeed-0.11.1-py3-none-any.whl (from -r requirements.txt (line 5))\u001b[0m\n",
      "\u001b[34mObtaining file:///opt/ml/code/axolotl (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting tensorboard (from -r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for tensorboard from https://files.pythonhosted.org/packages/69/38/fb2ac9c4c8efbe020ae88f6772be87d51ef18526ac541fc3393786b7c45a/tensorboard-2.15.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.15.0-py3-none-any.whl.metadata (1.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting flash-attn==2.2.1 (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading flash_attn-2.2.1.tar.gz (2.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 37.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 3)) (0.22.0)\u001b[0m\n",
      "\u001b[34mCollecting pydantic<2.0 (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for pydantic<2.0 from https://files.pythonhosted.org/packages/e0/2f/d6f17f8385d718233bcae893d27525443d41201c938b68a4af3d591a33e4/pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (149 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 149.6/149.6 kB 37.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.2.1->-r requirements.txt (line 2)) (2.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.2.1->-r requirements.txt (line 2)) (0.6.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.2.1->-r requirements.txt (line 2)) (23.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from flash-attn==2.2.1->-r requirements.txt (line 2)) (1.11.1)\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4 (from tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for absl-py>=0.4 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.48.2 (from tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for grpcio>=1.48.2 from https://files.pythonhosted.org/packages/20/7f/e76618521aa9d33c6c1c9c3473f866da521678aa6ea2f4df3a896757748c/grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3 (from tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/39/7c/2e4fa55a99f83ef9ef229ac5d59c44ceb90e2d0145711590c0fa39669f32/google_auth-2.23.3-py2.py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.23.3-py2.py3-none-any.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<2,>=0.5 (from tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for google-auth-oauthlib<2,>=0.5 from https://files.pythonhosted.org/packages/ce/33/a907b4b67245647746dde8d61e1643ef5d210c88e090d491efd89eff9f95/google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl.metadata (2.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8 (from tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/bb/c1/50caaec6cadc1c6adc8fe351e03bd646d6e4dd17f55fca0f4c8d7ea8d3e9/Markdown-3.5-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.5-py3-none-any.whl.metadata (7.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 1)) (1.24.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf<4.24,>=3.19.6 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 1)) (3.20.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 1)) (2.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 1)) (65.6.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>1.9 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/73/c6/825dab04195756cf8ff2e12698f22513b3db2f64925bdd41671bfb33aaa5/tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard->-r requirements.txt (line 1)) (2.3.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->-r requirements.txt (line 3)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->-r requirements.txt (line 3)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.2.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<2.0->-r requirements.txt (line 4)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.11.1->-r requirements.txt (line 5)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.11.1->-r requirements.txt (line 5)) (9.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.11.1->-r requirements.txt (line 5)) (4.65.0)\u001b[0m\n",
      "\u001b[34mCollecting auto-gptq (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for auto-gptq from https://files.pythonhosted.org/packages/d9/e2/51a1e760837d22b01b9393d36f34a4273eb3a20287e32021376a45cce205/auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting peft (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for peft from https://files.pythonhosted.org/packages/37/1a/8d20e8704da9fa070eb909265584b960da57be1d833d550c59f50906dc5c/peft-0.5.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl.metadata (22 kB)\u001b[0m\n",
      "\u001b[34mCollecting transformers (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for transformers from https://files.pythonhosted.org/packages/c1/bd/f64d67df4d3b05a460f281defe830ffab6d7940b7ca98ec085e94e024781/transformers-4.34.1-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.34.1-py3-none-any.whl.metadata (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.5/121.5 kB 27.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting bitsandbytes>=0.41.1 (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for bitsandbytes>=0.41.1 from https://files.pythonhosted.org/packages/1e/2c/af22cd797fc368a9f098ed03015730e6568b884fe67f9940793d944a4b7b/bitsandbytes-0.41.1-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.41.1-py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting addict (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting fire (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading fire-0.5.0.tar.gz (88 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 88.3/88.3 kB 26.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting datasets (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for datasets from https://files.pythonhosted.org/packages/7c/55/b3432f43d6d7fee999bb23a547820d74c48ec540f5f7842e41aa5d8d5f3a/datasets-2.14.6-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.14.6-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 93.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting wandb (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for wandb from https://files.pythonhosted.org/packages/1c/5e/0362fa88679852c7fd3ac85ee5bd949426c4a51a61379010d4089be6d7ac/wandb-0.15.12-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.15.12-py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting xformers (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for xformers from https://files.pythonhosted.org/packages/bb/9c/bb1a40d5e8db2b34dd6e6c0f851e86b38a3d0840fff1bf14240eff7d3da6/xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading xformers-0.0.22.post7-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting optimum (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading optimum-1.13.2.tar.gz (300 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 301.0/301.0 kB 49.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: started\u001b[0m\n",
      "\u001b[34mInstalling build dependencies: finished with status 'done'\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: started\u001b[0m\n",
      "\u001b[34mGetting requirements to build wheel: finished with status 'done'\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (pyproject.toml): finished with status 'done'\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2023-10-28 16:45:37 Training - Training image download completed. Training in progress.\u001b[34mCollecting hf_transfer (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading hf_transfer-0.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.9/3.9 MB 114.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from axolotl==0.3.0->-r requirements.txt (line 6)) (0.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from axolotl==0.3.0->-r requirements.txt (line 6)) (0.57.1)\u001b[0m\n",
      "\u001b[34mCollecting bert-score==0.3.13 (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.1/61.1 kB 16.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting evaluate==0.4.0 (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.0-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.4/81.4 kB 20.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting rouge-score==0.1.2 (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading rouge_score-0.1.2.tar.gz (17 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from axolotl==0.3.0->-r requirements.txt (line 6)) (1.11.2)\u001b[0m\n",
      "\u001b[34mCollecting scikit-learn==1.2.2 (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.6/9.6 MB 117.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pynvml (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading pynvml-11.5.0-py3-none-any.whl (53 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.1/53.1 kB 16.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting art (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for art from https://files.pythonhosted.org/packages/fc/53/d8792ac2ebb494db0e0ba3ad3f0a9ee71144a5ced266441166f7d038a37e/art-6.1-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading art-6.1-py3-none-any.whl.metadata (69 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 69.9/69.9 kB 20.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting fschat==0.2.29 (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for fschat==0.2.29 from https://files.pythonhosted.org/packages/af/99/c2be3ae9473a555923af840236cb8aeb6ecc96680b569f47bc9aa9e3bb6a/fschat-0.2.29-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading fschat-0.2.29-py3-none-any.whl.metadata (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (3.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.0->axolotl==0.3.0->-r requirements.txt (line 6)) (0.3.7)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from evaluate==0.4.0->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for xxhash from https://files.pythonhosted.org/packages/80/8a/1dd41557883b6196f8f092011a5c1f72d4d44cf36d7b67d4a5efe3127949/xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.0->axolotl==0.3.0->-r requirements.txt (line 6)) (0.70.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from evaluate==0.4.0->axolotl==0.3.0->-r requirements.txt (line 6)) (2023.9.2)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub>=0.7.0 (from evaluate==0.4.0->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for huggingface-hub>=0.7.0 from https://files.pythonhosted.org/packages/ef/b5/b6107bd65fa4c96fdf00e4733e2fe5729bb9e5e09997f63074bb43d3ab28/huggingface_hub-0.18.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.18.0-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19 (from evaluate==0.4.0->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/41/8e/4c48881316bbced3d13089c4d0df4be321ce79a0c695d82dee9996aaf56b/aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting fastapi (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for fastapi from https://files.pythonhosted.org/packages/db/30/b8d323119c37e15b7fa639e65e0eb7d81eb675ba166ac83e695aad3bd321/fastapi-0.104.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading fastapi-0.104.0-py3-none-any.whl.metadata (24 kB)\u001b[0m\n",
      "\u001b[34mCollecting httpx (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for httpx from https://files.pythonhosted.org/packages/33/0d/d9ce469af019741c8999711d36b270ff992ceb1a0293f73f9f34fdf131e9/httpx-0.25.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading httpx-0.25.0-py3-none-any.whl.metadata (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting markdown2[all] (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for markdown2[all] from https://files.pythonhosted.org/packages/f1/98/61276a753f078dd2f3171c9a69fd3f451d220e806b2b1cdca41b8e368b0f/markdown2-2.4.10-py2.py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading markdown2-2.4.10-py2.py3-none-any.whl.metadata (2.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting nh3 (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for nh3 from https://files.pythonhosted.org/packages/b7/cd/7f64121ec731255265867e0d7d782962f2bd1f15fce83f523c8f6b69463b/nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.6 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: prompt-toolkit>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (3.0.39)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rich>=10.0.0 in /opt/conda/lib/python3.10/site-packages (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (13.5.3)\u001b[0m\n",
      "\u001b[34mCollecting shortuuid (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting tiktoken (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for tiktoken from https://files.pythonhosted.org/packages/f4/2e/0adf6e264b996e263b1c57cad6560ffd5492a69beb9fd779ed0463d486bc/tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting uvicorn (from fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for uvicorn from https://files.pythonhosted.org/packages/79/96/b0882a1c3f7ef3dd86879e041212ae5b62b4bd352320889231cc735a8e8f/uvicorn-0.23.2-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading uvicorn-0.23.2-py3-none-any.whl.metadata (6.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from rouge-score==0.1.2->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 108.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->axolotl==0.3.0->-r requirements.txt (line 6)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn==1.2.2->axolotl==0.3.0->-r requirements.txt (line 6)) (3.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.2.1->-r requirements.txt (line 2)) (3.12.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.2.1->-r requirements.txt (line 2)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.2.1->-r requirements.txt (line 2)) (3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->flash-attn==2.2.1->-r requirements.txt (line 2)) (3.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets->axolotl==0.3.0->-r requirements.txt (line 6)) (13.0.0)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a2/91/2d843adb9fbd911e0da45fbf6f18ca89d07a087c3daa23e955584f90ebf4/cachetools-5.3.2-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 181.3/181.3 kB 39.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 1)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 1)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 1)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 1)) (1.26.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard->-r requirements.txt (line 1)) (2023.7.22)\u001b[0m\n",
      "\u001b[34mCollecting regex!=2019.12.17 (from transformers->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/8f/3e/4b8b40eb3c80aeaf360f0361d956d129bb3d23b2a3ecbe3a04a8f3bdd6d3/regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.9/40.9 kB 11.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tokenizers<0.15,>=0.14 (from transformers->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for tokenizers<0.15,>=0.14 from https://files.pythonhosted.org/packages/a7/7b/c1f643eb086b6c5c33eef0c3752e37624bd23e4cbc9f1332748f1c6252d1/tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting safetensors>=0.3.1 (from transformers->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/20/4e/878b080dbda92666233ec6f316a53969edcb58eab1aa399a64d0521cf953/safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->-r requirements.txt (line 1)) (2.1.3)\u001b[0m\n",
      "\u001b[34mCollecting rouge (from auto-gptq->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading rouge-1.0.1-py3-none-any.whl (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting termcolor (from fire->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->axolotl==0.3.0->-r requirements.txt (line 6)) (0.40.1)\u001b[0m\n",
      "\u001b[34mCollecting coloredlogs (from optimum->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 46.0/46.0 kB 14.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: Click!=8.0.0,>=7.1 in /opt/conda/lib/python3.10/site-packages (from wandb->axolotl==0.3.0->-r requirements.txt (line 6)) (8.1.7)\u001b[0m\n",
      "\u001b[34mCollecting GitPython!=3.1.29,>=1.0.0 (from wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for GitPython!=3.1.29,>=1.0.0 from https://files.pythonhosted.org/packages/8d/c4/82b858fb6483dfb5e338123c154d19c043305b01726a67d89532b8f8f01b/GitPython-3.1.40-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.40-py3-none-any.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=1.0.0 (from wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/63/25/d22e1e152e4eac10d39d9132d7b5f1ea4bdfa0b9a1d65fc606a7b90aeefb/sentry_sdk-1.32.0-py2.py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-1.32.0-py2.py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0 (from wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting pathtools (from wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCollecting setproctitle (from wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/79/e7/54b36be02aee8ad573be68f6f46fd62838735c2f007b22df50eb5e13a20d/setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\u001b[0m\n",
      "\u001b[34mCollecting appdirs>=1.4.3 (from wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting xformers (from axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for xformers from https://files.pythonhosted.org/packages/c2/2f/0fa3c080f00c2ebf6836bb1109b9d48b03a4f446e89a058b6c08ba3f7ba1/xformers-0.0.22.post4-cp310-cp310-manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading xformers-0.0.22.post4-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\u001b[0m\n",
      "\u001b[34mObtaining dependency information for xformers from https://files.pythonhosted.org/packages/52/ca/82aeee5dcc24a3429ff5de65cc58ae9695f90f49fbba71755e7fab69a706/xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (23.1.0)\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5 (from aiohttp->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 114.5/114.5 kB 29.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for async-timeout<5.0,>=4.0.0a3 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0 (from aiohttp->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 268.8/268.8 kB 51.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1 (from aiohttp->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/1e/28/74b8b6451c89c070d34e753d8b65a1e4ce508a6808b18529f36e8c0e2184/frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2 (from aiohttp->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for gitdb<5,>=4.0.1 from https://files.pythonhosted.org/packages/fd/5b/8f0c4a5bb9fd491c277c21eff7ccae71b47d43c4446c9d0c6cff2fe8c2c4/gitdb-4.0.11-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas>=1.0.1->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit>=3.0.0->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (0.2.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 1)) (0.5.0)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 1))\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 38.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (3.0.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.0.0->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (2.16.1)\u001b[0m\n",
      "\u001b[34mCollecting huggingface-hub>=0.7.0 (from evaluate==0.4.0->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for huggingface-hub>=0.7.0 from https://files.pythonhosted.org/packages/aa/f3/3fc97336a0e90516901befd4f500f08d691034d387406fdbde85bea827cc/huggingface_hub-0.17.3-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.17.3-py3-none-any.whl.metadata (13 kB)\u001b[0m\n",
      "\u001b[34mCollecting humanfriendly>=9.1 (from coloredlogs->optimum->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 23.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting anyio<4.0.0,>=3.7.1 (from fastapi->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for anyio<4.0.0,>=3.7.1 from https://files.pythonhosted.org/packages/19/24/44299477fe7dcc9cb58d0a57d5a7588d6af2ff403fdd2d47a246c91a3246/anyio-3.7.1-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting starlette<0.28.0,>=0.27.0 (from fastapi->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for starlette<0.28.0,>=0.27.0 from https://files.pythonhosted.org/packages/58/f8/e2cca22387965584a409795913b774235752be4176d276714e15e1a58884/starlette-0.27.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting httpcore<0.19.0,>=0.18.0 (from httpx->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for httpcore<0.19.0,>=0.18.0 from https://files.pythonhosted.org/packages/ac/97/724afbb7925339f6214bf1fdb5714d1a462690466832bf8fb3fd497649f1/httpcore-0.18.0-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading httpcore-0.18.0-py3-none-any.whl.metadata (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting sniffio (from httpx->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading sniffio-1.3.0-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting wavedrom (from markdown2[all]->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading wavedrom-2.0.3.post3.tar.gz (137 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 137.7/137.7 kB 40.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (1.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (4.42.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (1.4.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (10.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score==0.3.13->axolotl==0.3.0->-r requirements.txt (line 6)) (3.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->flash-attn==2.2.1->-r requirements.txt (line 2)) (1.3.0)\u001b[0m\n",
      "\u001b[34mCollecting h11>=0.8 (from uvicorn->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading h11-0.14.0-py3-none-any.whl (58 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.3/58.3 kB 19.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: exceptiongroup in /opt/conda/lib/python3.10/site-packages (from anyio<4.0.0,>=3.7.1->fastapi->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (1.1.3)\u001b[0m\n",
      "\u001b[34mCollecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mObtaining dependency information for smmap<6,>=3.0.1 from https://files.pythonhosted.org/packages/a7/a5/10f97f73544edcdef54409f1d839f6049a0d79df68adbc1ceb24d1aaca42/smmap-5.0.1-py3-none-any.whl.metadata\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6)) (0.1.0)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mCollecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.29->axolotl==0.3.0->-r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.1/67.1 kB 24.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.15.0-py3-none-any.whl (5.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 116.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.1/3.1 MB 102.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading fschat-0.2.29-py3-none-any.whl (200 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 200.7/200.7 kB 49.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading absl_py-2.0.0-py3-none-any.whl (130 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.2/130.2 kB 31.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading bitsandbytes-0.41.1-py3-none-any.whl (92.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.6/92.6 MB 25.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.14.6-py3-none-any.whl (493 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 493.7/493.7 kB 63.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.23.3-py2.py3-none-any.whl (182 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 182.3/182.3 kB 34.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-1.1.0-py2.py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 42.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.5-py3-none-any.whl (101 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 101.7/101.7 kB 32.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 122.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.34.1-py3-none-any.whl (7.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.7/7.7 MB 123.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading art-6.1-py3-none-any.whl (599 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 599.8/599.8 kB 71.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading auto_gptq-0.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.8/1.8 MB 99.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading peft-0.5.0-py3-none-any.whl (85 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.6/85.6 kB 16.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading wandb-0.15.12-py3-none-any.whl (2.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 95.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xformers-0.0.22-cp310-cp310-manylinux2014_x86_64.whl (211.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.6/211.6 MB 11.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 88.6 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading GitPython-3.1.40-py3-none-any.whl (190 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 190.6/190.6 kB 44.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 773.9/773.9 kB 85.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 93.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sentry_sdk-1.32.0-py2.py3-none-any.whl (240 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 241.0/241.0 kB 55.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.8/3.8 MB 122.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 295.0/295.0 kB 59.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading fastapi-0.104.0-py3-none-any.whl (92 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 92.9/92.9 kB 30.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httpx-0.25.0-py3-none-any.whl (75 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 75.7/75.7 kB 23.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nh3-0.2.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 112.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\u001b[0m\n",
      "\u001b[34mDownloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 103.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading uvicorn-0.23.2-py3-none-any.whl (59 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.5/59.5 kB 21.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 38.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading anyio-3.7.1-py3-none-any.whl (80 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 80.9/80.9 kB 27.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.4.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (225 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 225.7/225.7 kB 55.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.7/62.7 kB 19.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading httpcore-0.18.0-py3-none-any.whl (76 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 76.0/76.0 kB 25.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.0/67.0 kB 22.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading markdown2-2.4.10-py2.py3-none-any.whl (39 kB)\u001b[0m\n",
      "\u001b[34mDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: flash-attn, rouge-score, fire, optimum, pathtools, wavedrom\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for flash-attn (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for flash-attn: filename=flash_attn-2.2.1-cp310-cp310-linux_x86_64.whl size=193960420 sha256=90f73bf1b0351f988d545836abd0f27aca8f72040720003809003b0ed40685a0\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/29/3d/d0/ca80c9c6061afa997cd0246a982fd905ef3a1837c8442a0050\u001b[0m\n",
      "\u001b[34mBuilding wheel for rouge-score (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for rouge-score (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=6609a2af9851e3e9608c486feecf6319a1ed546006a7783f60a50e5aa09a543d\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for fire (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116932 sha256=e6464c30b7b76d48f9c7cb18e35b4e09a998b526c7f0f4c284f0bae509456cb4\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\u001b[0m\n",
      "\u001b[34mBuilding wheel for optimum (pyproject.toml): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for optimum (pyproject.toml): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for optimum: filename=optimum-1.13.2-py3-none-any.whl size=395599 sha256=67ed8de2894b12ac07a527d04cb32c7953c8b35013a88906ba2dbebe5f71fdc6\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/6e/b7/2c/79405d98f0943373d8546daeae25a3d377f7659ca0cbe48699\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for pathtools (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=c0e8e2830831620c00fc88679624148c9784d55337da51321d11a1600db444a3\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\u001b[0m\n",
      "\u001b[34mBuilding wheel for wavedrom (setup.py): started\u001b[0m\n",
      "\u001b[34mBuilding wheel for wavedrom (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30053 sha256=41bc222ed2983d3a38ec69891f5fb2bf57478300e066c1025a9081096e1bbb56\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\u001b[0m\n",
      "\u001b[34mSuccessfully built flash-attn rouge-score fire optimum pathtools wavedrom\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mInstalling collected packages: sentencepiece, pathtools, nh3, bitsandbytes, appdirs, addict, xxhash, termcolor, tensorboard-data-server, svgwrite, sniffio, smmap, shortuuid, setproctitle, sentry-sdk, safetensors, rouge, regex, pynvml, pydantic, pyasn1-modules, oauthlib, multidict, markdown2, markdown, humanfriendly, hf_transfer, h11, grpcio, frozenlist, docker-pycreds, cachetools, async-timeout, art, absl-py, yarl, wavedrom, uvicorn, tiktoken, scikit-learn, responses, requests-oauthlib, nltk, huggingface-hub, google-auth, gitdb, fire, coloredlogs, anyio, aiosignal, xformers, tokenizers, starlette, rouge-score, httpcore, google-auth-oauthlib, GitPython, flash-attn, deepspeed, aiohttp, wandb, transformers, tensorboard, httpx, fastapi, peft, fschat, datasets, bert-score, optimum, evaluate, auto-gptq, axolotl\u001b[0m\n",
      "\u001b[34mAttempting uninstall: pydantic\u001b[0m\n",
      "\u001b[34mFound existing installation: pydantic 2.4.1\u001b[0m\n",
      "\u001b[34mUninstalling pydantic-2.4.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled pydantic-2.4.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: scikit-learn\u001b[0m\n",
      "\u001b[34mFound existing installation: scikit-learn 1.3.1\u001b[0m\n",
      "\u001b[34mUninstalling scikit-learn-1.3.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled scikit-learn-1.3.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: flash-attn\u001b[0m\n",
      "\u001b[34mFound existing installation: flash-attn 0.2.8\u001b[0m\n",
      "\u001b[34mUninstalling flash-attn-0.2.8:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled flash-attn-0.2.8\u001b[0m\n",
      "\u001b[34mAttempting uninstall: deepspeed\u001b[0m\n",
      "\u001b[34mFound existing installation: deepspeed 0.6.1+1ea3d4b\u001b[0m\n",
      "\u001b[34mUninstalling deepspeed-0.6.1+1ea3d4b:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled deepspeed-0.6.1+1ea3d4b\u001b[0m\n",
      "\u001b[34mRunning setup.py develop for axolotl\u001b[0m\n",
      "\u001b[34mSuccessfully installed GitPython-3.1.40 absl-py-2.0.0 addict-2.4.0 aiohttp-3.8.6 aiosignal-1.3.1 anyio-3.7.1 appdirs-1.4.4 art-6.1 async-timeout-4.0.3 auto-gptq-0.4.2 axolotl-0.3.0 bert-score-0.3.13 bitsandbytes-0.41.1 cachetools-5.3.2 coloredlogs-15.0.1 datasets-2.14.6 deepspeed-0.11.1 docker-pycreds-0.4.0 evaluate-0.4.0 fastapi-0.104.0 fire-0.5.0 flash-attn-2.2.1 frozenlist-1.4.0 fschat-0.2.29 gitdb-4.0.11 google-auth-2.23.3 google-auth-oauthlib-1.1.0 grpcio-1.59.0 h11-0.14.0 hf_transfer-0.1.3 httpcore-0.18.0 httpx-0.25.0 huggingface-hub-0.17.3 humanfriendly-10.0 markdown-3.5 markdown2-2.4.10 multidict-6.0.4 nh3-0.2.14 nltk-3.8.1 oauthlib-3.2.2 optimum-1.13.2 pathtools-0.1.2 peft-0.5.0 pyasn1-modules-0.3.0 pydantic-1.10.13 pynvml-11.5.0 regex-2023.10.3 requests-oauthlib-1.3.1 responses-0.18.0 rouge-1.0.1 rouge-score-0.1.2 safetensors-0.4.0 scikit-learn-1.2.2 sentencepiece-0.1.99 sentry-sdk-1.32.0 setproctitle-1.3.3 shortuuid-1.0.11 smmap-5.0.1 sniffio-1.3.0 starlette-0.27.0 svgwrite-1.4.3 tensorboard-2.15.0 tensorboard-data-server-0.7.2 termcolor-2.3.0 tiktoken-0.5.1 tokenizers-0.14.1 transformers-4.34.1 uvicorn-0.23.2 wandb-0.15.12 wavedrom-2.0.3.post3 xformers-0.0.22 xxhash-3.4.1 yarl-1.9.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.2.1 -> 23.3.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-10-28 16:46:34,856 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-10-28 16:46:34,856 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-10-28 16:46:34,871 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-28 16:46:34,901 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-28 16:46:34,910 sagemaker-training-toolkit INFO     Starting distributed training through torchrun\u001b[0m\n",
      "\u001b[34m2023-10-28 16:46:34,924 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-10-28 16:46:34,933 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"sagemaker_torch_distributed_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {\n",
      "        \"model\": \"/opt/ml/input/data/model\",\n",
      "        \"train\": \"/opt/ml/input/data/train\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"config\": \"llama2-7b-qlora.yml\",\n",
      "        \"deepspeed\": \"axolotl/deepspeed/zero2.json\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"model\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.2xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-10-28-16-34-30-833\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-west-2-376678947624/pytorch-training-2023-10-28-16-34-30-833/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"axolotl/src/axolotl/cli/train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.2xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.2xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"axolotl/src/axolotl/cli/train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"config\":\"llama2-7b-qlora.yml\",\"deepspeed\":\"axolotl/deepspeed/zero2.json\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=axolotl/src/axolotl/cli/train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"model\",\"train\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.2xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=axolotl/src/axolotl/cli/train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-west-2-376678947624/pytorch-training-2023-10-28-16-34-30-833/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.g5.2xlarge\",\"sagemaker_torch_distributed_enabled\":true},\"channel_input_dirs\":{\"model\":\"/opt/ml/input/data/model\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.2xlarge\",\"distribution_hosts\":[\"algo-1\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"config\":\"llama2-7b-qlora.yml\",\"deepspeed\":\"axolotl/deepspeed/zero2.json\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"model\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"pytorch-training-2023-10-28-16-34-30-833\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-west-2-376678947624/pytorch-training-2023-10-28-16-34-30-833/source/sourcedir.tar.gz\",\"module_name\":\"axolotl/src/axolotl/cli/train\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.2xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.2xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"axolotl/src/axolotl/cli/train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--config\",\"llama2-7b-qlora.yml\",\"--deepspeed\",\"axolotl/deepspeed/zero2.json\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_MODEL=/opt/ml/input/data/model\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_HP_CONFIG=llama2-7b-qlora.yml\u001b[0m\n",
      "\u001b[34mSM_HP_DEEPSPEED=axolotl/deepspeed/zero2.json\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mtorchrun --nnodes 1 --nproc_per_node 1 axolotl/src/axolotl/cli/train.py --config llama2-7b-qlora.yml --deepspeed axolotl/deepspeed/zero2.json\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:38,980] [INFO] [real_accelerator.py:158:get_accelerator] Setting ds_accelerator to cuda (auto detect)\u001b[0m\n",
      "\u001b[34mdP            dP   dP \n",
      "                              88            88   88 \n",
      "   .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
      "   88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
      "   88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
      "   `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP\u001b[0m\n",
      "\u001b[34m#033[33m[2023-10-28 16:46:42,707] [WARNING] [axolotl.validate_config:163] [PID:197] [RANK:0] eval_batch_size != micro_batch_size. This can lead to VRAM instability.#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,709] [INFO] [axolotl.normalize_config:122] [PID:197] [RANK:0] GPU memory usage baseline: 0.000GB (+0.302GB misc)#033[39m\u001b[0m\n",
      "\u001b[34m#033[33m[2023-10-28 16:46:42,710] [WARNING] [axolotl.scripts.check_user_token:261] [PID:197] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.#033[39m\u001b[0m\n",
      "\u001b[34mYou are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\u001b[0m\n",
      "\u001b[34mYou are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,802] [DEBUG] [axolotl.load_tokenizer:74] [PID:197] [RANK:0] EOS: 2 / </s>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,802] [DEBUG] [axolotl.load_tokenizer:75] [PID:197] [RANK:0] BOS: 1 / <s>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,802] [DEBUG] [axolotl.load_tokenizer:76] [PID:197] [RANK:0] PAD: 2 / </s>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,802] [DEBUG] [axolotl.load_tokenizer:77] [PID:197] [RANK:0] UNK: 0 / <unk>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,936] [INFO] [axolotl.load_tokenized_prepared_datasets:130] [PID:197] [RANK:0] Unable to find prepared dataset in /tmp/last_run_prepared/f3d9deff3e37e80444b6c44261a80b6c#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,936] [INFO] [axolotl.load_tokenized_prepared_datasets:131] [PID:197] [RANK:0] Loading raw datasets...#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:46:42,936] [INFO] [axolotl.load_tokenized_prepared_datasets:136] [PID:197] [RANK:0] No seed provided, using default seed of 42#033[39m\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\u001b[0m\n",
      "\u001b[34mYou can remove this warning by passing 'token=None' instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mDownloading data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 1/1 [00:00<00:00, 10512.04it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files:   0%|          | 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files: 100%|██████████| 1/1 [00:00<00:00, 986.43it/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 0 examples [00:00, ? examples/s]\u001b[0m\n",
      "\u001b[34mGenerating train split: 78577 examples [00:00, 1294342.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/78577 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 15/78577 [00:00<18:39, 70.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 232/78577 [00:00<01:28, 884.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 526/78577 [00:00<00:48, 1617.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|          | 817/78577 [00:00<00:39, 1972.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   1%|▏         | 1076/78577 [00:00<00:37, 2087.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 1333/78577 [00:00<00:35, 2181.13 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 1590/78577 [00:00<00:35, 2192.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 1846/78577 [00:00<00:33, 2271.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 2093/78577 [00:01<00:33, 2308.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 2335/78577 [00:01<00:34, 2210.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 2590/78577 [00:01<00:34, 2230.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▎         | 2873/78577 [00:01<00:32, 2319.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 3111/78577 [00:01<00:32, 2296.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 3351/78577 [00:01<00:32, 2284.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 3599/78577 [00:01<00:33, 2267.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▍         | 3839/78577 [00:01<00:32, 2280.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   5%|▌         | 4081/78577 [00:01<00:33, 2217.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 4342/78577 [00:02<00:32, 2281.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 4582/78577 [00:02<00:32, 2311.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 4821/78577 [00:02<00:32, 2277.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▋         | 5084/78577 [00:02<00:31, 2304.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 5348/78577 [00:02<00:31, 2296.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 5610/78577 [00:02<00:30, 2355.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 5854/78577 [00:02<00:30, 2375.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 6112/78577 [00:02<00:31, 2330.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 6359/78577 [00:02<00:31, 2322.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 6607/78577 [00:03<00:31, 2311.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▊         | 6865/78577 [00:03<00:31, 2312.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 7119/78577 [00:03<00:31, 2293.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 7379/78577 [00:03<00:30, 2372.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|▉         | 7629/78577 [00:03<00:30, 2313.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|█         | 7862/78577 [00:03<00:35, 2003.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  10%|█         | 8072/78577 [00:03<00:43, 1626.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 8276/78577 [00:03<00:41, 1687.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 8556/78577 [00:04<00:37, 1851.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 8831/78577 [00:04<00:33, 2071.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 9053/78577 [00:04<00:33, 2091.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 9290/78577 [00:04<00:33, 2080.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 9521/78577 [00:04<00:32, 2136.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 9762/78577 [00:04<00:31, 2204.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 10024/78577 [00:04<00:30, 2227.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 10282/78577 [00:04<00:29, 2304.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 10520/78577 [00:04<00:30, 2267.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▎        | 10760/78577 [00:05<00:29, 2269.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 11006/78577 [00:05<00:29, 2308.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 11251/78577 [00:05<00:29, 2267.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 11485/78577 [00:05<00:30, 2219.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▍        | 11749/78577 [00:05<00:28, 2312.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 11992/78577 [00:05<00:28, 2319.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 12233/78577 [00:05<00:29, 2269.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 12462/78577 [00:05<00:29, 2249.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▌        | 12695/78577 [00:05<00:29, 2247.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▋        | 12941/78577 [00:05<00:28, 2281.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 13194/78577 [00:06<00:27, 2352.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 13434/78577 [00:06<00:28, 2263.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  17%|█▋        | 13676/78577 [00:06<00:29, 2229.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 13955/78577 [00:06<00:27, 2357.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 14209/78577 [00:06<00:27, 2333.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 14457/78577 [00:06<00:28, 2284.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▊        | 14694/78577 [00:06<00:28, 2266.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 14958/78577 [00:06<00:27, 2324.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 15199/78577 [00:06<00:28, 2244.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|█▉        | 15446/78577 [00:07<00:28, 2186.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|█▉        | 15668/78577 [00:07<00:29, 2113.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 15883/78577 [00:07<00:30, 2029.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 16087/78577 [00:07<00:34, 1831.04 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 16285/78577 [00:07<00:34, 1828.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 16518/78577 [00:07<00:31, 1941.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██▏       | 16788/78577 [00:07<00:29, 2061.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 16998/78577 [00:07<00:30, 2048.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 17245/78577 [00:08<00:29, 2108.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 17489/78577 [00:08<00:28, 2160.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 17738/78577 [00:08<00:27, 2246.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 17977/78577 [00:08<00:27, 2242.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 18217/78577 [00:08<00:27, 2215.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▎       | 18490/78577 [00:08<00:26, 2278.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 18763/78577 [00:08<00:25, 2309.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 19003/78577 [00:08<00:25, 2303.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  24%|██▍       | 19245/78577 [00:08<00:26, 2261.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 19515/78577 [00:08<00:25, 2356.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 19765/78577 [00:09<00:25, 2272.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▌       | 20000/78577 [00:09<00:25, 2267.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 20262/78577 [00:09<00:25, 2288.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 20506/78577 [00:09<00:25, 2307.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▋       | 20753/78577 [00:09<00:24, 2345.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 20998/78577 [00:09<00:24, 2353.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 21244/78577 [00:09<00:24, 2303.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 21500/78577 [00:09<00:24, 2297.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 21750/78577 [00:09<00:24, 2330.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 21995/78577 [00:10<00:24, 2330.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  28%|██▊       | 22232/78577 [00:10<00:24, 2322.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▊       | 22493/78577 [00:10<00:24, 2324.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 22728/78577 [00:10<00:24, 2281.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▉       | 22987/78577 [00:10<00:24, 2315.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 23235/78577 [00:10<00:24, 2268.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 23467/78577 [00:10<00:25, 2176.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 23698/78577 [00:10<00:26, 2061.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|███       | 23921/78577 [00:10<00:28, 1930.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 24133/78577 [00:11<00:29, 1834.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 24374/78577 [00:11<00:27, 1971.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███▏      | 24630/78577 [00:11<00:25, 2108.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 24846/78577 [00:11<00:25, 2103.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 25107/78577 [00:11<00:24, 2196.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 25339/78577 [00:11<00:24, 2205.88 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 25592/78577 [00:11<00:23, 2272.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 25828/78577 [00:11<00:23, 2221.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 26058/78577 [00:11<00:23, 2192.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▎      | 26334/78577 [00:12<00:22, 2285.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 26580/78577 [00:12<00:23, 2251.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 26832/78577 [00:12<00:23, 2225.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 27085/78577 [00:12<00:22, 2283.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▍      | 27374/78577 [00:12<00:23, 2211.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  35%|███▌      | 27630/78577 [00:12<00:22, 2267.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 27895/78577 [00:12<00:21, 2350.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 28137/78577 [00:12<00:22, 2248.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 28400/78577 [00:12<00:22, 2276.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▋      | 28656/78577 [00:13<00:21, 2332.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 28894/78577 [00:13<00:21, 2268.25 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 29141/78577 [00:13<00:21, 2294.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 29398/78577 [00:13<00:20, 2350.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 29645/78577 [00:13<00:21, 2324.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 29898/78577 [00:13<00:21, 2255.56 examples/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 30166/78577 [00:13<00:20, 2355.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▊      | 30404/78577 [00:13<00:21, 2291.81 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 30648/78577 [00:13<00:20, 2296.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 30883/78577 [00:14<00:21, 2264.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 31120/78577 [00:14<00:21, 2203.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|███▉      | 31355/78577 [00:14<00:22, 2135.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 31575/78577 [00:14<00:23, 1997.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 31823/78577 [00:14<00:23, 2007.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 32036/78577 [00:14<00:24, 1891.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████      | 32271/78577 [00:14<00:23, 1998.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  41%|████▏     | 32513/78577 [00:14<00:22, 2079.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 32747/78577 [00:14<00:22, 2062.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 33033/78577 [00:15<00:20, 2275.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 33267/78577 [00:15<00:19, 2269.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 33508/78577 [00:15<00:19, 2268.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 33753/78577 [00:15<00:19, 2316.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 34001/78577 [00:15<00:19, 2230.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▎     | 34241/78577 [00:15<00:19, 2253.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 34503/78577 [00:15<00:18, 2331.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 34751/78577 [00:15<00:19, 2248.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 34991/78577 [00:15<00:19, 2220.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▍     | 35240/78577 [00:16<00:19, 2169.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 35518/78577 [00:16<00:18, 2310.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 35752/78577 [00:16<00:19, 2242.34 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 36007/78577 [00:16<00:18, 2253.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▌     | 36283/78577 [00:16<00:18, 2317.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▋     | 36521/78577 [00:16<00:18, 2310.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 36762/78577 [00:16<00:18, 2259.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 37023/78577 [00:16<00:18, 2301.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  47%|████▋     | 37281/78577 [00:16<00:17, 2355.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 37521/78577 [00:17<00:17, 2344.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 37762/78577 [00:17<00:17, 2287.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 38029/78577 [00:17<00:17, 2310.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 38320/78577 [00:17<00:17, 2353.39 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 38568/78577 [00:17<00:17, 2336.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 38821/78577 [00:17<00:17, 2262.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|████▉     | 39066/78577 [00:17<00:17, 2215.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 39307/78577 [00:17<00:18, 2109.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 39524/78577 [00:18<00:19, 1979.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 39731/78577 [00:18<00:19, 2001.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 39942/78577 [00:18<00:19, 2007.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 40152/78577 [00:18<00:19, 1970.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████▏    | 40369/78577 [00:18<00:18, 2020.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 40632/78577 [00:18<00:17, 2133.67 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 40899/78577 [00:18<00:16, 2225.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 41167/78577 [00:18<00:16, 2329.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 41405/78577 [00:18<00:16, 2256.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 41653/78577 [00:18<00:16, 2253.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 41925/78577 [00:19<00:15, 2383.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▎    | 42183/78577 [00:19<00:15, 2303.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 42426/78577 [00:19<00:15, 2267.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 42691/78577 [00:19<00:15, 2348.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 42930/78577 [00:19<00:15, 2305.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▍    | 43171/78577 [00:19<00:16, 2211.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  55%|█████▌    | 43439/78577 [00:19<00:15, 2196.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 43727/78577 [00:19<00:14, 2327.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 43967/78577 [00:19<00:14, 2323.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▋    | 44207/78577 [00:20<00:14, 2293.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 44474/78577 [00:20<00:14, 2315.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 44742/78577 [00:20<00:14, 2397.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 44997/78577 [00:20<00:14, 2387.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 45248/78577 [00:20<00:13, 2421.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 45504/78577 [00:20<00:14, 2325.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 45760/78577 [00:20<00:13, 2365.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▊    | 46020/78577 [00:20<00:13, 2328.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 46264/78577 [00:20<00:13, 2357.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 46502/78577 [00:21<00:13, 2308.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 46739/78577 [00:21<00:13, 2298.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|█████▉    | 46990/78577 [00:21<00:14, 2187.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 47218/78577 [00:21<00:15, 2033.65 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  60%|██████    | 47442/78577 [00:21<00:16, 1942.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 47686/78577 [00:21<00:15, 2058.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 47906/78577 [00:21<00:14, 2089.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████▏   | 48133/78577 [00:21<00:14, 2071.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 48379/78577 [00:21<00:14, 2063.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 48642/78577 [00:22<00:13, 2172.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 48887/78577 [00:22<00:13, 2225.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 49114/78577 [00:22<00:13, 2211.83 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 49399/78577 [00:22<00:12, 2365.75 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 49643/78577 [00:22<00:12, 2330.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 49887/78577 [00:22<00:12, 2285.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 50155/78577 [00:22<00:11, 2371.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 50407/78577 [00:22<00:11, 2362.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 50646/78577 [00:22<00:12, 2290.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▍   | 50914/78577 [00:23<00:11, 2398.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 51159/78577 [00:23<00:11, 2411.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 51406/78577 [00:23<00:11, 2345.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 51658/78577 [00:23<00:11, 2291.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 51899/78577 [00:23<00:11, 2303.55 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▋   | 52148/78577 [00:23<00:11, 2272.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 52388/78577 [00:23<00:11, 2260.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 52661/78577 [00:23<00:10, 2369.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  67%|██████▋   | 52910/78577 [00:23<00:11, 2330.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 53176/78577 [00:24<00:10, 2389.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 53420/78577 [00:24<00:10, 2321.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 53661/78577 [00:24<00:10, 2320.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▊   | 53900/78577 [00:24<00:10, 2318.07 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 54162/78577 [00:24<00:10, 2376.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 54406/78577 [00:24<00:10, 2337.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 54659/78577 [00:24<00:10, 2351.76 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|██████▉   | 54901/78577 [00:24<00:10, 2257.78 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 55141/78577 [00:24<00:11, 2089.22 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 55359/78577 [00:25<00:11, 1963.31 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 55561/78577 [00:25<00:12, 1917.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████   | 55831/78577 [00:25<00:11, 2063.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████▏  | 56057/78577 [00:25<00:10, 2093.99 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 56319/78577 [00:25<00:10, 2210.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 56560/78577 [00:25<00:09, 2239.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 56798/78577 [00:25<00:10, 2161.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 57025/78577 [00:25<00:09, 2166.64 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 57274/78577 [00:25<00:09, 2232.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 57502/78577 [00:25<00:09, 2222.66 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▎  | 57778/78577 [00:26<00:08, 2348.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 58020/78577 [00:26<00:08, 2333.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 58259/78577 [00:26<00:08, 2306.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 58500/78577 [00:26<00:08, 2253.92 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▍  | 58766/78577 [00:26<00:08, 2362.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 59021/78577 [00:26<00:08, 2314.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  75%|███████▌  | 59286/78577 [00:26<00:08, 2334.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 59522/78577 [00:26<00:08, 2340.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 59762/78577 [00:26<00:08, 2254.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▋  | 60015/78577 [00:27<00:08, 2231.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 60262/78577 [00:27<00:07, 2295.48 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 60493/78577 [00:27<00:08, 2251.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 60746/78577 [00:27<00:07, 2255.91 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 61009/78577 [00:27<00:07, 2333.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 61251/78577 [00:27<00:07, 2280.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 61520/78577 [00:27<00:07, 2370.01 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▊  | 61766/78577 [00:27<00:07, 2365.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 62013/78577 [00:27<00:06, 2368.53 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 62258/78577 [00:28<00:07, 2316.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|███████▉  | 62495/78577 [00:28<00:06, 2305.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|███████▉  | 62751/78577 [00:28<00:06, 2349.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 63005/78577 [00:28<00:07, 2159.52 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  80%|████████  | 63225/78577 [00:28<00:07, 2022.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 63436/78577 [00:28<00:08, 1878.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 63712/78577 [00:28<00:07, 1992.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████▏ | 63970/78577 [00:28<00:06, 2140.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 64198/78577 [00:28<00:06, 2148.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 64445/78577 [00:29<00:06, 2163.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 64698/78577 [00:29<00:06, 2214.06 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 64940/78577 [00:29<00:06, 2196.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 65185/78577 [00:29<00:05, 2244.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 65411/78577 [00:29<00:05, 2247.35 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▎ | 65655/78577 [00:29<00:05, 2230.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 65939/78577 [00:29<00:05, 2358.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▍ | 66183/78577 [00:29<00:05, 2271.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 66453/78577 [00:29<00:05, 2311.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 66711/78577 [00:30<00:05, 2310.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▌ | 66970/78577 [00:30<00:04, 2361.30 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 67207/78577 [00:30<00:04, 2360.59 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 67458/78577 [00:30<00:04, 2352.41 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 67742/78577 [00:30<00:04, 2407.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 67991/78577 [00:30<00:04, 2249.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 68234/78577 [00:30<00:04, 2231.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 68477/78577 [00:30<00:04, 2248.98 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 68733/78577 [00:30<00:04, 2268.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 68988/78577 [00:31<00:04, 2298.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 69227/78577 [00:31<00:04, 2295.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 69473/78577 [00:31<00:03, 2292.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▊ | 69725/78577 [00:31<00:03, 2304.44 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 69983/78577 [00:31<00:03, 2378.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  89%|████████▉ | 70239/78577 [00:31<00:03, 2352.15 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 70492/78577 [00:31<00:03, 2377.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 70742/78577 [00:31<00:03, 2333.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|█████████ | 70980/78577 [00:31<00:03, 2000.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 71201/78577 [00:32<00:03, 1977.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 71411/78577 [00:32<00:03, 1988.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 71624/78577 [00:32<00:03, 1961.33 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████▏| 71862/78577 [00:32<00:03, 2052.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 72125/78577 [00:32<00:02, 2165.80 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 72367/78577 [00:32<00:02, 2211.38 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 72592/78577 [00:32<00:02, 2199.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 72825/78577 [00:32<00:02, 2209.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 73078/78577 [00:32<00:02, 2250.37 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 73311/78577 [00:33<00:02, 2249.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▎| 73539/78577 [00:33<00:02, 2202.16 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 73800/78577 [00:33<00:02, 2196.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  94%|█████████▍| 74072/78577 [00:33<00:01, 2291.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 74323/78577 [00:33<00:01, 2304.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 74596/78577 [00:33<00:01, 2291.57 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▌| 74859/78577 [00:33<00:01, 2360.13 examples/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 75102/78577 [00:33<00:01, 2353.23 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 75352/78577 [00:33<00:01, 2312.94 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▋| 75636/78577 [00:34<00:01, 2434.56 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 75896/78577 [00:34<00:01, 2399.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 76140/78577 [00:34<00:01, 2276.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 76385/78577 [00:34<00:00, 2237.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 76655/78577 [00:34<00:00, 2283.60 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 76904/78577 [00:34<00:00, 2293.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 77167/78577 [00:34<00:00, 2356.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▊| 77420/78577 [00:34<00:00, 2208.02 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 77646/78577 [00:34<00:00, 1957.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 77853/78577 [00:35<00:00, 1903.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 78057/78577 [00:35<00:00, 1933.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|█████████▉| 78300/78577 [00:35<00:00, 2048.32 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 78577/78577 [00:35<00:00, 1935.05 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 78577/78577 [00:35<00:00, 2211.56 examples/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:18,969] [INFO] [axolotl.load_tokenized_prepared_datasets:354] [PID:197] [RANK:0] merging datasets#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:18,972] [INFO] [axolotl.load_tokenized_prepared_datasets:361] [PID:197] [RANK:0] Saving merged prepared dataset to disk... /tmp/last_run_prepared/f3d9deff3e37e80444b6c44261a80b6c#033[39m\u001b[0m\n",
      "\u001b[34mSaving the dataset (0/1 shards):   0%|          | 0/78577 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/1 shards): 100%|██████████| 78577/78577 [00:00<00:00, 1043341.17 examples/s]\u001b[0m\n",
      "\u001b[34mSaving the dataset (1/1 shards): 100%|██████████| 78577/78577 [00:00<00:00, 1040209.53 examples/s]\u001b[0m\n",
      "\u001b[34mNCCL version 2.17.1+cuda11.8\u001b[0m\n",
      "\u001b[34malgo-1:197:277 [0] nccl_net_ofi_init:1472 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):   0%|          | 0/77791 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):   1%|▏         | 1000/77791 [00:00<00:53, 1432.25 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):   4%|▍         | 3000/77791 [00:00<00:16, 4521.85 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  12%|█▏        | 9000/77791 [00:01<00:08, 7668.46 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  17%|█▋        | 13000/77791 [00:01<00:05, 11108.47 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  22%|██▏       | 17000/77791 [00:02<00:06, 9251.85 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  26%|██▌       | 20000/77791 [00:02<00:05, 11418.29 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  31%|███       | 24000/77791 [00:02<00:03, 15252.41 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  35%|███▍      | 27000/77791 [00:02<00:04, 10190.60 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  39%|███▊      | 30000/77791 [00:02<00:03, 12462.17 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  42%|████▏     | 33000/77791 [00:03<00:04, 9802.31 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  45%|████▍     | 35000/77791 [00:03<00:03, 10759.92 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  49%|████▉     | 38000/77791 [00:03<00:03, 13119.85 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  51%|█████▏    | 40000/77791 [00:03<00:02, 13148.50 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  54%|█████▍    | 42000/77791 [00:04<00:03, 10089.82 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  58%|█████▊    | 45000/77791 [00:04<00:02, 13046.77 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  60%|██████    | 47000/77791 [00:04<00:02, 11861.54 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  63%|██████▎   | 49000/77791 [00:04<00:02, 9655.95 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  66%|██████▌   | 51000/77791 [00:04<00:02, 10946.50 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  71%|███████   | 55000/77791 [00:05<00:01, 11800.05 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  73%|███████▎  | 57000/77791 [00:05<00:02, 10338.96 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  77%|███████▋  | 60000/77791 [00:05<00:01, 13143.73 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  80%|███████▉  | 62000/77791 [00:05<00:01, 14196.81 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  82%|████████▏ | 64000/77791 [00:06<00:01, 10463.60 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  85%|████████▍ | 66000/77791 [00:06<00:01, 10670.89 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  89%|████████▊ | 69000/77791 [00:06<00:00, 12966.10 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  91%|█████████▏| 71000/77791 [00:06<00:00, 10705.86 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  95%|█████████▍| 73896/77791 [00:06<00:00, 13685.94 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  99%|█████████▉| 77067/77791 [00:06<00:00, 15974.05 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8): 100%|██████████| 77791/77791 [00:06<00:00, 11133.81 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):   0%|          | 0/786 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8):  13%|█▎        | 99/786 [00:00<00:00, 757.26 examples/s]\u001b[0m\n",
      "\u001b[34mFilter (num_proc=8): 100%|██████████| 786/786 [00:00<00:00, 3563.93 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/77791 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 92/77791 [00:00<02:18, 559.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   2%|▏         | 1285/77791 [00:00<00:13, 5750.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   3%|▎         | 2434/77791 [00:00<00:09, 7653.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   4%|▍         | 3419/77791 [00:00<00:08, 8308.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   6%|▌         | 4349/77791 [00:00<00:08, 8398.82 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   7%|▋         | 5275/77791 [00:00<00:08, 8364.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   8%|▊         | 6349/77791 [00:00<00:07, 8977.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   9%|▉         | 7305/77791 [00:00<00:08, 8632.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  11%|█         | 8240/77791 [00:01<00:12, 5455.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  12%|█▏        | 8998/77791 [00:01<00:11, 5837.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 9830/77791 [00:01<00:10, 6333.18 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  14%|█▍        | 10859/77791 [00:01<00:09, 7214.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  15%|█▌        | 11787/77791 [00:01<00:08, 7698.61 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  16%|█▋        | 12803/77791 [00:01<00:08, 8050.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  18%|█▊        | 13832/77791 [00:01<00:07, 8382.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  19%|█▉        | 14729/77791 [00:01<00:07, 8447.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  20%|██        | 15626/77791 [00:02<00:07, 7816.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  21%|██        | 16476/77791 [00:02<00:10, 5705.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  22%|██▏       | 17284/77791 [00:02<00:09, 6157.45 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  23%|██▎       | 18250/77791 [00:02<00:08, 6900.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  25%|██▍       | 19290/77791 [00:02<00:07, 7688.96 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  26%|██▌       | 20178/77791 [00:02<00:07, 7913.97 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  27%|██▋       | 21149/77791 [00:02<00:06, 8307.68 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  29%|██▊       | 22193/77791 [00:02<00:06, 8797.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  30%|██▉       | 23114/77791 [00:03<00:06, 8716.79 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  31%|███       | 24062/77791 [00:03<00:08, 6161.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  32%|███▏      | 24837/77791 [00:03<00:08, 6114.70 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  33%|███▎      | 25699/77791 [00:03<00:07, 6645.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  34%|███▍      | 26670/77791 [00:03<00:06, 7314.71 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  36%|███▌      | 27711/77791 [00:03<00:06, 8021.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  37%|███▋      | 28604/77791 [00:03<00:06, 8179.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  38%|███▊      | 29652/77791 [00:04<00:05, 8531.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  39%|███▉      | 30549/77791 [00:04<00:05, 8541.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  40%|████      | 31454/77791 [00:04<00:05, 8165.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  42%|████▏     | 32353/77791 [00:04<00:07, 6055.49 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  43%|████▎     | 33201/77791 [00:04<00:06, 6372.54 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  44%|████▍     | 34245/77791 [00:04<00:06, 7123.90 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  45%|████▌     | 35130/77791 [00:04<00:05, 7470.74 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  46%|████▋     | 36097/77791 [00:04<00:05, 7955.03 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  48%|████▊     | 37138/77791 [00:05<00:04, 8518.46 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  49%|████▉     | 38051/77791 [00:05<00:04, 8404.62 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  50%|█████     | 38979/77791 [00:05<00:04, 8031.36 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  51%|█████     | 39847/77791 [00:05<00:05, 7551.85 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  52%|█████▏    | 40674/77791 [00:05<00:05, 6198.20 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  53%|█████▎    | 41427/77791 [00:05<00:05, 6446.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  54%|█████▍    | 42369/77791 [00:05<00:04, 7102.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  56%|█████▌    | 43325/77791 [00:05<00:04, 7657.77 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  57%|█████▋    | 44279/77791 [00:06<00:04, 8113.43 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  58%|█████▊    | 45327/77791 [00:06<00:03, 8440.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  59%|█████▉    | 46229/77791 [00:06<00:03, 8323.73 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  61%|██████    | 47115/77791 [00:06<00:03, 7869.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  62%|██████▏   | 47975/77791 [00:06<00:04, 7143.08 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  63%|██████▎   | 48719/77791 [00:06<00:04, 5998.10 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  64%|██████▍   | 49759/77791 [00:06<00:04, 6897.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  65%|██████▌   | 50722/77791 [00:06<00:03, 7562.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  66%|██████▌   | 51529/77791 [00:07<00:03, 7496.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  68%|██████▊   | 52640/77791 [00:07<00:03, 7994.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  69%|██████▉   | 53749/77791 [00:07<00:02, 8203.09 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  70%|███████   | 54628/77791 [00:07<00:02, 7973.26 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  71%|███████▏  | 55469/77791 [00:07<00:02, 7977.11 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  72%|███████▏  | 56326/77791 [00:07<00:02, 7585.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  73%|███████▎  | 57096/77791 [00:07<00:03, 6219.95 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  74%|███████▍  | 57818/77791 [00:07<00:03, 6396.86 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  76%|███████▌  | 58928/77791 [00:08<00:02, 7380.21 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  77%|███████▋  | 60028/77791 [00:08<00:02, 8198.12 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  78%|███████▊  | 60907/77791 [00:08<00:02, 8095.14 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  79%|███████▉  | 61782/77791 [00:08<00:01, 8177.00 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  81%|████████  | 62674/77791 [00:08<00:01, 7823.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  82%|████████▏ | 63528/77791 [00:08<00:01, 7567.69 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  83%|████████▎ | 64304/77791 [00:08<00:01, 6948.19 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  84%|████████▎ | 65023/77791 [00:08<00:01, 6419.63 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  85%|████████▍ | 65768/77791 [00:08<00:01, 6548.40 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  86%|████████▌ | 66682/77791 [00:09<00:01, 7005.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  87%|████████▋ | 67787/77791 [00:09<00:01, 7831.84 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  88%|████████▊ | 68809/77791 [00:09<00:01, 8379.51 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  90%|████████▉ | 69694/77791 [00:09<00:00, 8241.17 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  91%|█████████ | 70530/77791 [00:09<00:00, 7757.89 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  92%|█████████▏| 71362/77791 [00:09<00:00, 7353.28 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  93%|█████████▎| 72167/77791 [00:09<00:00, 6883.54 examples/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mMap (num_proc=8):  94%|█████████▎| 72901/77791 [00:09<00:00, 6530.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  95%|█████████▍| 73764/77791 [00:10<00:00, 6925.72 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  96%|█████████▌| 74468/77791 [00:10<00:00, 6885.47 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  97%|█████████▋| 75504/77791 [00:10<00:00, 7272.42 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  98%|█████████▊| 76316/77791 [00:10<00:00, 7194.27 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  99%|█████████▉| 77188/77791 [00:10<00:00, 7201.29 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 77791/77791 [00:10<00:00, 7273.24 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):   0%|          | 0/786 [00:00<?, ? examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8):  13%|█▎        | 99/786 [00:00<00:01, 674.50 examples/s]\u001b[0m\n",
      "\u001b[34mMap (num_proc=8): 100%|██████████| 786/786 [00:00<00:00, 2888.17 examples/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:38,437] [INFO] [axolotl.calculate_total_num_steps:438] [PID:197] [RANK:0] calculating total_num_tokens#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:38,488] [INFO] [axolotl.calculate_total_num_steps:445] [PID:197] [RANK:0] total_num_tokens: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,181] [INFO] [axolotl.calculate_total_num_steps:455] [PID:197] [RANK:0] `total_supervised_tokens: 2375856`#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,420] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,440] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 2e3df3c37d6f9bda2c30b73c679e92f6d5fc62012daf1fa35030413182d2c1a7#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,796] [INFO] [axolotl.utils.dataloader.len_w_stats:295] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 actual packing efficiency: 0.9946962611227009#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,797] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,797] [INFO] [axolotl.calculate_total_num_steps:504] [PID:197] [RANK:0] data_loader_len: 721#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,809] [INFO] [axolotl.calc_sample_packing_eff_est:510] [PID:197] [RANK:0] sample_packing_eff_est across ranks: [0.9946962594985962]#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,810] [INFO] [axolotl.calculate_total_num_steps:521] [PID:197] [RANK:0] sample_packing_eff_est: 1.0#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,810] [INFO] [axolotl.calculate_total_num_steps:526] [PID:197] [RANK:0] total_num_steps: 2884#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,815] [INFO] [axolotl.train.train:48] [PID:197] [RANK:0] loading tokenizer... /opt/ml/input/data/model#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,902] [DEBUG] [axolotl.load_tokenizer:74] [PID:197] [RANK:0] EOS: 2 / </s>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,902] [DEBUG] [axolotl.load_tokenizer:75] [PID:197] [RANK:0] BOS: 1 / <s>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,902] [DEBUG] [axolotl.load_tokenizer:76] [PID:197] [RANK:0] PAD: 2 / </s>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:39,902] [DEBUG] [axolotl.load_tokenizer:77] [PID:197] [RANK:0] UNK: 0 / <unk>#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:40,034] [INFO] [axolotl.train.train:56] [PID:197] [RANK:0] loading model and (optionally) peft_config...#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:40,039] [INFO] [axolotl.load_model:122] [PID:197] [RANK:0] patching with flash attention for sample packing#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:47:40,041] [INFO] [axolotl.load_model:175] [PID:197] [RANK:0] patching _expand_mask#033[39m\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards:  50%|█████     | 1/2 [00:13<00:13, 13.96s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.50s/it]\u001b[0m\n",
      "\u001b[34mLoading checkpoint shards: 100%|██████████| 2/2 [00:25<00:00, 12.72s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:06,118] [INFO] [axolotl.load_model:358] [PID:197] [RANK:0] GPU memory usage after model load: 3.684GB (+0.138GB cache, +0.727GB misc)#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:06,122] [INFO] [axolotl.load_model:375] [PID:197] [RANK:0] converting PEFT model w/ prepare_model_for_kbit_training#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:06,126] [INFO] [axolotl.load_model:386] [PID:197] [RANK:0] converting modules to torch.bfloat16 for flash attention#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:06,129] [INFO] [axolotl.load_lora:491] [PID:197] [RANK:0] found linear modules: ['q_proj', 'gate_proj', 'down_proj', 'o_proj', 'v_proj', 'k_proj', 'up_proj']#033[39m\u001b[0m\n",
      "\u001b[34mtrainable params: 79,953,920 || all params: 6,818,369,536 || trainable%: 1.172625208678628\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:54,519] [INFO] [axolotl.load_model:422] [PID:197] [RANK:0] GPU memory usage after adapters: 3.985GB (+0.986GB cache, +0.727GB misc)#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:54,527] [INFO] [axolotl.train.train:84] [PID:197] [RANK:0] Pre-saving adapter config to /opt/ml/model#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:54,529] [INFO] [axolotl.train.train:108] [PID:197] [RANK:0] Starting trainer...#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:54,916] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:48:54,916] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34mUsing /root/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\u001b[0m\n",
      "\u001b[34mCreating extension directory /root/.cache/torch_extensions/py310_cu118/cpu_adam...\u001b[0m\n",
      "\u001b[34mDetected CUDA files, patching ldflags\u001b[0m\n",
      "\u001b[34mEmitting ninja build file /root/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\u001b[0m\n",
      "\u001b[34mBuilding extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mAllowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\u001b[0m\n",
      "\u001b[34m[1/4] /opt/conda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++17 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o\u001b[0m\n",
      "\u001b[34m[2/4] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o\u001b[0m\n",
      "\u001b[34m[3/4] c++ -MMD -MF cpu_adam_impl.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/opt/conda/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /opt/conda/lib/python3.10/site-packages/torch/include/TH -isystem /opt/conda/lib/python3.10/site-packages/torch/include/THC -isystem /opt/conda/include -isystem /opt/conda/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++17 -g -Wno-reorder -L/opt/conda/lib -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -D__ENABLE_CUDA__ -DBF16_AVAILABLE -c /opt/conda/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam_impl.cpp -o cpu_adam_impl.o\u001b[0m\n",
      "\u001b[34m[4/4] c++ cpu_adam.o cpu_adam_impl.o custom_cuda_kernel.cuda.o -shared -lcurand -L/opt/conda/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/opt/conda/lib64 -lcudart -o cpu_adam.so\u001b[0m\n",
      "\u001b[34mLoading extension module cpu_adam...\u001b[0m\n",
      "\u001b[34mTime to load cpu_adam op: 33.98340368270874 seconds\u001b[0m\n",
      "\u001b[34m0%|          | 0/720 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:49:31,653] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:49:31,653] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:49:31,674] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] e367fc745384ff07881ed447e077139653b10e5b6d14bd5a48b3660fae3ec916#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:49:32,038] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m0%|          | 1/720 [00:34<6:52:08, 34.39s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.1016, 'learning_rate': 0.0, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 1/720 [00:34<6:52:08, 34.39s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:06,050] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:06,058] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:06,058] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:06,062] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:08,556] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:08,557] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:11,118] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:13,680] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:16,242] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:18,834] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 1.1446866989135742, 'eval_runtime': 12.8818, 'eval_samples_per_second': 61.016, 'eval_steps_per_second': 30.508, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 1/720 [00:47<6:52:08, 34.39s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 16:50:52,744] [INFO] [axolotl.callbacks.on_step_end:122] [PID:197] [RANK:0] GPU memory usage while training: 3.937GB (+8.752GB cache, +0.823GB misc)#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 2/720 [01:21<8:18:11, 41.63s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0271, 'learning_rate': 2e-05, 'epoch': 0.01}\u001b[0m\n",
      "\u001b[34m0%|          | 2/720 [01:21<8:18:11, 41.63s/it]\u001b[0m\n",
      "\u001b[34m0%|          | 3/720 [01:54<7:34:55, 38.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0664, 'learning_rate': 4e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m0%|          | 3/720 [01:54<7:34:55, 38.07s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 4/720 [02:28<7:14:20, 36.40s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 1.0437, 'learning_rate': 6e-05, 'epoch': 0.02}\u001b[0m\n",
      "\u001b[34m1%|          | 4/720 [02:28<7:14:20, 36.40s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 5/720 [03:02<7:02:39, 35.47s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9926, 'learning_rate': 8e-05, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 5/720 [03:02<7:02:39, 35.47s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 6/720 [03:36<6:55:21, 34.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.9522, 'learning_rate': 0.0001, 'epoch': 0.03}\u001b[0m\n",
      "\u001b[34m1%|          | 6/720 [03:36<6:55:21, 34.90s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 7/720 [04:10<6:50:30, 34.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.8243, 'learning_rate': 0.00012, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 7/720 [04:10<6:50:30, 34.54s/it]\u001b[0m\n",
      "\u001b[34m1%|          | 8/720 [04:44<6:47:18, 34.32s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.6605, 'learning_rate': 0.00014, 'epoch': 0.04}\u001b[0m\n",
      "\u001b[34m1%|          | 8/720 [04:44<6:47:18, 34.32s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 9/720 [05:17<6:44:57, 34.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.5184, 'learning_rate': 0.00016, 'epoch': 0.05}\u001b[0m\n",
      "\u001b[34m1%|▏         | 9/720 [05:17<6:44:57, 34.17s/it]\u001b[0m\n",
      "\u001b[34m1%|▏         | 10/720 [05:51<6:43:10, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.339, 'learning_rate': 0.00018, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34m1%|▏         | 10/720 [05:51<6:43:10, 34.07s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 11/720 [06:25<6:41:47, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1959, 'learning_rate': 0.0002, 'epoch': 0.06}\u001b[0m\n",
      "\u001b[34m2%|▏         | 11/720 [06:25<6:41:47, 34.00s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 12/720 [06:59<6:40:40, 33.96s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1777, 'learning_rate': 0.00019971830985915495, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34m2%|▏         | 12/720 [06:59<6:40:40, 33.96s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 13/720 [07:33<6:39:42, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1664, 'learning_rate': 0.00019943661971830986, 'epoch': 0.07}\u001b[0m\n",
      "\u001b[34m2%|▏         | 13/720 [07:33<6:39:42, 33.92s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 14/720 [08:07<6:38:50, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1539, 'learning_rate': 0.0001991549295774648, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m2%|▏         | 14/720 [08:07<6:38:50, 33.90s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 15/720 [08:40<6:38:05, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.166, 'learning_rate': 0.00019887323943661972, 'epoch': 0.08}\u001b[0m\n",
      "\u001b[34m2%|▏         | 15/720 [08:40<6:38:05, 33.88s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/720 [09:14<6:37:25, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.139, 'learning_rate': 0.00019859154929577466, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m2%|▏         | 16/720 [09:14<6:37:25, 33.87s/it]\u001b[0m\n",
      "\u001b[34m2%|▏         | 17/720 [09:48<6:36:46, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1331, 'learning_rate': 0.0001983098591549296, 'epoch': 0.09}\u001b[0m\n",
      "\u001b[34m2%|▏         | 17/720 [09:48<6:36:46, 33.86s/it]\u001b[0m\n",
      "\u001b[34m2%|▎         | 18/720 [10:22<6:36:09, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1261, 'learning_rate': 0.00019802816901408452, 'epoch': 0.1}\u001b[0m\n",
      "\u001b[34m2%|▎         | 18/720 [10:22<6:36:09, 33.86s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 19/720 [10:56<6:35:33, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.118, 'learning_rate': 0.00019774647887323946, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34m3%|▎         | 19/720 [10:56<6:35:33, 33.86s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 20/720 [11:30<6:35:00, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1199, 'learning_rate': 0.00019746478873239437, 'epoch': 0.11}\u001b[0m\n",
      "\u001b[34m3%|▎         | 20/720 [11:30<6:35:00, 33.86s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 21/720 [12:04<6:34:23, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1112, 'learning_rate': 0.0001971830985915493, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m3%|▎         | 21/720 [12:04<6:34:23, 33.85s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 22/720 [12:37<6:33:48, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1066, 'learning_rate': 0.00019690140845070423, 'epoch': 0.12}\u001b[0m\n",
      "\u001b[34m3%|▎         | 22/720 [12:37<6:33:48, 33.85s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 23/720 [13:11<6:33:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.094, 'learning_rate': 0.00019661971830985917, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m3%|▎         | 23/720 [13:11<6:33:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 24/720 [13:45<6:32:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.096, 'learning_rate': 0.0001963380281690141, 'epoch': 0.13}\u001b[0m\n",
      "\u001b[34m3%|▎         | 24/720 [13:45<6:32:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m3%|▎         | 25/720 [14:19<6:32:02, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.1038, 'learning_rate': 0.00019605633802816902, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m3%|▎         | 25/720 [14:19<6:32:02, 33.85s/it]\u001b[0m\n",
      "\u001b[34m4%|▎         | 26/720 [14:53<6:31:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0935, 'learning_rate': 0.00019577464788732396, 'epoch': 0.14}\u001b[0m\n",
      "\u001b[34m4%|▎         | 26/720 [14:53<6:31:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 27/720 [15:27<6:30:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0962, 'learning_rate': 0.00019549295774647888, 'epoch': 0.15}\u001b[0m\n",
      "\u001b[34m4%|▍         | 27/720 [15:27<6:30:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 28/720 [16:00<6:30:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0953, 'learning_rate': 0.00019521126760563382, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m4%|▍         | 28/720 [16:00<6:30:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 29/720 [16:34<6:29:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0827, 'learning_rate': 0.00019492957746478876, 'epoch': 0.16}\u001b[0m\n",
      "\u001b[34m4%|▍         | 29/720 [16:34<6:29:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 30/720 [17:08<6:29:11, 33.84s/it]\u001b[0m\n",
      "\u001b[34m4%|▍         | 30/720 [17:08<6:29:11, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0982, 'learning_rate': 0.00019464788732394367, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34m4%|▍         | 31/720 [17:42<6:28:36, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.086, 'learning_rate': 0.00019436619718309861, 'epoch': 0.17}\u001b[0m\n",
      "\u001b[34m4%|▍         | 31/720 [17:42<6:28:36, 33.84s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m4%|▍         | 32/720 [18:16<6:28:03, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0889, 'learning_rate': 0.00019408450704225353, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m4%|▍         | 32/720 [18:16<6:28:03, 33.84s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 33/720 [18:50<6:27:30, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0806, 'learning_rate': 0.00019380281690140847, 'epoch': 0.18}\u001b[0m\n",
      "\u001b[34m5%|▍         | 33/720 [18:50<6:27:30, 33.84s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 34/720 [19:23<6:26:55, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0699, 'learning_rate': 0.0001935211267605634, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m5%|▍         | 34/720 [19:23<6:26:55, 33.84s/it]\u001b[0m\n",
      "\u001b[34m5%|▍         | 35/720 [19:57<6:26:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.078, 'learning_rate': 0.00019323943661971832, 'epoch': 0.19}\u001b[0m\n",
      "\u001b[34m5%|▍         | 35/720 [19:57<6:26:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 36/720 [20:31<6:25:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0793, 'learning_rate': 0.00019295774647887326, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m5%|▌         | 36/720 [20:31<6:25:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:03,341] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:03,349] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:03,349] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:03,353] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:05,849] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:05,849] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:08,411] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:10,974] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:13,535] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:10:16,128] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.06627684831619263, 'eval_runtime': 12.8839, 'eval_samples_per_second': 61.006, 'eval_steps_per_second': 30.503, 'epoch': 0.2}\u001b[0m\n",
      "\u001b[34m5%|▌         | 36/720 [20:44<6:25:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 37/720 [21:18<7:09:15, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0719, 'learning_rate': 0.00019267605633802818, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m5%|▌         | 37/720 [21:18<7:09:15, 37.71s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 38/720 [21:52<6:55:27, 36.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0692, 'learning_rate': 0.00019239436619718312, 'epoch': 0.21}\u001b[0m\n",
      "\u001b[34m5%|▌         | 38/720 [21:52<6:55:27, 36.55s/it]\u001b[0m\n",
      "\u001b[34m5%|▌         | 39/720 [22:26<6:45:38, 35.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0785, 'learning_rate': 0.00019211267605633806, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34m5%|▌         | 39/720 [22:26<6:45:38, 35.74s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 40/720 [22:59<6:38:34, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0673, 'learning_rate': 0.00019183098591549297, 'epoch': 0.22}\u001b[0m\n",
      "\u001b[34m6%|▌         | 40/720 [22:59<6:38:34, 35.17s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 41/720 [23:33<6:33:28, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0731, 'learning_rate': 0.0001915492957746479, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34m6%|▌         | 41/720 [23:33<6:33:28, 34.77s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 42/720 [24:07<6:29:43, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0625, 'learning_rate': 0.0001912676056338028, 'epoch': 0.23}\u001b[0m\n",
      "\u001b[34m6%|▌         | 42/720 [24:07<6:29:43, 34.49s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 43/720 [24:41<6:26:56, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0665, 'learning_rate': 0.00019098591549295774, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34m6%|▌         | 43/720 [24:41<6:26:56, 34.29s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 44/720 [25:15<6:24:50, 34.16s/it]\u001b[0m\n",
      "\u001b[34m6%|▌         | 44/720 [25:15<6:24:50, 34.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0566, 'learning_rate': 0.00019070422535211268, 'epoch': 0.24}\u001b[0m\n",
      "\u001b[34m6%|▋         | 45/720 [25:49<6:23:12, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.071, 'learning_rate': 0.0001904225352112676, 'epoch': 0.25}\u001b[0m\n",
      "\u001b[34m6%|▋         | 45/720 [25:49<6:23:12, 34.06s/it]\u001b[0m\n",
      "\u001b[34m6%|▋         | 46/720 [26:22<6:21:54, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0643, 'learning_rate': 0.00019014084507042254, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34m6%|▋         | 46/720 [26:22<6:21:54, 34.00s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 47/720 [26:56<6:20:50, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0623, 'learning_rate': 0.00018985915492957745, 'epoch': 0.26}\u001b[0m\n",
      "\u001b[34m7%|▋         | 47/720 [26:56<6:20:50, 33.95s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 48/720 [27:30<6:19:58, 33.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0604, 'learning_rate': 0.0001895774647887324, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m7%|▋         | 48/720 [27:30<6:19:58, 33.93s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 49/720 [28:04<6:19:08, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0539, 'learning_rate': 0.00018929577464788734, 'epoch': 0.27}\u001b[0m\n",
      "\u001b[34m7%|▋         | 49/720 [28:04<6:19:08, 33.90s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 50/720 [28:38<6:18:23, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0498, 'learning_rate': 0.00018901408450704225, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m7%|▋         | 50/720 [28:38<6:18:23, 33.89s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 51/720 [29:12<6:17:40, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0538, 'learning_rate': 0.0001887323943661972, 'epoch': 0.28}\u001b[0m\n",
      "\u001b[34m7%|▋         | 51/720 [29:12<6:17:40, 33.87s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 52/720 [29:46<6:17:00, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0596, 'learning_rate': 0.0001884507042253521, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m7%|▋         | 52/720 [29:46<6:17:00, 33.86s/it]\u001b[0m\n",
      "\u001b[34m7%|▋         | 53/720 [30:19<6:16:22, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0443, 'learning_rate': 0.00018816901408450705, 'epoch': 0.29}\u001b[0m\n",
      "\u001b[34m7%|▋         | 53/720 [30:19<6:16:22, 33.86s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 54/720 [30:53<6:15:47, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0589, 'learning_rate': 0.000187887323943662, 'epoch': 0.3}\u001b[0m\n",
      "\u001b[34m8%|▊         | 54/720 [30:53<6:15:47, 33.86s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 55/720 [31:27<6:15:09, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.048, 'learning_rate': 0.0001876056338028169, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34m8%|▊         | 55/720 [31:27<6:15:09, 33.85s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 56/720 [32:01<6:14:34, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0386, 'learning_rate': 0.00018732394366197184, 'epoch': 0.31}\u001b[0m\n",
      "\u001b[34m8%|▊         | 56/720 [32:01<6:14:34, 33.85s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 57/720 [32:35<6:14:00, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0441, 'learning_rate': 0.00018704225352112676, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34m8%|▊         | 57/720 [32:35<6:14:00, 33.85s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 58/720 [33:09<6:13:23, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0362, 'learning_rate': 0.0001867605633802817, 'epoch': 0.32}\u001b[0m\n",
      "\u001b[34m8%|▊         | 58/720 [33:09<6:13:23, 33.84s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 59/720 [33:42<6:12:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0437, 'learning_rate': 0.0001864788732394366, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m8%|▊         | 59/720 [33:42<6:12:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 60/720 [34:16<6:12:16, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0474, 'learning_rate': 0.00018619718309859155, 'epoch': 0.33}\u001b[0m\n",
      "\u001b[34m8%|▊         | 60/720 [34:16<6:12:16, 33.84s/it]\u001b[0m\n",
      "\u001b[34m8%|▊         | 61/720 [34:50<6:11:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0463, 'learning_rate': 0.0001859154929577465, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34m8%|▊         | 61/720 [34:50<6:11:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▊         | 62/720 [35:24<6:11:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0471, 'learning_rate': 0.0001856338028169014, 'epoch': 0.34}\u001b[0m\n",
      "\u001b[34m9%|▊         | 62/720 [35:24<6:11:07, 33.84s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m9%|▉         | 63/720 [35:58<6:10:31, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0349, 'learning_rate': 0.00018535211267605635, 'epoch': 0.35}\u001b[0m\n",
      "\u001b[34m9%|▉         | 63/720 [35:58<6:10:31, 33.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 64/720 [36:32<6:09:57, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.04, 'learning_rate': 0.00018507042253521126, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m9%|▉         | 64/720 [36:32<6:09:57, 33.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 65/720 [37:05<6:09:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0367, 'learning_rate': 0.0001847887323943662, 'epoch': 0.36}\u001b[0m\n",
      "\u001b[34m9%|▉         | 65/720 [37:05<6:09:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 66/720 [37:39<6:08:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0442, 'learning_rate': 0.00018450704225352114, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m9%|▉         | 66/720 [37:39<6:08:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 67/720 [38:13<6:08:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0381, 'learning_rate': 0.00018422535211267606, 'epoch': 0.37}\u001b[0m\n",
      "\u001b[34m9%|▉         | 67/720 [38:13<6:08:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m9%|▉         | 68/720 [38:47<6:07:47, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0408, 'learning_rate': 0.000183943661971831, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m9%|▉         | 68/720 [38:47<6:07:47, 33.85s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 69/720 [39:21<6:07:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0372, 'learning_rate': 0.0001836619718309859, 'epoch': 0.38}\u001b[0m\n",
      "\u001b[34m10%|▉         | 69/720 [39:21<6:07:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 70/720 [39:55<6:06:40, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0383, 'learning_rate': 0.00018338028169014085, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m10%|▉         | 70/720 [39:55<6:06:40, 33.85s/it]\u001b[0m\n",
      "\u001b[34m10%|▉         | 71/720 [40:29<6:06:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0487, 'learning_rate': 0.0001830985915492958, 'epoch': 0.39}\u001b[0m\n",
      "\u001b[34m10%|▉         | 71/720 [40:29<6:06:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 72/720 [41:02<6:05:31, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0437, 'learning_rate': 0.0001828169014084507, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m10%|█         | 72/720 [41:02<6:05:31, 33.85s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:34,575] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:34,583] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:34,583] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:34,587] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:37,081] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:37,082] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:39,644] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:42,206] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:44,768] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:30:47,361] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.03387169539928436, 'eval_runtime': 12.883, 'eval_samples_per_second': 61.011, 'eval_steps_per_second': 30.505, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m10%|█         | 72/720 [41:15<6:05:31, 33.85s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 73/720 [41:49<6:46:39, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0466, 'learning_rate': 0.00018253521126760565, 'epoch': 0.4}\u001b[0m\n",
      "\u001b[34m10%|█         | 73/720 [41:49<6:46:39, 37.71s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 74/720 [42:23<6:33:31, 36.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0387, 'learning_rate': 0.00018225352112676056, 'epoch': 0.41}\u001b[0m\n",
      "\u001b[34m10%|█         | 74/720 [42:23<6:33:31, 36.55s/it]\u001b[0m\n",
      "\u001b[34m10%|█         | 75/720 [42:57<6:24:09, 35.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0434, 'learning_rate': 0.0001819718309859155, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m10%|█         | 75/720 [42:57<6:24:09, 35.74s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 76/720 [43:31<6:17:29, 35.17s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 76/720 [43:31<6:17:29, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0433, 'learning_rate': 0.00018169014084507045, 'epoch': 0.42}\u001b[0m\n",
      "\u001b[34m11%|█         | 77/720 [44:05<6:12:49, 34.79s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0394, 'learning_rate': 0.00018140845070422536, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m11%|█         | 77/720 [44:05<6:12:49, 34.79s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 78/720 [44:38<6:09:15, 34.51s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0445, 'learning_rate': 0.0001811267605633803, 'epoch': 0.43}\u001b[0m\n",
      "\u001b[34m11%|█         | 78/720 [44:38<6:09:15, 34.51s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 79/720 [45:12<6:06:32, 34.31s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0305, 'learning_rate': 0.00018084507042253522, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34m11%|█         | 79/720 [45:12<6:06:32, 34.31s/it]\u001b[0m\n",
      "\u001b[34m11%|█         | 80/720 [45:46<6:04:27, 34.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0427, 'learning_rate': 0.00018056338028169016, 'epoch': 0.44}\u001b[0m\n",
      "\u001b[34m11%|█         | 80/720 [45:46<6:04:27, 34.17s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 81/720 [46:20<6:02:48, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0378, 'learning_rate': 0.00018028169014084507, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m11%|█▏        | 81/720 [46:20<6:02:48, 34.07s/it]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 82/720 [46:54<6:01:30, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0419, 'learning_rate': 0.00018, 'epoch': 0.45}\u001b[0m\n",
      "\u001b[34m11%|█▏        | 82/720 [46:54<6:01:30, 34.00s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 83/720 [47:28<6:00:26, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.031, 'learning_rate': 0.00017971830985915495, 'epoch': 0.46}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 83/720 [47:28<6:00:26, 33.95s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 84/720 [48:01<5:59:32, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0363, 'learning_rate': 0.00017943661971830987, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 84/720 [48:01<5:59:32, 33.92s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 85/720 [48:35<5:58:43, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0276, 'learning_rate': 0.0001791549295774648, 'epoch': 0.47}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 85/720 [48:35<5:58:43, 33.90s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 86/720 [49:09<5:57:58, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0366, 'learning_rate': 0.00017887323943661972, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 86/720 [49:09<5:57:58, 33.88s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 87/720 [49:43<5:57:18, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0311, 'learning_rate': 0.00017859154929577466, 'epoch': 0.48}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 87/720 [49:43<5:57:18, 33.87s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 88/720 [50:17<5:56:41, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0305, 'learning_rate': 0.0001783098591549296, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 88/720 [50:17<5:56:41, 33.86s/it]\u001b[0m\n",
      "\u001b[34m12%|█▏        | 89/720 [50:51<5:56:03, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0367, 'learning_rate': 0.00017802816901408452, 'epoch': 0.49}\u001b[0m\n",
      "\u001b[34m12%|█▏        | 89/720 [50:51<5:56:03, 33.86s/it]\u001b[0m\n",
      "\u001b[34m12%|█▎        | 90/720 [51:25<5:55:26, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0338, 'learning_rate': 0.00017774647887323946, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m12%|█▎        | 90/720 [51:25<5:55:26, 33.85s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 91/720 [51:58<5:54:51, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.033, 'learning_rate': 0.00017746478873239437, 'epoch': 0.5}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 91/720 [51:58<5:54:51, 33.85s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 92/720 [52:32<5:54:17, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0314, 'learning_rate': 0.0001771830985915493, 'epoch': 0.51}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 92/720 [52:32<5:54:17, 33.85s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m13%|█▎        | 93/720 [53:06<5:53:44, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0389, 'learning_rate': 0.00017690140845070425, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 93/720 [53:06<5:53:44, 33.85s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 94/720 [53:40<5:53:08, 33.85s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 94/720 [53:40<5:53:08, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0354, 'learning_rate': 0.00017661971830985917, 'epoch': 0.52}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 95/720 [54:14<5:52:32, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.037, 'learning_rate': 0.0001763380281690141, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 95/720 [54:14<5:52:32, 33.84s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 96/720 [54:48<5:52:00, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0303, 'learning_rate': 0.00017605633802816902, 'epoch': 0.53}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 96/720 [54:48<5:52:00, 33.85s/it]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 97/720 [55:21<5:51:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0368, 'learning_rate': 0.00017577464788732396, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m13%|█▎        | 97/720 [55:21<5:51:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 98/720 [55:55<5:50:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▎        | 98/720 [55:55<5:50:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0344, 'learning_rate': 0.0001754929577464789, 'epoch': 0.54}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 99/720 [56:29<5:50:18, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0334, 'learning_rate': 0.00017521126760563382, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 99/720 [56:29<5:50:18, 33.85s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 100/720 [57:03<5:49:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0316, 'learning_rate': 0.00017492957746478873, 'epoch': 0.55}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 100/720 [57:03<5:49:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 101/720 [57:37<5:49:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.03, 'learning_rate': 0.00017464788732394365, 'epoch': 0.56}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 101/720 [57:37<5:49:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 102/720 [58:11<5:48:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0356, 'learning_rate': 0.0001743661971830986, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 102/720 [58:11<5:48:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 103/720 [58:45<5:48:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0309, 'learning_rate': 0.00017408450704225353, 'epoch': 0.57}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 103/720 [58:45<5:48:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 104/720 [59:18<5:47:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0306, 'learning_rate': 0.00017380281690140844, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m14%|█▍        | 104/720 [59:18<5:47:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 105/720 [59:52<5:46:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0313, 'learning_rate': 0.00017352112676056338, 'epoch': 0.58}\u001b[0m\n",
      "\u001b[34m15%|█▍        | 105/720 [59:52<5:46:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 106/720 [1:00:26<5:46:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0369, 'learning_rate': 0.0001732394366197183, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34m15%|█▍        | 106/720 [1:00:26<5:46:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m15%|█▍        | 107/720 [1:01:00<5:45:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0423, 'learning_rate': 0.00017295774647887324, 'epoch': 0.59}\u001b[0m\n",
      "\u001b[34m15%|█▍        | 107/720 [1:01:00<5:45:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 108/720 [1:01:34<5:45:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0314, 'learning_rate': 0.00017267605633802818, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 108/720 [1:01:34<5:45:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:05,845] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:05,853] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:05,853] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:05,857] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:08,351] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:08,351] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:10,914] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:13,476] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:16,038] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 17:51:18,630] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.02781844139099121, 'eval_runtime': 12.8826, 'eval_samples_per_second': 61.012, 'eval_steps_per_second': 30.506, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 108/720 [1:01:47<5:45:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 109/720 [1:02:20<6:23:53, 37.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.033, 'learning_rate': 0.0001723943661971831, 'epoch': 0.6}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 109/720 [1:02:20<6:23:53, 37.70s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 110/720 [1:02:54<6:11:29, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0403, 'learning_rate': 0.00017211267605633804, 'epoch': 0.61}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 110/720 [1:02:54<6:11:29, 36.54s/it]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 111/720 [1:03:28<6:02:42, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0414, 'learning_rate': 0.00017183098591549295, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m15%|█▌        | 111/720 [1:03:28<6:02:42, 35.73s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 112/720 [1:04:02<5:56:20, 35.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.034, 'learning_rate': 0.0001715492957746479, 'epoch': 0.62}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 112/720 [1:04:02<5:56:20, 35.16s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 113/720 [1:04:36<5:51:45, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0264, 'learning_rate': 0.00017126760563380283, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 113/720 [1:04:36<5:51:45, 34.77s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 114/720 [1:05:10<5:48:22, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0279, 'learning_rate': 0.00017098591549295775, 'epoch': 0.63}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 114/720 [1:05:10<5:48:22, 34.49s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 115/720 [1:05:43<5:45:49, 34.30s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0354, 'learning_rate': 0.0001707042253521127, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 115/720 [1:05:43<5:45:49, 34.30s/it]\u001b[0m\n",
      "\u001b[34m16%|█▌        | 116/720 [1:06:17<5:43:52, 34.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.028, 'learning_rate': 0.0001704225352112676, 'epoch': 0.64}\u001b[0m\n",
      "\u001b[34m16%|█▌        | 116/720 [1:06:17<5:43:52, 34.16s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 117/720 [1:06:51<5:42:21, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0332, 'learning_rate': 0.00017014084507042254, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m16%|█▋        | 117/720 [1:06:51<5:42:21, 34.07s/it]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 118/720 [1:07:25<5:41:08, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0322, 'learning_rate': 0.00016985915492957746, 'epoch': 0.65}\u001b[0m\n",
      "\u001b[34m16%|█▋        | 118/720 [1:07:25<5:41:08, 34.00s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 119/720 [1:07:59<5:40:04, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0373, 'learning_rate': 0.0001695774647887324, 'epoch': 0.66}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 119/720 [1:07:59<5:40:04, 33.95s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 120/720 [1:08:33<5:39:11, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0273, 'learning_rate': 0.00016929577464788734, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 120/720 [1:08:33<5:39:11, 33.92s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 121/720 [1:09:07<5:38:22, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.031, 'learning_rate': 0.00016901408450704225, 'epoch': 0.67}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 121/720 [1:09:07<5:38:22, 33.89s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 122/720 [1:09:40<5:37:38, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0339, 'learning_rate': 0.0001687323943661972, 'epoch': 0.68}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 122/720 [1:09:40<5:37:38, 33.88s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m17%|█▋        | 123/720 [1:10:14<5:36:58, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0275, 'learning_rate': 0.0001684507042253521, 'epoch': 0.68}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 123/720 [1:10:14<5:36:58, 33.87s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 124/720 [1:10:48<5:36:20, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0223, 'learning_rate': 0.00016816901408450705, 'epoch': 0.69}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 124/720 [1:10:48<5:36:20, 33.86s/it]\u001b[0m\n",
      "\u001b[34m17%|█▋        | 125/720 [1:11:22<5:35:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0262, 'learning_rate': 0.000167887323943662, 'epoch': 0.69}\u001b[0m\n",
      "\u001b[34m17%|█▋        | 125/720 [1:11:22<5:35:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 126/720 [1:11:56<5:35:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0268, 'learning_rate': 0.0001676056338028169, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 126/720 [1:11:56<5:35:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 127/720 [1:12:30<5:34:32, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0351, 'learning_rate': 0.00016732394366197184, 'epoch': 0.7}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 127/720 [1:12:30<5:34:32, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 128/720 [1:13:03<5:33:56, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 128/720 [1:13:03<5:33:56, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.029, 'learning_rate': 0.00016704225352112676, 'epoch': 0.71}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 129/720 [1:13:37<5:33:23, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0299, 'learning_rate': 0.0001667605633802817, 'epoch': 0.72}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 129/720 [1:13:37<5:33:23, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 130/720 [1:14:11<5:32:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0285, 'learning_rate': 0.00016647887323943664, 'epoch': 0.72}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 130/720 [1:14:11<5:32:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 131/720 [1:14:45<5:32:16, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 131/720 [1:14:45<5:32:16, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0278, 'learning_rate': 0.00016619718309859155, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 132/720 [1:15:19<5:31:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0248, 'learning_rate': 0.0001659154929577465, 'epoch': 0.73}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 132/720 [1:15:19<5:31:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 133/720 [1:15:53<5:31:10, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.03, 'learning_rate': 0.0001656338028169014, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m18%|█▊        | 133/720 [1:15:53<5:31:10, 33.85s/it]\u001b[0m\n",
      "\u001b[34m19%|█▊        | 134/720 [1:16:26<5:30:34, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0276, 'learning_rate': 0.00016535211267605635, 'epoch': 0.74}\u001b[0m\n",
      "\u001b[34m19%|█▊        | 134/720 [1:16:26<5:30:34, 33.85s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 135/720 [1:17:00<5:30:00, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0325, 'learning_rate': 0.0001650704225352113, 'epoch': 0.75}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 135/720 [1:17:00<5:30:00, 33.85s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 136/720 [1:17:34<5:29:25, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0249, 'learning_rate': 0.0001647887323943662, 'epoch': 0.75}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 136/720 [1:17:34<5:29:25, 33.84s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 137/720 [1:18:08<5:28:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0335, 'learning_rate': 0.00016450704225352115, 'epoch': 0.76}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 137/720 [1:18:08<5:28:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 138/720 [1:18:42<5:28:15, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0314, 'learning_rate': 0.00016422535211267606, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 138/720 [1:18:42<5:28:15, 33.84s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 139/720 [1:19:16<5:27:41, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0256, 'learning_rate': 0.000163943661971831, 'epoch': 0.77}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 139/720 [1:19:16<5:27:41, 33.84s/it]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 140/720 [1:19:50<5:27:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0337, 'learning_rate': 0.00016366197183098591, 'epoch': 0.78}\u001b[0m\n",
      "\u001b[34m19%|█▉        | 140/720 [1:19:50<5:27:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 141/720 [1:20:23<5:26:31, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0217, 'learning_rate': 0.00016338028169014086, 'epoch': 0.78}\u001b[0m\n",
      "\u001b[34m20%|█▉        | 141/720 [1:20:23<5:26:31, 33.84s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 142/720 [1:20:57<5:25:58, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0346, 'learning_rate': 0.0001630985915492958, 'epoch': 0.79}\u001b[0m\n",
      "\u001b[34m20%|█▉        | 142/720 [1:20:57<5:25:58, 33.84s/it]\u001b[0m\n",
      "\u001b[34m20%|█▉        | 143/720 [1:21:31<5:25:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0224, 'learning_rate': 0.0001628169014084507, 'epoch': 0.79}\u001b[0m\n",
      "\u001b[34m20%|█▉        | 143/720 [1:21:31<5:25:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 144/720 [1:22:05<5:24:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 0.00016253521126760565, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m20%|██        | 144/720 [1:22:05<5:24:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:37,056] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:37,064] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:37,064] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:37,068] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:39,563] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:39,564] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:42,126] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:44,688] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:47,250] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:11:49,843] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.02346746437251568, 'eval_runtime': 12.8843, 'eval_samples_per_second': 61.004, 'eval_steps_per_second': 30.502, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m20%|██        | 144/720 [1:22:18<5:24:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m#015100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 145/720 [1:22:52<6:01:23, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0252, 'learning_rate': 0.00016225352112676057, 'epoch': 0.8}\u001b[0m\n",
      "\u001b[34m20%|██        | 145/720 [1:22:52<6:01:23, 37.71s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 146/720 [1:23:25<5:49:38, 36.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.029, 'learning_rate': 0.0001619718309859155, 'epoch': 0.81}\u001b[0m\n",
      "\u001b[34m20%|██        | 146/720 [1:23:25<5:49:38, 36.55s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 147/720 [1:23:59<5:41:16, 35.74s/it]\u001b[0m\n",
      "\u001b[34m20%|██        | 147/720 [1:23:59<5:41:16, 35.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0284, 'learning_rate': 0.00016169014084507045, 'epoch': 0.82}\u001b[0m\n",
      "\u001b[34m21%|██        | 148/720 [1:24:33<5:35:15, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0291, 'learning_rate': 0.00016140845070422536, 'epoch': 0.82}\u001b[0m\n",
      "\u001b[34m21%|██        | 148/720 [1:24:33<5:35:15, 35.17s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 149/720 [1:25:07<5:30:53, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0315, 'learning_rate': 0.0001611267605633803, 'epoch': 0.83}\u001b[0m\n",
      "\u001b[34m21%|██        | 149/720 [1:25:07<5:30:53, 34.77s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 150/720 [1:25:41<5:27:39, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0316, 'learning_rate': 0.00016084507042253522, 'epoch': 0.83}\u001b[0m\n",
      "\u001b[34m21%|██        | 150/720 [1:25:41<5:27:39, 34.49s/it]\u001b[0m\n",
      "\u001b[34m21%|██        | 151/720 [1:26:15<5:25:16, 34.30s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0289, 'learning_rate': 0.00016056338028169016, 'epoch': 0.84}\u001b[0m\n",
      "\u001b[34m21%|██        | 151/720 [1:26:15<5:25:16, 34.30s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m21%|██        | 152/720 [1:26:49<5:23:23, 34.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0279, 'learning_rate': 0.0001602816901408451, 'epoch': 0.84}\u001b[0m\n",
      "\u001b[34m21%|██        | 152/720 [1:26:49<5:23:23, 34.16s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 153/720 [1:27:22<5:21:55, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0232, 'learning_rate': 0.00016, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m21%|██▏       | 153/720 [1:27:22<5:21:55, 34.07s/it]\u001b[0m\n",
      "\u001b[34m21%|██▏       | 154/720 [1:27:56<5:20:43, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0273, 'learning_rate': 0.00015971830985915495, 'epoch': 0.85}\u001b[0m\n",
      "\u001b[34m21%|██▏       | 154/720 [1:27:56<5:20:43, 34.00s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 155/720 [1:28:30<5:19:44, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0244, 'learning_rate': 0.00015943661971830987, 'epoch': 0.86}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 155/720 [1:28:30<5:19:44, 33.95s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 156/720 [1:29:04<5:18:51, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0279, 'learning_rate': 0.0001591549295774648, 'epoch': 0.87}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 156/720 [1:29:04<5:18:51, 33.92s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 157/720 [1:29:38<5:18:05, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0276, 'learning_rate': 0.00015887323943661972, 'epoch': 0.87}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 157/720 [1:29:38<5:18:05, 33.90s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 158/720 [1:30:12<5:17:21, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0282, 'learning_rate': 0.00015859154929577466, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 158/720 [1:30:12<5:17:21, 33.88s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 159/720 [1:30:45<5:16:41, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0212, 'learning_rate': 0.00015830985915492958, 'epoch': 0.88}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 159/720 [1:30:45<5:16:41, 33.87s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 160/720 [1:31:19<5:16:02, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0224, 'learning_rate': 0.0001580281690140845, 'epoch': 0.89}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 160/720 [1:31:19<5:16:02, 33.86s/it]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 161/720 [1:31:53<5:15:24, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0205, 'learning_rate': 0.00015774647887323943, 'epoch': 0.89}\u001b[0m\n",
      "\u001b[34m22%|██▏       | 161/720 [1:31:53<5:15:24, 33.85s/it]\u001b[0m\n",
      "\u001b[34m22%|██▎       | 162/720 [1:32:27<5:14:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0291, 'learning_rate': 0.00015746478873239437, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m22%|██▎       | 162/720 [1:32:27<5:14:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 163/720 [1:33:01<5:14:15, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0252, 'learning_rate': 0.0001571830985915493, 'epoch': 0.9}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 163/720 [1:33:01<5:14:15, 33.85s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 164/720 [1:33:35<5:13:41, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0236, 'learning_rate': 0.00015690140845070423, 'epoch': 0.91}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 164/720 [1:33:35<5:13:41, 33.85s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 165/720 [1:34:09<5:13:05, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0272, 'learning_rate': 0.00015661971830985914, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 165/720 [1:34:09<5:13:05, 33.85s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 166/720 [1:34:42<5:12:32, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0293, 'learning_rate': 0.00015633802816901408, 'epoch': 0.92}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 166/720 [1:34:42<5:12:32, 33.85s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 167/720 [1:35:16<5:11:56, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0319, 'learning_rate': 0.00015605633802816903, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 167/720 [1:35:16<5:11:56, 33.85s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 168/720 [1:35:50<5:11:21, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.028, 'learning_rate': 0.00015577464788732394, 'epoch': 0.93}\u001b[0m\n",
      "\u001b[34m23%|██▎       | 168/720 [1:35:50<5:11:21, 33.84s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 169/720 [1:36:24<5:10:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 169/720 [1:36:24<5:10:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0267, 'learning_rate': 0.00015549295774647888, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m24%|██▎       | 170/720 [1:36:58<5:10:13, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0251, 'learning_rate': 0.0001552112676056338, 'epoch': 0.94}\u001b[0m\n",
      "\u001b[34m24%|██▎       | 170/720 [1:36:58<5:10:13, 33.84s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 171/720 [1:37:32<5:09:40, 33.84s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 171/720 [1:37:32<5:09:40, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0246, 'learning_rate': 0.00015492957746478874, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 172/720 [1:38:05<5:09:08, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0259, 'learning_rate': 0.00015464788732394368, 'epoch': 0.95}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 172/720 [1:38:05<5:09:08, 33.85s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 173/720 [1:38:39<5:08:33, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0342, 'learning_rate': 0.0001543661971830986, 'epoch': 0.96}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 173/720 [1:38:39<5:08:33, 33.85s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 174/720 [1:39:13<5:07:59, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0258, 'learning_rate': 0.00015408450704225353, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 174/720 [1:39:13<5:07:59, 33.85s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 175/720 [1:39:47<5:07:25, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0271, 'learning_rate': 0.00015380281690140845, 'epoch': 0.97}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 175/720 [1:39:47<5:07:25, 33.84s/it]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 176/720 [1:40:21<5:06:49, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.025, 'learning_rate': 0.00015352112676056339, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[34m24%|██▍       | 176/720 [1:40:21<5:06:49, 33.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 177/720 [1:40:55<5:06:14, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0225, 'learning_rate': 0.0001532394366197183, 'epoch': 0.98}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 177/720 [1:40:55<5:06:14, 33.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 178/720 [1:41:28<5:05:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0313, 'learning_rate': 0.00015295774647887324, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 178/720 [1:41:28<5:05:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▍       | 179/720 [1:42:02<5:05:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0289, 'learning_rate': 0.00015267605633802818, 'epoch': 0.99}\u001b[0m\n",
      "\u001b[34m25%|██▍       | 179/720 [1:42:02<5:05:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 180/720 [1:42:36<5:04:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0248, 'learning_rate': 0.0001523943661971831, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 180/720 [1:42:36<5:04:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:08,297] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:08,306] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:08,306] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:08,311] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:10,811] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:10,812] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:13,374] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:15,937] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.82s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:18,499] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:32:21,090] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.02315068058669567, 'eval_runtime': 12.8913, 'eval_samples_per_second': 60.972, 'eval_steps_per_second': 30.486, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 180/720 [1:42:49<5:04:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:33:08,576] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:33:08,576] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:33:08,707] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 9b552f6299ea956339a049be965f47b35a071d052f4306f6fa9aef71df7c2145#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:33:09,067] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m25%|██▌       | 181/720 [1:44:02<7:25:08, 49.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0198, 'learning_rate': 0.00015211267605633804, 'epoch': 1.0}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 181/720 [1:44:02<7:25:08, 49.55s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 182/720 [1:44:36<6:42:02, 44.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.026, 'learning_rate': 0.00015183098591549295, 'epoch': 1.01}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 182/720 [1:44:36<6:42:02, 44.84s/it]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 183/720 [1:45:10<6:11:45, 41.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0188, 'learning_rate': 0.0001515492957746479, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m25%|██▌       | 183/720 [1:45:10<6:11:45, 41.54s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 184/720 [1:45:44<5:50:27, 39.23s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0212, 'learning_rate': 0.00015126760563380283, 'epoch': 1.02}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 184/720 [1:45:44<5:50:27, 39.23s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 185/720 [1:46:18<5:35:23, 37.61s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0287, 'learning_rate': 0.00015098591549295775, 'epoch': 1.03}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 185/720 [1:46:18<5:35:23, 37.61s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 186/720 [1:46:52<5:24:43, 36.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0231, 'learning_rate': 0.0001507042253521127, 'epoch': 1.03}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 186/720 [1:46:52<5:24:43, 36.49s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 187/720 [1:47:25<5:17:04, 35.69s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0236, 'learning_rate': 0.0001504225352112676, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 187/720 [1:47:25<5:17:04, 35.69s/it]\u001b[0m\n",
      "\u001b[34m26%|██▌       | 188/720 [1:47:59<5:11:33, 35.14s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0245, 'learning_rate': 0.00015014084507042254, 'epoch': 1.04}\u001b[0m\n",
      "\u001b[34m26%|██▌       | 188/720 [1:47:59<5:11:33, 35.14s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 189/720 [1:48:33<5:07:31, 34.75s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0187, 'learning_rate': 0.00014985915492957748, 'epoch': 1.05}\u001b[0m\n",
      "\u001b[34m26%|██▋       | 189/720 [1:48:33<5:07:31, 34.75s/it]\u001b[0m\n",
      "\u001b[34m26%|██▋       | 190/720 [1:49:07<5:04:32, 34.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0242, 'learning_rate': 0.0001495774647887324, 'epoch': 1.05}\u001b[0m\n",
      "\u001b[34m26%|██▋       | 190/720 [1:49:07<5:04:32, 34.48s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 191/720 [1:49:41<5:02:17, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0214, 'learning_rate': 0.00014929577464788734, 'epoch': 1.06}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 191/720 [1:49:41<5:02:17, 34.29s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 192/720 [1:50:15<5:00:33, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0214, 'learning_rate': 0.00014901408450704225, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 192/720 [1:50:15<5:00:33, 34.15s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 193/720 [1:50:48<4:59:09, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0281, 'learning_rate': 0.0001487323943661972, 'epoch': 1.07}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 193/720 [1:50:48<4:59:09, 34.06s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 194/720 [1:51:22<4:58:00, 33.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0246, 'learning_rate': 0.0001484507042253521, 'epoch': 1.08}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 194/720 [1:51:22<4:58:00, 33.99s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 195/720 [1:51:56<4:57:03, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.024, 'learning_rate': 0.00014816901408450705, 'epoch': 1.08}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 195/720 [1:51:56<4:57:03, 33.95s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 196/720 [1:52:30<4:56:15, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0249, 'learning_rate': 0.000147887323943662, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 196/720 [1:52:30<4:56:15, 33.92s/it]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 197/720 [1:53:04<4:55:28, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0233, 'learning_rate': 0.0001476056338028169, 'epoch': 1.09}\u001b[0m\n",
      "\u001b[34m27%|██▋       | 197/720 [1:53:04<4:55:28, 33.90s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 198/720 [1:53:38<4:54:48, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0228, 'learning_rate': 0.00014732394366197185, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 198/720 [1:53:38<4:54:48, 33.89s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 199/720 [1:54:12<4:54:07, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0192, 'learning_rate': 0.00014704225352112676, 'epoch': 1.1}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 199/720 [1:54:12<4:54:07, 33.87s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 200/720 [1:54:45<4:53:31, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0224, 'learning_rate': 0.0001467605633802817, 'epoch': 1.11}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 200/720 [1:54:45<4:53:31, 33.87s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 201/720 [1:55:19<4:52:54, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0185, 'learning_rate': 0.00014647887323943664, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 201/720 [1:55:19<4:52:54, 33.86s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 202/720 [1:55:53<4:52:17, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0235, 'learning_rate': 0.00014619718309859156, 'epoch': 1.12}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 202/720 [1:55:53<4:52:17, 33.86s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 203/720 [1:56:27<4:51:41, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0197, 'learning_rate': 0.0001459154929577465, 'epoch': 1.13}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 203/720 [1:56:27<4:51:41, 33.85s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 204/720 [1:57:01<4:51:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0254, 'learning_rate': 0.0001456338028169014, 'epoch': 1.13}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 204/720 [1:57:01<4:51:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 205/720 [1:57:35<4:50:30, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0229, 'learning_rate': 0.00014535211267605635, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m28%|██▊       | 205/720 [1:57:35<4:50:30, 33.85s/it]\u001b[0m\n",
      "\u001b[34m29%|██▊       | 206/720 [1:58:08<4:49:57, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0175, 'learning_rate': 0.0001450704225352113, 'epoch': 1.14}\u001b[0m\n",
      "\u001b[34m29%|██▊       | 206/720 [1:58:08<4:49:57, 33.85s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 207/720 [1:58:42<4:49:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0179, 'learning_rate': 0.0001447887323943662, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 207/720 [1:58:42<4:49:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 208/720 [1:59:16<4:48:47, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0221, 'learning_rate': 0.00014450704225352115, 'epoch': 1.15}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 208/720 [1:59:16<4:48:47, 33.84s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 209/720 [1:59:50<4:48:14, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0254, 'learning_rate': 0.00014422535211267606, 'epoch': 1.16}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 209/720 [1:59:50<4:48:14, 33.84s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 210/720 [2:00:24<4:47:39, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0222, 'learning_rate': 0.000143943661971831, 'epoch': 1.17}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 210/720 [2:00:24<4:47:39, 33.84s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 211/720 [2:00:58<4:47:05, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0267, 'learning_rate': 0.00014366197183098594, 'epoch': 1.17}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 211/720 [2:00:58<4:47:05, 33.84s/it]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 212/720 [2:01:32<4:46:30, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0215, 'learning_rate': 0.00014338028169014086, 'epoch': 1.18}\u001b[0m\n",
      "\u001b[34m29%|██▉       | 212/720 [2:01:32<4:46:30, 33.84s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 213/720 [2:02:05<4:45:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0191, 'learning_rate': 0.0001430985915492958, 'epoch': 1.18}\u001b[0m\n",
      "\u001b[34m30%|██▉       | 213/720 [2:02:05<4:45:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 214/720 [2:02:39<4:45:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0181, 'learning_rate': 0.0001428169014084507, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m30%|██▉       | 214/720 [2:02:39<4:45:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m30%|██▉       | 215/720 [2:03:13<4:44:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0194, 'learning_rate': 0.00014253521126760565, 'epoch': 1.19}\u001b[0m\n",
      "\u001b[34m30%|██▉       | 215/720 [2:03:13<4:44:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 216/720 [2:03:47<4:44:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0229, 'learning_rate': 0.00014225352112676057, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m30%|███       | 216/720 [2:03:47<4:44:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:19,034] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:19,041] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:19,042] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:19,046] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:21,540] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:21,541] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:24,103] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:26,665] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2023-10-28 18:53:29,228] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 18:53:31,820] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.02307100035250187, 'eval_runtime': 12.8835, 'eval_samples_per_second': 61.008, 'eval_steps_per_second': 30.504, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m30%|███       | 216/720 [2:04:00<4:44:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 217/720 [2:04:34<5:16:08, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0185, 'learning_rate': 0.0001419718309859155, 'epoch': 1.2}\u001b[0m\n",
      "\u001b[34m30%|███       | 217/720 [2:04:34<5:16:08, 37.71s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 218/720 [2:05:07<5:05:47, 36.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0197, 'learning_rate': 0.00014169014084507045, 'epoch': 1.21}\u001b[0m\n",
      "\u001b[34m30%|███       | 218/720 [2:05:07<5:05:47, 36.55s/it]\u001b[0m\n",
      "\u001b[34m30%|███       | 219/720 [2:05:41<4:58:24, 35.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0197, 'learning_rate': 0.00014140845070422534, 'epoch': 1.21}\u001b[0m\n",
      "\u001b[34m30%|███       | 219/720 [2:05:41<4:58:24, 35.74s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 220/720 [2:06:15<4:53:04, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 0.00014112676056338028, 'epoch': 1.22}\u001b[0m\n",
      "\u001b[34m31%|███       | 220/720 [2:06:15<4:53:04, 35.17s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 221/720 [2:06:49<4:49:09, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0259, 'learning_rate': 0.00014084507042253522, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m31%|███       | 221/720 [2:06:49<4:49:09, 34.77s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 222/720 [2:07:23<4:46:15, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0222, 'learning_rate': 0.00014056338028169013, 'epoch': 1.23}\u001b[0m\n",
      "\u001b[34m31%|███       | 222/720 [2:07:23<4:46:15, 34.49s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 223/720 [2:07:57<4:44:06, 34.30s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0237, 'learning_rate': 0.00014028169014084507, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m31%|███       | 223/720 [2:07:57<4:44:06, 34.30s/it]\u001b[0m\n",
      "\u001b[34m31%|███       | 224/720 [2:08:31<4:42:24, 34.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0221, 'learning_rate': 0.00014, 'epoch': 1.24}\u001b[0m\n",
      "\u001b[34m31%|███       | 224/720 [2:08:31<4:42:24, 34.16s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 225/720 [2:09:04<4:41:02, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0229, 'learning_rate': 0.00013971830985915493, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m31%|███▏      | 225/720 [2:09:04<4:41:02, 34.07s/it]\u001b[0m\n",
      "\u001b[34m31%|███▏      | 226/720 [2:09:38<4:39:55, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0211, 'learning_rate': 0.00013943661971830987, 'epoch': 1.25}\u001b[0m\n",
      "\u001b[34m31%|███▏      | 226/720 [2:09:38<4:39:55, 34.00s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 227/720 [2:10:12<4:38:57, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0215, 'learning_rate': 0.00013915492957746478, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 227/720 [2:10:12<4:38:57, 33.95s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 228/720 [2:10:46<4:38:08, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0259, 'learning_rate': 0.00013887323943661972, 'epoch': 1.26}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 228/720 [2:10:46<4:38:08, 33.92s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 229/720 [2:11:20<4:37:22, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0183, 'learning_rate': 0.00013859154929577464, 'epoch': 1.27}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 229/720 [2:11:20<4:37:22, 33.90s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 230/720 [2:11:54<4:36:40, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0239, 'learning_rate': 0.00013830985915492958, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 230/720 [2:11:54<4:36:40, 33.88s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 231/720 [2:12:27<4:36:01, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0201, 'learning_rate': 0.00013802816901408452, 'epoch': 1.28}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 231/720 [2:12:27<4:36:01, 33.87s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 232/720 [2:13:01<4:35:23, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0247, 'learning_rate': 0.00013774647887323943, 'epoch': 1.29}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 232/720 [2:13:01<4:35:23, 33.86s/it]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 233/720 [2:13:35<4:34:47, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0237, 'learning_rate': 0.00013746478873239438, 'epoch': 1.29}\u001b[0m\n",
      "\u001b[34m32%|███▏      | 233/720 [2:13:35<4:34:47, 33.85s/it]\u001b[0m\n",
      "\u001b[34m32%|███▎      | 234/720 [2:14:09<4:34:11, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0236, 'learning_rate': 0.0001371830985915493, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m32%|███▎      | 234/720 [2:14:09<4:34:11, 33.85s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 235/720 [2:14:43<4:33:36, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0249, 'learning_rate': 0.00013690140845070423, 'epoch': 1.3}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 235/720 [2:14:43<4:33:36, 33.85s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 236/720 [2:15:17<4:33:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0311, 'learning_rate': 0.00013661971830985914, 'epoch': 1.31}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 236/720 [2:15:17<4:33:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 237/720 [2:15:50<4:32:27, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0167, 'learning_rate': 0.00013633802816901409, 'epoch': 1.31}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 237/720 [2:15:50<4:32:27, 33.85s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 238/720 [2:16:24<4:31:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0232, 'learning_rate': 0.00013605633802816903, 'epoch': 1.32}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 238/720 [2:16:24<4:31:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 239/720 [2:16:58<4:31:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0233, 'learning_rate': 0.00013577464788732394, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 239/720 [2:16:58<4:31:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 240/720 [2:17:32<4:30:44, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0222, 'learning_rate': 0.00013549295774647888, 'epoch': 1.33}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 240/720 [2:17:32<4:30:44, 33.84s/it]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 241/720 [2:18:06<4:30:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0223, 'learning_rate': 0.0001352112676056338, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m33%|███▎      | 241/720 [2:18:06<4:30:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m34%|███▎      | 242/720 [2:18:40<4:29:36, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0234, 'learning_rate': 0.00013492957746478874, 'epoch': 1.34}\u001b[0m\n",
      "\u001b[34m34%|███▎      | 242/720 [2:18:40<4:29:36, 33.84s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 243/720 [2:19:13<4:29:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0241, 'learning_rate': 0.00013464788732394368, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 243/720 [2:19:13<4:29:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 244/720 [2:19:47<4:28:28, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0211, 'learning_rate': 0.0001343661971830986, 'epoch': 1.35}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 244/720 [2:19:47<4:28:28, 33.84s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 245/720 [2:20:21<4:27:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0201, 'learning_rate': 0.00013408450704225353, 'epoch': 1.36}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 245/720 [2:20:21<4:27:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 246/720 [2:20:55<4:27:23, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0236, 'learning_rate': 0.00013380281690140845, 'epoch': 1.36}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 246/720 [2:20:55<4:27:23, 33.85s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 247/720 [2:21:29<4:26:49, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0231, 'learning_rate': 0.0001335211267605634, 'epoch': 1.37}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 247/720 [2:21:29<4:26:49, 33.85s/it]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 248/720 [2:22:03<4:26:16, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0171, 'learning_rate': 0.00013323943661971833, 'epoch': 1.38}\u001b[0m\n",
      "\u001b[34m34%|███▍      | 248/720 [2:22:03<4:26:16, 33.85s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 249/720 [2:22:37<4:25:42, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0257, 'learning_rate': 0.00013295774647887324, 'epoch': 1.38}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 249/720 [2:22:37<4:25:42, 33.85s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 250/720 [2:23:10<4:25:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0209, 'learning_rate': 0.00013267605633802818, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 250/720 [2:23:10<4:25:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m35%|███▍      | 251/720 [2:23:44<4:24:32, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0217, 'learning_rate': 0.0001323943661971831, 'epoch': 1.39}\u001b[0m\n",
      "\u001b[34m35%|███▍      | 251/720 [2:23:44<4:24:32, 33.84s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 252/720 [2:24:18<4:24:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.022, 'learning_rate': 0.00013211267605633804, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m35%|███▌      | 252/720 [2:24:18<4:24:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:13:50,273] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:13:50,281] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:13:50,281] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:13:50,285] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:13:52,781] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:13:52,782] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2023-10-28 19:13:55,345] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:13:57,907] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.82s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:14:00,469] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:14:03,063] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.020420636981725693, 'eval_runtime': 12.8873, 'eval_samples_per_second': 60.99, 'eval_steps_per_second': 30.495, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m35%|███▌      | 252/720 [2:24:31<4:24:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 253/720 [2:25:05<4:53:32, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0253, 'learning_rate': 0.00013183098591549295, 'epoch': 1.4}\u001b[0m\n",
      "\u001b[34m35%|███▌      | 253/720 [2:25:05<4:53:32, 37.71s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 254/720 [2:25:39<4:43:53, 36.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 0.0001315492957746479, 'epoch': 1.41}\u001b[0m\n",
      "\u001b[34m35%|███▌      | 254/720 [2:25:39<4:43:53, 36.55s/it]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 255/720 [2:26:13<4:36:58, 35.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.021, 'learning_rate': 0.00013126760563380284, 'epoch': 1.41}\u001b[0m\n",
      "\u001b[34m35%|███▌      | 255/720 [2:26:13<4:36:58, 35.74s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 256/720 [2:26:46<4:32:00, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0248, 'learning_rate': 0.00013098591549295775, 'epoch': 1.42}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 256/720 [2:26:46<4:32:00, 35.17s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 257/720 [2:27:20<4:28:20, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0201, 'learning_rate': 0.0001307042253521127, 'epoch': 1.43}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 257/720 [2:27:20<4:28:20, 34.77s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 258/720 [2:27:54<4:25:36, 34.50s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0205, 'learning_rate': 0.0001304225352112676, 'epoch': 1.43}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 258/720 [2:27:54<4:25:36, 34.50s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 259/720 [2:28:28<4:23:31, 34.30s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0228, 'learning_rate': 0.00013014084507042255, 'epoch': 1.44}\u001b[0m\n",
      "\u001b[34m36%|███▌      | 259/720 [2:28:28<4:23:31, 34.30s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 260/720 [2:29:02<4:21:54, 34.16s/it]\u001b[0m\n",
      "\u001b[34m36%|███▌      | 260/720 [2:29:02<4:21:54, 34.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0188, 'learning_rate': 0.00012985915492957749, 'epoch': 1.44}\u001b[0m\n",
      "\u001b[34m36%|███▋      | 261/720 [2:29:36<4:20:36, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0241, 'learning_rate': 0.0001295774647887324, 'epoch': 1.45}\u001b[0m\n",
      "\u001b[34m36%|███▋      | 261/720 [2:29:36<4:20:36, 34.07s/it]\u001b[0m\n",
      "\u001b[34m36%|███▋      | 262/720 [2:30:09<4:19:30, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.019, 'learning_rate': 0.00012929577464788734, 'epoch': 1.45}\u001b[0m\n",
      "\u001b[34m36%|███▋      | 262/720 [2:30:09<4:19:30, 34.00s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 263/720 [2:30:43<4:18:34, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0234, 'learning_rate': 0.00012901408450704226, 'epoch': 1.46}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 263/720 [2:30:43<4:18:34, 33.95s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 264/720 [2:31:17<4:17:45, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0195, 'learning_rate': 0.0001287323943661972, 'epoch': 1.46}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 264/720 [2:31:17<4:17:45, 33.92s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 265/720 [2:31:51<4:17:00, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0219, 'learning_rate': 0.00012845070422535214, 'epoch': 1.47}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 265/720 [2:31:51<4:17:00, 33.89s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 266/720 [2:32:25<4:16:20, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0195, 'learning_rate': 0.00012816901408450705, 'epoch': 1.48}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 266/720 [2:32:25<4:16:20, 33.88s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 267/720 [2:32:59<4:15:43, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.02, 'learning_rate': 0.000127887323943662, 'epoch': 1.48}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 267/720 [2:32:59<4:15:43, 33.87s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 268/720 [2:33:32<4:15:04, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0249, 'learning_rate': 0.0001276056338028169, 'epoch': 1.49}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 268/720 [2:33:32<4:15:04, 33.86s/it]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 269/720 [2:34:06<4:14:31, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0219, 'learning_rate': 0.00012732394366197185, 'epoch': 1.49}\u001b[0m\n",
      "\u001b[34m37%|███▋      | 269/720 [2:34:06<4:14:31, 33.86s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 270/720 [2:34:40<4:13:53, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.02, 'learning_rate': 0.0001270422535211268, 'epoch': 1.5}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 270/720 [2:34:40<4:13:53, 33.85s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 271/720 [2:35:14<4:13:19, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0205, 'learning_rate': 0.0001267605633802817, 'epoch': 1.5}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 271/720 [2:35:14<4:13:19, 33.85s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 272/720 [2:35:48<4:12:45, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0228, 'learning_rate': 0.00012647887323943664, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 272/720 [2:35:48<4:12:45, 33.85s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 273/720 [2:36:22<4:12:11, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.02, 'learning_rate': 0.00012619718309859156, 'epoch': 1.51}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 273/720 [2:36:22<4:12:11, 33.85s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 274/720 [2:36:56<4:11:36, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0186, 'learning_rate': 0.0001259154929577465, 'epoch': 1.52}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 274/720 [2:36:56<4:11:36, 33.85s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 275/720 [2:37:29<4:11:04, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 0.0001256338028169014, 'epoch': 1.53}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 275/720 [2:37:29<4:11:04, 33.85s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 276/720 [2:38:03<4:10:30, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0209, 'learning_rate': 0.00012535211267605635, 'epoch': 1.53}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 276/720 [2:38:03<4:10:30, 33.85s/it]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 277/720 [2:38:37<4:09:54, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0223, 'learning_rate': 0.0001250704225352113, 'epoch': 1.54}\u001b[0m\n",
      "\u001b[34m38%|███▊      | 277/720 [2:38:37<4:09:54, 33.85s/it]\u001b[0m\n",
      "\u001b[34m39%|███▊      | 278/720 [2:39:11<4:09:19, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0192, 'learning_rate': 0.00012478873239436618, 'epoch': 1.54}\u001b[0m\n",
      "\u001b[34m39%|███▊      | 278/720 [2:39:11<4:09:19, 33.84s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 279/720 [2:39:45<4:08:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0271, 'learning_rate': 0.00012450704225352112, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 279/720 [2:39:45<4:08:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 280/720 [2:40:19<4:08:10, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0183, 'learning_rate': 0.00012422535211267606, 'epoch': 1.55}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 280/720 [2:40:19<4:08:10, 33.84s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 281/720 [2:40:52<4:07:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0279, 'learning_rate': 0.00012394366197183098, 'epoch': 1.56}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 281/720 [2:40:52<4:07:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 282/720 [2:41:26<4:07:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.02, 'learning_rate': 0.00012366197183098592, 'epoch': 1.56}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 282/720 [2:41:26<4:07:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 283/720 [2:42:00<4:06:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0175, 'learning_rate': 0.00012338028169014083, 'epoch': 1.57}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 283/720 [2:42:00<4:06:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 284/720 [2:42:34<4:05:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0217, 'learning_rate': 0.00012309859154929577, 'epoch': 1.58}\u001b[0m\n",
      "\u001b[34m39%|███▉      | 284/720 [2:42:34<4:05:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 285/720 [2:43:08<4:05:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0187, 'learning_rate': 0.00012281690140845071, 'epoch': 1.58}\u001b[0m\n",
      "\u001b[34m40%|███▉      | 285/720 [2:43:08<4:05:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 286/720 [2:43:42<4:04:44, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0264, 'learning_rate': 0.00012253521126760563, 'epoch': 1.59}\u001b[0m\n",
      "\u001b[34m40%|███▉      | 286/720 [2:43:42<4:04:44, 33.84s/it]\u001b[0m\n",
      "\u001b[34m40%|███▉      | 287/720 [2:44:15<4:04:10, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0202, 'learning_rate': 0.00012225352112676057, 'epoch': 1.59}\u001b[0m\n",
      "\u001b[34m40%|███▉      | 287/720 [2:44:15<4:04:10, 33.84s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m40%|████      | 288/720 [2:44:49<4:03:37, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0251, 'learning_rate': 0.0001219718309859155, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m40%|████      | 288/720 [2:44:49<4:03:37, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:21,485] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:21,493] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:21,493] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:21,497] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:23,993] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:23,993] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:26,554] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:29,117] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:31,678] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 19:34:34,271] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.01876789703965187, 'eval_runtime': 12.8829, 'eval_samples_per_second': 61.011, 'eval_steps_per_second': 30.506, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m40%|████      | 288/720 [2:45:02<4:03:37, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 289/720 [2:45:36<4:30:50, 37.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0216, 'learning_rate': 0.00012169014084507042, 'epoch': 1.6}\u001b[0m\n",
      "\u001b[34m40%|████      | 289/720 [2:45:36<4:30:50, 37.70s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 290/720 [2:46:10<4:21:54, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.023, 'learning_rate': 0.00012140845070422535, 'epoch': 1.61}\u001b[0m\n",
      "\u001b[34m40%|████      | 290/720 [2:46:10<4:21:54, 36.54s/it]\u001b[0m\n",
      "\u001b[34m40%|████      | 291/720 [2:46:44<4:15:29, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 0.00012112676056338028, 'epoch': 1.61}\u001b[0m\n",
      "\u001b[34m40%|████      | 291/720 [2:46:44<4:15:29, 35.73s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 292/720 [2:47:18<4:10:51, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0159, 'learning_rate': 0.00012084507042253521, 'epoch': 1.62}\u001b[0m\n",
      "\u001b[34m41%|████      | 292/720 [2:47:18<4:10:51, 35.17s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 293/720 [2:47:51<4:07:26, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0231, 'learning_rate': 0.00012056338028169015, 'epoch': 1.63}\u001b[0m\n",
      "\u001b[34m41%|████      | 293/720 [2:47:51<4:07:26, 34.77s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 294/720 [2:48:25<4:04:53, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.021, 'learning_rate': 0.00012028169014084508, 'epoch': 1.63}\u001b[0m\n",
      "\u001b[34m41%|████      | 294/720 [2:48:25<4:04:53, 34.49s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 295/720 [2:48:59<4:02:56, 34.30s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0271, 'learning_rate': 0.00012, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m41%|████      | 295/720 [2:48:59<4:02:56, 34.30s/it]\u001b[0m\n",
      "\u001b[34m41%|████      | 296/720 [2:49:33<4:01:23, 34.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0197, 'learning_rate': 0.00011971830985915493, 'epoch': 1.64}\u001b[0m\n",
      "\u001b[34m41%|████      | 296/720 [2:49:33<4:01:23, 34.16s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 297/720 [2:50:07<4:00:09, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0204, 'learning_rate': 0.00011943661971830986, 'epoch': 1.65}\u001b[0m\n",
      "\u001b[34m41%|████▏     | 297/720 [2:50:07<4:00:09, 34.07s/it]\u001b[0m\n",
      "\u001b[34m41%|████▏     | 298/720 [2:50:41<3:59:06, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0211, 'learning_rate': 0.00011915492957746479, 'epoch': 1.65}\u001b[0m\n",
      "\u001b[34m41%|████▏     | 298/720 [2:50:41<3:59:06, 34.00s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 299/720 [2:51:14<3:58:12, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0184, 'learning_rate': 0.00011887323943661973, 'epoch': 1.66}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 299/720 [2:51:14<3:58:12, 33.95s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 300/720 [2:51:48<3:57:24, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.02, 'learning_rate': 0.00011859154929577465, 'epoch': 1.66}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 300/720 [2:51:48<3:57:24, 33.92s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 301/720 [2:52:22<3:56:42, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0189, 'learning_rate': 0.00011830985915492958, 'epoch': 1.67}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 301/720 [2:52:22<3:56:42, 33.90s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 302/720 [2:52:56<3:56:02, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.017, 'learning_rate': 0.00011802816901408451, 'epoch': 1.68}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 302/720 [2:52:56<3:56:02, 33.88s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 303/720 [2:53:30<3:55:24, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 0.00011774647887323944, 'epoch': 1.68}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 303/720 [2:53:30<3:55:24, 33.87s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 304/720 [2:54:04<3:54:48, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0212, 'learning_rate': 0.00011746478873239436, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 304/720 [2:54:04<3:54:48, 33.87s/it]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 305/720 [2:54:38<3:54:11, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 0.0001171830985915493, 'epoch': 1.69}\u001b[0m\n",
      "\u001b[34m42%|████▏     | 305/720 [2:54:38<3:54:11, 33.86s/it]\u001b[0m\n",
      "\u001b[34m42%|████▎     | 306/720 [2:55:11<3:53:35, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0252, 'learning_rate': 0.00011690140845070423, 'epoch': 1.7}\u001b[0m\n",
      "\u001b[34m42%|████▎     | 306/720 [2:55:11<3:53:35, 33.85s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 307/720 [2:55:45<3:52:59, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0219, 'learning_rate': 0.00011661971830985916, 'epoch': 1.7}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 307/720 [2:55:45<3:52:59, 33.85s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 308/720 [2:56:19<3:52:23, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0206, 'learning_rate': 0.00011633802816901409, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 308/720 [2:56:19<3:52:23, 33.84s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 309/720 [2:56:53<3:51:49, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0204, 'learning_rate': 0.00011605633802816902, 'epoch': 1.71}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 309/720 [2:56:53<3:51:49, 33.84s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 310/720 [2:57:27<3:51:14, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0174, 'learning_rate': 0.00011577464788732396, 'epoch': 1.72}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 310/720 [2:57:27<3:51:14, 33.84s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 311/720 [2:58:01<3:50:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.024, 'learning_rate': 0.00011549295774647888, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 311/720 [2:58:01<3:50:42, 33.84s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 312/720 [2:58:34<3:50:08, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0257, 'learning_rate': 0.00011521126760563381, 'epoch': 1.73}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 312/720 [2:58:34<3:50:08, 33.84s/it]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 313/720 [2:59:08<3:49:34, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0216, 'learning_rate': 0.00011492957746478874, 'epoch': 1.74}\u001b[0m\n",
      "\u001b[34m43%|████▎     | 313/720 [2:59:08<3:49:34, 33.84s/it]\u001b[0m\n",
      "\u001b[34m44%|████▎     | 314/720 [2:59:42<3:49:00, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0255, 'learning_rate': 0.00011464788732394367, 'epoch': 1.74}\u001b[0m\n",
      "\u001b[34m44%|████▎     | 314/720 [2:59:42<3:49:00, 33.84s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 315/720 [3:00:16<3:48:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0196, 'learning_rate': 0.0001143661971830986, 'epoch': 1.75}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 315/720 [3:00:16<3:48:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 316/720 [3:00:50<3:47:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0208, 'learning_rate': 0.00011408450704225353, 'epoch': 1.75}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 316/720 [3:00:50<3:47:51, 33.84s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m44%|████▍     | 317/720 [3:01:24<3:47:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0222, 'learning_rate': 0.00011380281690140846, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 317/720 [3:01:24<3:47:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 318/720 [3:01:57<3:46:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0172, 'learning_rate': 0.00011352112676056339, 'epoch': 1.76}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 318/720 [3:01:57<3:46:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 319/720 [3:02:31<3:46:12, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.025, 'learning_rate': 0.00011323943661971832, 'epoch': 1.77}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 319/720 [3:02:31<3:46:12, 33.85s/it]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 320/720 [3:03:05<3:45:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0187, 'learning_rate': 0.00011295774647887324, 'epoch': 1.78}\u001b[0m\n",
      "\u001b[34m44%|████▍     | 320/720 [3:03:05<3:45:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 321/720 [3:03:39<3:45:03, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0224, 'learning_rate': 0.00011267605633802819, 'epoch': 1.78}\u001b[0m\n",
      "\u001b[34m45%|████▍     | 321/720 [3:03:39<3:45:03, 33.84s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 322/720 [3:04:13<3:44:30, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0235, 'learning_rate': 0.00011239436619718311, 'epoch': 1.79}\u001b[0m\n",
      "\u001b[34m45%|████▍     | 322/720 [3:04:13<3:44:30, 33.85s/it]\u001b[0m\n",
      "\u001b[34m45%|████▍     | 323/720 [3:04:47<3:43:55, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0191, 'learning_rate': 0.00011211267605633804, 'epoch': 1.79}\u001b[0m\n",
      "\u001b[34m45%|████▍     | 323/720 [3:04:47<3:43:55, 33.84s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 343/720 [3:16:16<3:32:40, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0182, 'learning_rate': 0.00010647887323943662, 'epoch': 1.9}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 343/720 [3:16:16<3:32:40, 33.85s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 344/720 [3:16:50<3:32:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0188, 'learning_rate': 0.00010619718309859155, 'epoch': 1.91}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 344/720 [3:16:50<3:32:06, 33.85s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 345/720 [3:17:24<3:31:32, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 0.00010591549295774647, 'epoch': 1.91}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 345/720 [3:17:24<3:31:32, 33.85s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 346/720 [3:17:58<3:30:58, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0159, 'learning_rate': 0.0001056338028169014, 'epoch': 1.92}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 346/720 [3:17:58<3:30:58, 33.85s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 347/720 [3:18:32<3:30:24, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0175, 'learning_rate': 0.00010535211267605634, 'epoch': 1.93}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 347/720 [3:18:32<3:30:24, 33.85s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 348/720 [3:19:06<3:29:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0206, 'learning_rate': 0.00010507042253521127, 'epoch': 1.93}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 348/720 [3:19:06<3:29:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 349/720 [3:19:40<3:29:16, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0184, 'learning_rate': 0.0001047887323943662, 'epoch': 1.94}\u001b[0m\n",
      "\u001b[34m48%|████▊     | 349/720 [3:19:40<3:29:16, 33.85s/it]\u001b[0m\n",
      "\u001b[34m49%|████▊     | 350/720 [3:20:13<3:28:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0209, 'learning_rate': 0.00010450704225352112, 'epoch': 1.94}\u001b[0m\n",
      "\u001b[34m49%|████▊     | 350/720 [3:20:13<3:28:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 351/720 [3:20:47<3:28:09, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0153, 'learning_rate': 0.00010422535211267605, 'epoch': 1.95}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 351/720 [3:20:47<3:28:09, 33.85s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 352/720 [3:21:21<3:27:35, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0166, 'learning_rate': 0.00010394366197183098, 'epoch': 1.95}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 352/720 [3:21:21<3:27:35, 33.85s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 353/720 [3:21:55<3:27:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0178, 'learning_rate': 0.00010366197183098592, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 353/720 [3:21:55<3:27:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 354/720 [3:22:29<3:26:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0213, 'learning_rate': 0.00010338028169014085, 'epoch': 1.96}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 354/720 [3:22:29<3:26:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 355/720 [3:23:03<3:25:52, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0164, 'learning_rate': 0.00010309859154929578, 'epoch': 1.97}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 355/720 [3:23:03<3:25:52, 33.84s/it]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 356/720 [3:23:36<3:25:19, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 0.0001028169014084507, 'epoch': 1.98}\u001b[0m\n",
      "\u001b[34m49%|████▉     | 356/720 [3:23:36<3:25:19, 33.85s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 357/720 [3:24:10<3:24:45, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0272, 'learning_rate': 0.00010253521126760563, 'epoch': 1.98}\u001b[0m\n",
      "\u001b[34m50%|████▉     | 357/720 [3:24:10<3:24:45, 33.85s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 358/720 [3:24:44<3:24:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0198, 'learning_rate': 0.00010225352112676057, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m50%|████▉     | 358/720 [3:24:44<3:24:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m50%|████▉     | 359/720 [3:25:18<3:23:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0153, 'learning_rate': 0.0001019718309859155, 'epoch': 1.99}\u001b[0m\n",
      "\u001b[34m50%|████▉     | 359/720 [3:25:18<3:23:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 360/720 [3:25:52<3:23:05, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0209, 'learning_rate': 0.00010169014084507043, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m50%|█████     | 360/720 [3:25:52<3:23:05, 33.85s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:23,996] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:24,006] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:24,006] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:24,010] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:26,512] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:26,512] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:29,074] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:31,636] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:34,198] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:15:36,791] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.01832692325115204, 'eval_runtime': 12.8919, 'eval_samples_per_second': 60.969, 'eval_steps_per_second': 30.484, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m50%|█████     | 360/720 [3:26:05<3:23:05, 33.85s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:16:31,936] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:16:31,936] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:16:31,960] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] cdd05fd5640bbcf0f6fc7859827f338d0828cd3f387436f5feea6fc61d622a4a#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:16:32,316] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m50%|█████     | 361/720 [3:27:17<4:54:54, 49.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0161, 'learning_rate': 0.00010140845070422535, 'epoch': 2.0}\u001b[0m\n",
      "\u001b[34m50%|█████     | 361/720 [3:27:17<4:54:54, 49.29s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m50%|█████     | 362/720 [3:27:51<4:26:22, 44.64s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0154, 'learning_rate': 0.00010112676056338028, 'epoch': 2.01}\u001b[0m\n",
      "\u001b[34m50%|█████     | 362/720 [3:27:51<4:26:22, 44.64s/it]\u001b[0m\n",
      "\u001b[34m50%|█████     | 363/720 [3:28:25<4:06:20, 41.40s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 0.00010084507042253521, 'epoch': 2.01}\u001b[0m\n",
      "\u001b[34m50%|█████     | 363/720 [3:28:25<4:06:20, 41.40s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 364/720 [3:28:59<3:52:09, 39.13s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0181, 'learning_rate': 0.00010056338028169015, 'epoch': 2.02}\u001b[0m\n",
      "\u001b[34m51%|█████     | 364/720 [3:28:59<3:52:09, 39.13s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 365/720 [3:29:32<3:42:05, 37.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 0.00010028169014084508, 'epoch': 2.02}\u001b[0m\n",
      "\u001b[34m51%|█████     | 365/720 [3:29:32<3:42:05, 37.54s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 366/720 [3:30:06<3:34:53, 36.42s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0172, 'learning_rate': 0.0001, 'epoch': 2.03}\u001b[0m\n",
      "\u001b[34m51%|█████     | 366/720 [3:30:06<3:34:53, 36.42s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 367/720 [3:30:40<3:29:42, 35.64s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0194, 'learning_rate': 9.971830985915493e-05, 'epoch': 2.04}\u001b[0m\n",
      "\u001b[34m51%|█████     | 367/720 [3:30:40<3:29:42, 35.64s/it]\u001b[0m\n",
      "\u001b[34m51%|█████     | 368/720 [3:31:14<3:25:54, 35.10s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0182, 'learning_rate': 9.943661971830986e-05, 'epoch': 2.04}\u001b[0m\n",
      "\u001b[34m51%|█████     | 368/720 [3:31:14<3:25:54, 35.10s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 369/720 [3:31:48<3:23:05, 34.72s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0132, 'learning_rate': 9.91549295774648e-05, 'epoch': 2.05}\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 369/720 [3:31:48<3:23:05, 34.72s/it]\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 370/720 [3:32:22<3:20:57, 34.45s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.016, 'learning_rate': 9.887323943661973e-05, 'epoch': 2.05}\u001b[0m\n",
      "\u001b[34m51%|█████▏    | 370/720 [3:32:22<3:20:57, 34.45s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 371/720 [3:32:55<3:19:18, 34.27s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 9.859154929577466e-05, 'epoch': 2.06}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 371/720 [3:32:55<3:19:18, 34.27s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 372/720 [3:33:29<3:17:59, 34.14s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0183, 'learning_rate': 9.830985915492958e-05, 'epoch': 2.06}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 372/720 [3:33:29<3:17:59, 34.14s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 373/720 [3:34:03<3:16:52, 34.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0168, 'learning_rate': 9.802816901408451e-05, 'epoch': 2.07}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 373/720 [3:34:03<3:16:52, 34.04s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 374/720 [3:34:37<3:15:57, 33.98s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0126, 'learning_rate': 9.774647887323944e-05, 'epoch': 2.07}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 374/720 [3:34:37<3:15:57, 33.98s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 375/720 [3:35:11<3:15:18, 33.97s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.014, 'learning_rate': 9.746478873239438e-05, 'epoch': 2.08}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 375/720 [3:35:11<3:15:18, 33.97s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 376/720 [3:35:45<3:14:30, 33.93s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0165, 'learning_rate': 9.718309859154931e-05, 'epoch': 2.09}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 376/720 [3:35:45<3:14:30, 33.93s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 377/720 [3:36:18<3:13:46, 33.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0142, 'learning_rate': 9.690140845070423e-05, 'epoch': 2.09}\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 377/720 [3:36:18<3:13:46, 33.90s/it]\u001b[0m\n",
      "\u001b[34m52%|█████▎    | 378/720 [3:36:52<3:13:05, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0155, 'learning_rate': 9.661971830985916e-05, 'epoch': 2.1}\u001b[0m\n",
      "\u001b[34m52%|█████▎    | 378/720 [3:36:52<3:13:05, 33.87s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 379/720 [3:37:26<3:12:26, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0145, 'learning_rate': 9.633802816901409e-05, 'epoch': 2.1}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 379/720 [3:37:26<3:12:26, 33.86s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 380/720 [3:38:00<3:11:49, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0137, 'learning_rate': 9.605633802816903e-05, 'epoch': 2.11}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 380/720 [3:38:00<3:11:49, 33.85s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 381/720 [3:38:34<3:11:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0198, 'learning_rate': 9.577464788732394e-05, 'epoch': 2.11}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 381/720 [3:38:34<3:11:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 382/720 [3:39:08<3:10:37, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 9.549295774647887e-05, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 382/720 [3:39:08<3:10:37, 33.84s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 383/720 [3:39:41<3:10:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0149, 'learning_rate': 9.52112676056338e-05, 'epoch': 2.12}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 383/720 [3:39:41<3:10:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 384/720 [3:40:15<3:09:28, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0138, 'learning_rate': 9.492957746478873e-05, 'epoch': 2.13}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 384/720 [3:40:15<3:09:28, 33.83s/it]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 385/720 [3:40:49<3:08:54, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0212, 'learning_rate': 9.464788732394367e-05, 'epoch': 2.14}\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 385/720 [3:40:49<3:08:54, 33.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 386/720 [3:41:23<3:08:20, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0172, 'learning_rate': 9.43661971830986e-05, 'epoch': 2.14}\u001b[0m\n",
      "\u001b[34m54%|█████▎    | 386/720 [3:41:23<3:08:20, 33.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 387/720 [3:41:57<3:07:46, 33.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 387/720 [3:41:57<3:07:46, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'learning_rate': 9.408450704225352e-05, 'epoch': 2.15}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 388/720 [3:42:31<3:07:13, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0178, 'learning_rate': 9.380281690140845e-05, 'epoch': 2.15}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 388/720 [3:42:31<3:07:13, 33.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 389/720 [3:43:04<3:06:37, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0142, 'learning_rate': 9.352112676056338e-05, 'epoch': 2.16}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 389/720 [3:43:04<3:06:37, 33.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 390/720 [3:43:38<3:06:04, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0138, 'learning_rate': 9.32394366197183e-05, 'epoch': 2.16}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 390/720 [3:43:38<3:06:04, 33.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 391/720 [3:44:12<3:05:31, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0157, 'learning_rate': 9.295774647887325e-05, 'epoch': 2.17}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 391/720 [3:44:12<3:05:31, 33.83s/it]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 392/720 [3:44:46<3:04:57, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0155, 'learning_rate': 9.267605633802817e-05, 'epoch': 2.17}\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 392/720 [3:44:46<3:04:57, 33.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 393/720 [3:45:20<3:04:23, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0185, 'learning_rate': 9.23943661971831e-05, 'epoch': 2.18}\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 393/720 [3:45:20<3:04:23, 33.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 394/720 [3:45:54<3:03:48, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0148, 'learning_rate': 9.211267605633803e-05, 'epoch': 2.19}\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 394/720 [3:45:54<3:03:48, 33.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 395/720 [3:46:27<3:03:15, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0161, 'learning_rate': 9.183098591549296e-05, 'epoch': 2.19}\u001b[0m\n",
      "\u001b[34m55%|█████▍    | 395/720 [3:46:27<3:03:15, 33.83s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 396/720 [3:47:01<3:02:41, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0146, 'learning_rate': 9.15492957746479e-05, 'epoch': 2.2}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 396/720 [3:47:01<3:02:41, 33.83s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:33,441] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:33,449] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:33,449] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:33,453] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:35,948] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:35,948] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:38,511] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:41,073] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2023-10-28 20:36:43,635] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:36:46,227] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.01725311391055584, 'eval_runtime': 12.8838, 'eval_samples_per_second': 61.007, 'eval_steps_per_second': 30.503, 'epoch': 2.2}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 396/720 [3:47:14<3:02:41, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 397/720 [3:47:48<3:22:57, 37.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0168, 'learning_rate': 9.126760563380283e-05, 'epoch': 2.2}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 397/720 [3:47:48<3:22:57, 37.70s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 398/720 [3:48:22<3:16:06, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0146, 'learning_rate': 9.098591549295775e-05, 'epoch': 2.21}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 398/720 [3:48:22<3:16:06, 36.54s/it]\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 399/720 [3:48:56<3:11:09, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0143, 'learning_rate': 9.070422535211268e-05, 'epoch': 2.21}\u001b[0m\n",
      "\u001b[34m55%|█████▌    | 399/720 [3:48:56<3:11:09, 35.73s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 400/720 [3:49:30<3:07:31, 35.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'learning_rate': 9.042253521126761e-05, 'epoch': 2.22}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 400/720 [3:49:30<3:07:31, 35.16s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 401/720 [3:50:03<3:04:49, 34.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0196, 'learning_rate': 9.014084507042254e-05, 'epoch': 2.22}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 401/720 [3:50:03<3:04:49, 34.76s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 402/720 [3:50:37<3:02:46, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0176, 'learning_rate': 8.985915492957748e-05, 'epoch': 2.23}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 402/720 [3:50:37<3:02:46, 34.49s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 403/720 [3:51:11<3:01:09, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0169, 'learning_rate': 8.95774647887324e-05, 'epoch': 2.24}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 403/720 [3:51:11<3:01:09, 34.29s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 404/720 [3:51:45<2:59:52, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0145, 'learning_rate': 8.929577464788733e-05, 'epoch': 2.24}\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 404/720 [3:51:45<2:59:52, 34.15s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 405/720 [3:52:19<2:58:47, 34.05s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0167, 'learning_rate': 8.901408450704226e-05, 'epoch': 2.25}\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 405/720 [3:52:19<2:58:47, 34.05s/it]\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 406/720 [3:52:53<2:57:52, 33.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0151, 'learning_rate': 8.873239436619719e-05, 'epoch': 2.25}\u001b[0m\n",
      "\u001b[34m56%|█████▋    | 406/720 [3:52:53<2:57:52, 33.99s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 407/720 [3:53:26<2:57:03, 33.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0161, 'learning_rate': 8.845070422535213e-05, 'epoch': 2.26}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 407/720 [3:53:26<2:57:03, 33.94s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 408/720 [3:54:00<2:56:19, 33.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0167, 'learning_rate': 8.816901408450705e-05, 'epoch': 2.26}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 408/720 [3:54:00<2:56:19, 33.91s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 409/720 [3:54:34<2:55:38, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0238, 'learning_rate': 8.788732394366198e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 409/720 [3:54:34<2:55:38, 33.88s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 410/720 [3:55:08<2:54:58, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0187, 'learning_rate': 8.760563380281691e-05, 'epoch': 2.27}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 410/720 [3:55:08<2:54:58, 33.87s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 411/720 [3:55:42<2:54:22, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0179, 'learning_rate': 8.732394366197182e-05, 'epoch': 2.28}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 411/720 [3:55:42<2:54:22, 33.86s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 412/720 [3:56:16<2:53:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0159, 'learning_rate': 8.704225352112676e-05, 'epoch': 2.29}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 412/720 [3:56:16<2:53:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 413/720 [3:56:49<2:53:11, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0169, 'learning_rate': 8.676056338028169e-05, 'epoch': 2.29}\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 413/720 [3:56:49<2:53:11, 33.85s/it]\u001b[0m\n",
      "\u001b[34m57%|█████▊    | 414/720 [3:57:23<2:52:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0189, 'learning_rate': 8.647887323943662e-05, 'epoch': 2.3}\u001b[0m\n",
      "\u001b[34m57%|█████▊    | 414/720 [3:57:23<2:52:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 415/720 [3:57:57<2:52:00, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 8.619718309859155e-05, 'epoch': 2.3}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 415/720 [3:57:57<2:52:00, 33.84s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 416/720 [3:58:31<2:51:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 8.591549295774647e-05, 'epoch': 2.31}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 416/720 [3:58:31<2:51:26, 33.84s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 417/720 [3:59:05<2:50:51, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0184, 'learning_rate': 8.563380281690142e-05, 'epoch': 2.31}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 417/720 [3:59:05<2:50:51, 33.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 418/720 [3:59:39<2:50:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 8.535211267605634e-05, 'epoch': 2.32}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 418/720 [3:59:39<2:50:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 419/720 [4:00:12<2:49:44, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0195, 'learning_rate': 8.507042253521127e-05, 'epoch': 2.32}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 419/720 [4:00:12<2:49:44, 33.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 420/720 [4:00:46<2:49:09, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 8.47887323943662e-05, 'epoch': 2.33}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 420/720 [4:00:46<2:49:09, 33.83s/it]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 421/720 [4:01:20<2:48:35, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0171, 'learning_rate': 8.450704225352113e-05, 'epoch': 2.34}\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 421/720 [4:01:20<2:48:35, 33.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 422/720 [4:01:54<2:48:01, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0165, 'learning_rate': 8.422535211267605e-05, 'epoch': 2.34}\u001b[0m\n",
      "\u001b[34m59%|█████▊    | 422/720 [4:01:54<2:48:01, 33.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 423/720 [4:02:28<2:47:27, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0147, 'learning_rate': 8.3943661971831e-05, 'epoch': 2.35}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 423/720 [4:02:28<2:47:27, 33.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 424/720 [4:03:01<2:46:53, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0143, 'learning_rate': 8.366197183098592e-05, 'epoch': 2.35}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 424/720 [4:03:01<2:46:53, 33.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 425/720 [4:03:35<2:46:20, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0186, 'learning_rate': 8.338028169014085e-05, 'epoch': 2.36}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 425/720 [4:03:35<2:46:20, 33.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 426/720 [4:04:09<2:45:46, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0144, 'learning_rate': 8.309859154929578e-05, 'epoch': 2.36}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 426/720 [4:04:09<2:45:46, 33.83s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 427/720 [4:04:43<2:45:13, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0159, 'learning_rate': 8.28169014084507e-05, 'epoch': 2.37}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 427/720 [4:04:43<2:45:13, 33.84s/it]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 428/720 [4:05:17<2:44:39, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0168, 'learning_rate': 8.253521126760565e-05, 'epoch': 2.37}\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 428/720 [4:05:17<2:44:39, 33.83s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 429/720 [4:05:51<2:44:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0151, 'learning_rate': 8.225352112676057e-05, 'epoch': 2.38}\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 429/720 [4:05:51<2:44:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 430/720 [4:06:25<2:43:31, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0132, 'learning_rate': 8.19718309859155e-05, 'epoch': 2.39}\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 430/720 [4:06:25<2:43:31, 33.83s/it]\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 431/720 [4:06:58<2:42:57, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0154, 'learning_rate': 8.169014084507043e-05, 'epoch': 2.39}\u001b[0m\n",
      "\u001b[34m60%|█████▉    | 431/720 [4:06:58<2:42:57, 33.83s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 432/720 [4:07:32<2:42:24, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0153, 'learning_rate': 8.140845070422536e-05, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m60%|██████    | 432/720 [4:07:32<2:42:24, 33.83s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:04,325] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:04,334] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:04,334] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:04,339] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:06,842] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:06,842] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2023-10-28 20:57:09,405] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:11,967] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.82s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:14,529] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 20:57:17,121] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.018914448097348213, 'eval_runtime': 12.8941, 'eval_samples_per_second': 60.958, 'eval_steps_per_second': 30.479, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m60%|██████    | 432/720 [4:07:45<2:42:24, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 433/720 [4:08:19<3:00:21, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.017, 'learning_rate': 8.112676056338028e-05, 'epoch': 2.4}\u001b[0m\n",
      "\u001b[34m60%|██████    | 433/720 [4:08:19<3:00:21, 37.71s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 434/720 [4:08:53<2:54:11, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 8.084507042253522e-05, 'epoch': 2.41}\u001b[0m\n",
      "\u001b[34m60%|██████    | 434/720 [4:08:53<2:54:11, 36.54s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 435/720 [4:09:27<2:49:42, 35.73s/it]\u001b[0m\n",
      "\u001b[34m60%|██████    | 435/720 [4:09:27<2:49:42, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0133, 'learning_rate': 8.056338028169015e-05, 'epoch': 2.41}\u001b[0m\n",
      "\u001b[34m61%|██████    | 436/720 [4:10:00<2:46:27, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0154, 'learning_rate': 8.028169014084508e-05, 'epoch': 2.42}\u001b[0m\n",
      "\u001b[34m61%|██████    | 436/720 [4:10:00<2:46:27, 35.17s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 437/720 [4:10:34<2:43:58, 34.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0166, 'learning_rate': 8e-05, 'epoch': 2.42}\u001b[0m\n",
      "\u001b[34m61%|██████    | 437/720 [4:10:34<2:43:58, 34.76s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 438/720 [4:11:08<2:42:04, 34.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0177, 'learning_rate': 7.971830985915493e-05, 'epoch': 2.43}\u001b[0m\n",
      "\u001b[34m61%|██████    | 438/720 [4:11:08<2:42:04, 34.48s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 439/720 [4:11:42<2:40:35, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0121, 'learning_rate': 7.943661971830986e-05, 'epoch': 2.44}\u001b[0m\n",
      "\u001b[34m61%|██████    | 439/720 [4:11:42<2:40:35, 34.29s/it]\u001b[0m\n",
      "\u001b[34m61%|██████    | 440/720 [4:12:16<2:39:22, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0152, 'learning_rate': 7.915492957746479e-05, 'epoch': 2.44}\u001b[0m\n",
      "\u001b[34m61%|██████    | 440/720 [4:12:16<2:39:22, 34.15s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 441/720 [4:12:50<2:38:21, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0124, 'learning_rate': 7.887323943661972e-05, 'epoch': 2.45}\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 441/720 [4:12:50<2:38:21, 34.06s/it]\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 442/720 [4:13:23<2:37:28, 33.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0158, 'learning_rate': 7.859154929577464e-05, 'epoch': 2.45}\u001b[0m\n",
      "\u001b[34m61%|██████▏   | 442/720 [4:13:23<2:37:28, 33.99s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 443/720 [4:13:57<2:36:42, 33.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0164, 'learning_rate': 7.830985915492957e-05, 'epoch': 2.46}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 443/720 [4:13:57<2:36:42, 33.94s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 444/720 [4:14:31<2:36:00, 33.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0185, 'learning_rate': 7.802816901408451e-05, 'epoch': 2.46}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 444/720 [4:14:31<2:36:00, 33.91s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 445/720 [4:15:05<2:35:19, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.016, 'learning_rate': 7.774647887323944e-05, 'epoch': 2.47}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 445/720 [4:15:05<2:35:19, 33.89s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 446/720 [4:15:39<2:34:41, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 7.746478873239437e-05, 'epoch': 2.47}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 446/720 [4:15:39<2:34:41, 33.87s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 447/720 [4:16:13<2:34:04, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0157, 'learning_rate': 7.71830985915493e-05, 'epoch': 2.48}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 447/720 [4:16:13<2:34:04, 33.86s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 448/720 [4:16:46<2:33:27, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.02, 'learning_rate': 7.690140845070422e-05, 'epoch': 2.49}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 448/720 [4:16:46<2:33:27, 33.85s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 449/720 [4:17:20<2:32:52, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0187, 'learning_rate': 7.661971830985915e-05, 'epoch': 2.49}\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 449/720 [4:17:20<2:32:52, 33.85s/it]\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 450/720 [4:17:54<2:32:19, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0149, 'learning_rate': 7.633802816901409e-05, 'epoch': 2.5}\u001b[0m\n",
      "\u001b[34m62%|██████▎   | 450/720 [4:17:54<2:32:19, 33.85s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 451/720 [4:18:28<2:31:45, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0197, 'learning_rate': 7.605633802816902e-05, 'epoch': 2.5}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 451/720 [4:18:28<2:31:45, 33.85s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 452/720 [4:19:02<2:31:10, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0198, 'learning_rate': 7.577464788732395e-05, 'epoch': 2.51}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 452/720 [4:19:02<2:31:10, 33.85s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 453/720 [4:19:36<2:30:36, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0159, 'learning_rate': 7.549295774647887e-05, 'epoch': 2.51}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 453/720 [4:19:36<2:30:36, 33.85s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 454/720 [4:20:09<2:30:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0166, 'learning_rate': 7.52112676056338e-05, 'epoch': 2.52}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 454/720 [4:20:09<2:30:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 455/720 [4:20:43<2:29:28, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 7.492957746478874e-05, 'epoch': 2.52}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 455/720 [4:20:43<2:29:28, 33.84s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 456/720 [4:21:17<2:28:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0117, 'learning_rate': 7.464788732394367e-05, 'epoch': 2.53}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 456/720 [4:21:17<2:28:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 457/720 [4:21:51<2:28:20, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0148, 'learning_rate': 7.43661971830986e-05, 'epoch': 2.54}\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 457/720 [4:21:51<2:28:20, 33.84s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 458/720 [4:22:25<2:27:45, 33.84s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▎   | 458/720 [4:22:25<2:27:45, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0157, 'learning_rate': 7.408450704225352e-05, 'epoch': 2.54}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 459/720 [4:22:59<2:27:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0142, 'learning_rate': 7.380281690140845e-05, 'epoch': 2.55}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 459/720 [4:22:59<2:27:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 460/720 [4:23:33<2:26:39, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0114, 'learning_rate': 7.352112676056338e-05, 'epoch': 2.55}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 460/720 [4:23:33<2:26:39, 33.85s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 461/720 [4:24:06<2:26:05, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0148, 'learning_rate': 7.323943661971832e-05, 'epoch': 2.56}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 461/720 [4:24:06<2:26:05, 33.84s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 462/720 [4:24:40<2:25:31, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0194, 'learning_rate': 7.295774647887325e-05, 'epoch': 2.56}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 462/720 [4:24:40<2:25:31, 33.84s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 463/720 [4:25:14<2:24:57, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0157, 'learning_rate': 7.267605633802818e-05, 'epoch': 2.57}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 463/720 [4:25:14<2:24:57, 33.84s/it]\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 464/720 [4:25:48<2:24:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.015, 'learning_rate': 7.23943661971831e-05, 'epoch': 2.57}\u001b[0m\n",
      "\u001b[34m64%|██████▍   | 464/720 [4:25:48<2:24:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 465/720 [4:26:22<2:23:49, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0152, 'learning_rate': 7.211267605633803e-05, 'epoch': 2.58}\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 465/720 [4:26:22<2:23:49, 33.84s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 466/720 [4:26:56<2:23:15, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0195, 'learning_rate': 7.183098591549297e-05, 'epoch': 2.59}\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 466/720 [4:26:56<2:23:15, 33.84s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 467/720 [4:27:29<2:22:41, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0153, 'learning_rate': 7.15492957746479e-05, 'epoch': 2.59}\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 467/720 [4:27:29<2:22:41, 33.84s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m65%|██████▌   | 468/720 [4:28:03<2:22:08, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0142, 'learning_rate': 7.126760563380283e-05, 'epoch': 2.6}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 468/720 [4:28:03<2:22:08, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:35,432] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:35,440] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:35,440] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:35,444] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:37,940] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:37,940] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:40,502] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:43,064] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:45,626] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:17:48,218] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.01859666034579277, 'eval_runtime': 12.8831, 'eval_samples_per_second': 61.01, 'eval_steps_per_second': 30.505, 'epoch': 2.6}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 468/720 [4:28:16<2:22:08, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 469/720 [4:28:50<2:37:44, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.016, 'learning_rate': 7.098591549295775e-05, 'epoch': 2.6}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 469/720 [4:28:50<2:37:44, 37.71s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 470/720 [4:29:24<2:32:15, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0193, 'learning_rate': 7.070422535211267e-05, 'epoch': 2.61}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 470/720 [4:29:24<2:32:15, 36.54s/it]\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 471/720 [4:29:58<2:28:16, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0165, 'learning_rate': 7.042253521126761e-05, 'epoch': 2.61}\u001b[0m\n",
      "\u001b[34m65%|██████▌   | 471/720 [4:29:58<2:28:16, 35.73s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 472/720 [4:30:31<2:25:19, 35.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0186, 'learning_rate': 7.014084507042254e-05, 'epoch': 2.62}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 472/720 [4:30:31<2:25:19, 35.16s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 473/720 [4:31:05<2:23:05, 34.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0151, 'learning_rate': 6.985915492957746e-05, 'epoch': 2.62}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 473/720 [4:31:05<2:23:05, 34.76s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 474/720 [4:31:39<2:21:23, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0185, 'learning_rate': 6.957746478873239e-05, 'epoch': 2.63}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 474/720 [4:31:39<2:21:23, 34.49s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 475/720 [4:32:13<2:20:01, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0176, 'learning_rate': 6.929577464788732e-05, 'epoch': 2.64}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 475/720 [4:32:13<2:20:01, 34.29s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 476/720 [4:32:47<2:18:53, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0119, 'learning_rate': 6.901408450704226e-05, 'epoch': 2.64}\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 476/720 [4:32:47<2:18:53, 34.15s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 477/720 [4:33:21<2:17:56, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0197, 'learning_rate': 6.873239436619719e-05, 'epoch': 2.65}\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 477/720 [4:33:21<2:17:56, 34.06s/it]\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 478/720 [4:33:55<2:17:06, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0153, 'learning_rate': 6.845070422535212e-05, 'epoch': 2.65}\u001b[0m\n",
      "\u001b[34m66%|██████▋   | 478/720 [4:33:55<2:17:06, 34.00s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 479/720 [4:34:28<2:16:22, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0166, 'learning_rate': 6.816901408450704e-05, 'epoch': 2.66}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 479/720 [4:34:28<2:16:22, 33.95s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 480/720 [4:35:02<2:15:40, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0126, 'learning_rate': 6.788732394366197e-05, 'epoch': 2.66}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 480/720 [4:35:02<2:15:40, 33.92s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 481/720 [4:35:36<2:15:00, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0145, 'learning_rate': 6.76056338028169e-05, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 481/720 [4:35:36<2:15:00, 33.89s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 482/720 [4:36:10<2:14:21, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0119, 'learning_rate': 6.732394366197184e-05, 'epoch': 2.67}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 482/720 [4:36:10<2:14:21, 33.87s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 483/720 [4:36:44<2:13:45, 33.86s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 483/720 [4:36:44<2:13:45, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.016, 'learning_rate': 6.704225352112677e-05, 'epoch': 2.68}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 484/720 [4:37:18<2:13:09, 33.85s/it]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 484/720 [4:37:18<2:13:09, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0168, 'learning_rate': 6.67605633802817e-05, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 485/720 [4:37:51<2:12:34, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0173, 'learning_rate': 6.647887323943662e-05, 'epoch': 2.69}\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 485/720 [4:37:51<2:12:34, 33.85s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 486/720 [4:38:25<2:11:59, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0111, 'learning_rate': 6.619718309859155e-05, 'epoch': 2.7}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 486/720 [4:38:25<2:11:59, 33.84s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 487/720 [4:38:59<2:11:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0157, 'learning_rate': 6.591549295774648e-05, 'epoch': 2.7}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 487/720 [4:38:59<2:11:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 488/720 [4:39:33<2:10:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0148, 'learning_rate': 6.563380281690142e-05, 'epoch': 2.71}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 488/720 [4:39:33<2:10:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 489/720 [4:40:07<2:10:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0167, 'learning_rate': 6.535211267605635e-05, 'epoch': 2.71}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 489/720 [4:40:07<2:10:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 490/720 [4:40:41<2:09:44, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0173, 'learning_rate': 6.507042253521127e-05, 'epoch': 2.72}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 490/720 [4:40:41<2:09:44, 33.84s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 491/720 [4:41:14<2:09:10, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0166, 'learning_rate': 6.47887323943662e-05, 'epoch': 2.72}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 491/720 [4:41:14<2:09:10, 33.84s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 492/720 [4:41:48<2:08:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0135, 'learning_rate': 6.450704225352113e-05, 'epoch': 2.73}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 492/720 [4:41:48<2:08:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 493/720 [4:42:22<2:08:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.014, 'learning_rate': 6.422535211267607e-05, 'epoch': 2.74}\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 493/720 [4:42:22<2:08:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 494/720 [4:42:56<2:07:26, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0181, 'learning_rate': 6.3943661971831e-05, 'epoch': 2.74}\u001b[0m\n",
      "\u001b[34m69%|██████▊   | 494/720 [4:42:56<2:07:26, 33.83s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 495/720 [4:43:30<2:06:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 495/720 [4:43:30<2:06:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0159, 'learning_rate': 6.366197183098592e-05, 'epoch': 2.75}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 496/720 [4:44:04<2:06:20, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0173, 'learning_rate': 6.338028169014085e-05, 'epoch': 2.75}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 496/720 [4:44:04<2:06:20, 33.84s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m69%|██████▉   | 497/720 [4:44:37<2:05:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0177, 'learning_rate': 6.309859154929578e-05, 'epoch': 2.76}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 497/720 [4:44:37<2:05:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 498/720 [4:45:11<2:05:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0183, 'learning_rate': 6.28169014084507e-05, 'epoch': 2.76}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 498/720 [4:45:11<2:05:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 499/720 [4:45:45<2:04:38, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0146, 'learning_rate': 6.253521126760565e-05, 'epoch': 2.77}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 499/720 [4:45:45<2:04:38, 33.84s/it]\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 500/720 [4:46:19<2:04:03, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0177, 'learning_rate': 6.225352112676056e-05, 'epoch': 2.77}\u001b[0m\n",
      "\u001b[34m69%|██████▉   | 500/720 [4:46:19<2:04:03, 33.83s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 501/720 [4:46:53<2:03:29, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0175, 'learning_rate': 6.197183098591549e-05, 'epoch': 2.78}\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 501/720 [4:46:53<2:03:29, 33.83s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 502/720 [4:47:27<2:02:55, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0178, 'learning_rate': 6.169014084507042e-05, 'epoch': 2.79}\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 502/720 [4:47:27<2:02:55, 33.83s/it]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 503/720 [4:48:00<2:02:22, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0176, 'learning_rate': 6.140845070422536e-05, 'epoch': 2.79}\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 503/720 [4:48:00<2:02:22, 33.83s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 504/720 [4:48:34<2:01:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.021, 'learning_rate': 6.112676056338028e-05, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m70%|███████   | 504/720 [4:48:34<2:01:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:06,435] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:06,444] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:06,444] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:06,449] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:08,951] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:08,951] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:11,513] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:14,075] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:16,637] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:38:19,230] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.01845867559313774, 'eval_runtime': 12.8929, 'eval_samples_per_second': 60.964, 'eval_steps_per_second': 30.482, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m70%|███████   | 504/720 [4:48:47<2:01:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 505/720 [4:49:21<2:15:06, 37.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0131, 'learning_rate': 6.084507042253521e-05, 'epoch': 2.8}\u001b[0m\n",
      "\u001b[34m70%|███████   | 505/720 [4:49:21<2:15:06, 37.70s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 506/720 [4:49:55<2:10:20, 36.54s/it]\u001b[0m\n",
      "\u001b[34m70%|███████   | 506/720 [4:49:55<2:10:20, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0158, 'learning_rate': 6.056338028169014e-05, 'epoch': 2.81}\u001b[0m\n",
      "\u001b[34m70%|███████   | 507/720 [4:50:29<2:06:50, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0163, 'learning_rate': 6.0281690140845074e-05, 'epoch': 2.81}\u001b[0m\n",
      "\u001b[34m70%|███████   | 507/720 [4:50:29<2:06:50, 35.73s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 508/720 [4:51:03<2:04:14, 35.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0156, 'learning_rate': 6e-05, 'epoch': 2.82}\u001b[0m\n",
      "\u001b[34m71%|███████   | 508/720 [4:51:03<2:04:14, 35.16s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 509/720 [4:51:36<2:02:15, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0128, 'learning_rate': 5.971830985915493e-05, 'epoch': 2.82}\u001b[0m\n",
      "\u001b[34m71%|███████   | 509/720 [4:51:36<2:02:15, 34.77s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 510/720 [4:52:10<2:00:41, 34.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0161, 'learning_rate': 5.943661971830986e-05, 'epoch': 2.83}\u001b[0m\n",
      "\u001b[34m71%|███████   | 510/720 [4:52:10<2:00:41, 34.48s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 511/720 [4:52:44<1:59:26, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 5.915492957746479e-05, 'epoch': 2.83}\u001b[0m\n",
      "\u001b[34m71%|███████   | 511/720 [4:52:44<1:59:26, 34.29s/it]\u001b[0m\n",
      "\u001b[34m71%|███████   | 512/720 [4:53:18<1:58:23, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0172, 'learning_rate': 5.887323943661972e-05, 'epoch': 2.84}\u001b[0m\n",
      "\u001b[34m71%|███████   | 512/720 [4:53:18<1:58:23, 34.15s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 513/720 [4:53:52<1:57:29, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0169, 'learning_rate': 5.859154929577465e-05, 'epoch': 2.85}\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 513/720 [4:53:52<1:57:29, 34.06s/it]\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 514/720 [4:54:26<1:56:41, 33.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 5.830985915492958e-05, 'epoch': 2.85}\u001b[0m\n",
      "\u001b[34m71%|███████▏  | 514/720 [4:54:26<1:56:41, 33.99s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 515/720 [4:54:59<1:55:58, 33.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0153, 'learning_rate': 5.802816901408451e-05, 'epoch': 2.86}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 515/720 [4:54:59<1:55:58, 33.94s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 516/720 [4:55:33<1:55:19, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0143, 'learning_rate': 5.774647887323944e-05, 'epoch': 2.86}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 516/720 [4:55:33<1:55:19, 33.92s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 517/720 [4:56:07<1:54:40, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.018, 'learning_rate': 5.746478873239437e-05, 'epoch': 2.87}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 517/720 [4:56:07<1:54:40, 33.89s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 518/720 [4:56:41<1:54:02, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0158, 'learning_rate': 5.71830985915493e-05, 'epoch': 2.87}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 518/720 [4:56:41<1:54:02, 33.87s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 519/720 [4:57:15<1:53:26, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0132, 'learning_rate': 5.690140845070423e-05, 'epoch': 2.88}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 519/720 [4:57:15<1:53:26, 33.86s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 520/720 [4:57:49<1:52:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0135, 'learning_rate': 5.661971830985916e-05, 'epoch': 2.88}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 520/720 [4:57:49<1:52:50, 33.85s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 521/720 [4:58:22<1:52:15, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0141, 'learning_rate': 5.633802816901409e-05, 'epoch': 2.89}\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 521/720 [4:58:22<1:52:15, 33.85s/it]\u001b[0m\n",
      "\u001b[34m72%|███████▎  | 522/720 [4:58:56<1:51:41, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.016, 'learning_rate': 5.605633802816902e-05, 'epoch': 2.9}\u001b[0m\n",
      "\u001b[34m72%|███████▎  | 522/720 [4:58:56<1:51:41, 33.85s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 523/720 [4:59:30<1:51:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0155, 'learning_rate': 5.577464788732395e-05, 'epoch': 2.9}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 523/720 [4:59:30<1:51:07, 33.84s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 524/720 [5:00:04<1:50:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0123, 'learning_rate': 5.549295774647888e-05, 'epoch': 2.91}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 524/720 [5:00:04<1:50:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 525/720 [5:00:38<1:49:59, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0191, 'learning_rate': 5.521126760563381e-05, 'epoch': 2.91}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 525/720 [5:00:38<1:49:59, 33.85s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 526/720 [5:01:12<1:49:25, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0178, 'learning_rate': 5.492957746478874e-05, 'epoch': 2.92}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 526/720 [5:01:12<1:49:25, 33.84s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m73%|███████▎  | 527/720 [5:01:45<1:48:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0201, 'learning_rate': 5.464788732394367e-05, 'epoch': 2.92}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 527/720 [5:01:45<1:48:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 528/720 [5:02:19<1:48:16, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0152, 'learning_rate': 5.43661971830986e-05, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 528/720 [5:02:19<1:48:16, 33.84s/it]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 529/720 [5:02:53<1:47:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0154, 'learning_rate': 5.408450704225352e-05, 'epoch': 2.93}\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 529/720 [5:02:53<1:47:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 530/720 [5:03:27<1:47:08, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.015, 'learning_rate': 5.380281690140845e-05, 'epoch': 2.94}\u001b[0m\n",
      "\u001b[34m74%|███████▎  | 530/720 [5:03:27<1:47:08, 33.84s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 531/720 [5:04:01<1:46:34, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0165, 'learning_rate': 5.352112676056338e-05, 'epoch': 2.95}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 531/720 [5:04:01<1:46:34, 33.84s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 532/720 [5:04:35<1:46:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 532/720 [5:04:35<1:46:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0144, 'learning_rate': 5.323943661971831e-05, 'epoch': 2.95}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 533/720 [5:05:08<1:45:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0148, 'learning_rate': 5.2957746478873237e-05, 'epoch': 2.96}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 533/720 [5:05:08<1:45:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 534/720 [5:05:42<1:44:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0139, 'learning_rate': 5.267605633802817e-05, 'epoch': 2.96}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 534/720 [5:05:42<1:44:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 535/720 [5:06:16<1:44:19, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0172, 'learning_rate': 5.23943661971831e-05, 'epoch': 2.97}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 535/720 [5:06:16<1:44:19, 33.84s/it]\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 536/720 [5:06:50<1:43:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 5.2112676056338026e-05, 'epoch': 2.97}\u001b[0m\n",
      "\u001b[34m74%|███████▍  | 536/720 [5:06:50<1:43:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 537/720 [5:07:24<1:43:11, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0196, 'learning_rate': 5.183098591549296e-05, 'epoch': 2.98}\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 537/720 [5:07:24<1:43:11, 33.84s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 538/720 [5:07:58<1:42:37, 33.83s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 538/720 [5:07:58<1:42:37, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0155, 'learning_rate': 5.154929577464789e-05, 'epoch': 2.98}\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 539/720 [5:08:31<1:42:03, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0167, 'learning_rate': 5.1267605633802815e-05, 'epoch': 2.99}\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 539/720 [5:08:31<1:42:03, 33.83s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 540/720 [5:09:05<1:41:29, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0135, 'learning_rate': 5.098591549295775e-05, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 540/720 [5:09:05<1:41:29, 33.83s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:37,428] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:37,436] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:37,436] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:37,440] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:39,935] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:39,935] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:42,498] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:45,060] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:47,622] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:58:50,215] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.017587559297680855, 'eval_runtime': 12.8843, 'eval_samples_per_second': 61.004, 'eval_steps_per_second': 30.502, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 540/720 [5:09:18<1:41:29, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:59:51,684] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:59:51,684] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:59:51,704] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] d475fa545a8905b1445e3fbc59e6c3804f874d39738af897862714bf22582ea2#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 21:59:52,058] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 5981037#033[39m\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 541/720 [5:10:28<2:25:08, 48.65s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0165, 'learning_rate': 5.070422535211268e-05, 'epoch': 3.0}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 541/720 [5:10:28<2:25:08, 48.65s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 542/720 [5:11:02<2:11:05, 44.19s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 5.0422535211267604e-05, 'epoch': 3.01}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 542/720 [5:11:02<2:11:05, 44.19s/it]\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 543/720 [5:11:36<2:01:10, 41.08s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0116, 'learning_rate': 5.014084507042254e-05, 'epoch': 3.01}\u001b[0m\n",
      "\u001b[34m75%|███████▌  | 543/720 [5:11:36<2:01:10, 41.08s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 544/720 [5:12:10<1:54:06, 38.90s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 4.9859154929577466e-05, 'epoch': 3.02}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 544/720 [5:12:10<1:54:06, 38.90s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 545/720 [5:12:44<1:49:01, 37.38s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0108, 'learning_rate': 4.95774647887324e-05, 'epoch': 3.02}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 545/720 [5:12:44<1:49:01, 37.38s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 546/720 [5:13:18<1:45:19, 36.32s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0126, 'learning_rate': 4.929577464788733e-05, 'epoch': 3.03}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 546/720 [5:13:18<1:45:19, 36.32s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 547/720 [5:13:51<1:42:33, 35.57s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 4.9014084507042255e-05, 'epoch': 3.03}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 547/720 [5:13:51<1:42:33, 35.57s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 548/720 [5:14:25<1:40:28, 35.05s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0154, 'learning_rate': 4.873239436619719e-05, 'epoch': 3.04}\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 548/720 [5:14:25<1:40:28, 35.05s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 549/720 [5:14:59<1:38:50, 34.68s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0133, 'learning_rate': 4.845070422535212e-05, 'epoch': 3.05}\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 549/720 [5:14:59<1:38:50, 34.68s/it]\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 550/720 [5:15:33<1:37:32, 34.43s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0136, 'learning_rate': 4.8169014084507045e-05, 'epoch': 3.05}\u001b[0m\n",
      "\u001b[34m76%|███████▋  | 550/720 [5:15:33<1:37:32, 34.43s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 551/720 [5:16:07<1:36:28, 34.25s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.01, 'learning_rate': 4.788732394366197e-05, 'epoch': 3.06}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 551/720 [5:16:07<1:36:28, 34.25s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 552/720 [5:16:41<1:35:33, 34.13s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 552/720 [5:16:41<1:35:33, 34.13s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 4.76056338028169e-05, 'epoch': 3.06}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m77%|███████▋  | 553/720 [5:17:14<1:34:44, 34.04s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0119, 'learning_rate': 4.7323943661971834e-05, 'epoch': 3.07}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 553/720 [5:17:14<1:34:44, 34.04s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 554/720 [5:17:48<1:34:00, 33.98s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 4.704225352112676e-05, 'epoch': 3.07}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 554/720 [5:17:48<1:34:00, 33.98s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 555/720 [5:18:22<1:33:19, 33.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0136, 'learning_rate': 4.676056338028169e-05, 'epoch': 3.08}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 555/720 [5:18:22<1:33:19, 33.94s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 556/720 [5:18:56<1:32:40, 33.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0133, 'learning_rate': 4.647887323943662e-05, 'epoch': 3.08}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 556/720 [5:18:56<1:32:40, 33.91s/it]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 557/720 [5:19:30<1:32:03, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0142, 'learning_rate': 4.619718309859155e-05, 'epoch': 3.09}\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 557/720 [5:19:30<1:32:03, 33.89s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 558/720 [5:20:04<1:31:26, 33.87s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 558/720 [5:20:04<1:31:26, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0108, 'learning_rate': 4.591549295774648e-05, 'epoch': 3.1}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 559/720 [5:20:37<1:30:50, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0128, 'learning_rate': 4.563380281690141e-05, 'epoch': 3.1}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 559/720 [5:20:37<1:30:50, 33.86s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 560/720 [5:21:11<1:30:15, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0125, 'learning_rate': 4.535211267605634e-05, 'epoch': 3.11}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 560/720 [5:21:11<1:30:15, 33.85s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 561/720 [5:21:45<1:29:41, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.015, 'learning_rate': 4.507042253521127e-05, 'epoch': 3.11}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 561/720 [5:21:45<1:29:41, 33.84s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 562/720 [5:22:19<1:29:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0113, 'learning_rate': 4.47887323943662e-05, 'epoch': 3.12}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 562/720 [5:22:19<1:29:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 563/720 [5:22:53<1:28:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0128, 'learning_rate': 4.450704225352113e-05, 'epoch': 3.12}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 563/720 [5:22:53<1:28:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 564/720 [5:23:27<1:27:58, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0166, 'learning_rate': 4.4225352112676064e-05, 'epoch': 3.13}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 564/720 [5:23:27<1:27:58, 33.84s/it]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 565/720 [5:24:00<1:27:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0103, 'learning_rate': 4.394366197183099e-05, 'epoch': 3.13}\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 565/720 [5:24:00<1:27:24, 33.84s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 566/720 [5:24:34<1:26:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0165, 'learning_rate': 4.366197183098591e-05, 'epoch': 3.14}\u001b[0m\n",
      "\u001b[34m79%|███████▊  | 566/720 [5:24:34<1:26:50, 33.84s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 567/720 [5:25:08<1:26:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0112, 'learning_rate': 4.3380281690140846e-05, 'epoch': 3.15}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 567/720 [5:25:08<1:26:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 568/720 [5:25:42<1:25:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0131, 'learning_rate': 4.3098591549295774e-05, 'epoch': 3.15}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 568/720 [5:25:42<1:25:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 569/720 [5:26:16<1:25:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'learning_rate': 4.281690140845071e-05, 'epoch': 3.16}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 569/720 [5:26:16<1:25:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 570/720 [5:26:50<1:24:35, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0138, 'learning_rate': 4.2535211267605635e-05, 'epoch': 3.16}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 570/720 [5:26:50<1:24:35, 33.83s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 571/720 [5:27:23<1:24:00, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0112, 'learning_rate': 4.225352112676056e-05, 'epoch': 3.17}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 571/720 [5:27:23<1:24:00, 33.83s/it]\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 572/720 [5:27:57<1:23:26, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0117, 'learning_rate': 4.19718309859155e-05, 'epoch': 3.17}\u001b[0m\n",
      "\u001b[34m79%|███████▉  | 572/720 [5:27:57<1:23:26, 33.83s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 573/720 [5:28:31<1:22:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0136, 'learning_rate': 4.1690140845070425e-05, 'epoch': 3.18}\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 573/720 [5:28:31<1:22:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 574/720 [5:29:05<1:22:20, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0117, 'learning_rate': 4.140845070422535e-05, 'epoch': 3.18}\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 574/720 [5:29:05<1:22:20, 33.84s/it]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 575/720 [5:29:39<1:21:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0146, 'learning_rate': 4.1126760563380286e-05, 'epoch': 3.19}\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 575/720 [5:29:39<1:21:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 576/720 [5:30:13<1:21:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0126, 'learning_rate': 4.0845070422535214e-05, 'epoch': 3.2}\u001b[0m\n",
      "\u001b[34m80%|████████  | 576/720 [5:30:13<1:21:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:44,783] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:44,791] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:44,791] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:44,795] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:47,289] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:47,290] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:49,852] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:52,414] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:54,976] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:19:57,568] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.018750134855508804, 'eval_runtime': 12.8822, 'eval_samples_per_second': 61.015, 'eval_steps_per_second': 30.507, 'epoch': 3.2}\u001b[0m\n",
      "\u001b[34m80%|████████  | 576/720 [5:30:26<1:21:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 577/720 [5:30:59<1:29:55, 37.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0132, 'learning_rate': 4.056338028169014e-05, 'epoch': 3.2}\u001b[0m\n",
      "\u001b[34m80%|████████  | 577/720 [5:30:59<1:29:55, 37.73s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 578/720 [5:31:33<1:26:32, 36.56s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0107, 'learning_rate': 4.0281690140845076e-05, 'epoch': 3.21}\u001b[0m\n",
      "\u001b[34m80%|████████  | 578/720 [5:31:33<1:26:32, 36.56s/it]\u001b[0m\n",
      "\u001b[34m80%|████████  | 579/720 [5:32:07<1:23:59, 35.74s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0146, 'learning_rate': 4e-05, 'epoch': 3.21}\u001b[0m\n",
      "\u001b[34m80%|████████  | 579/720 [5:32:07<1:23:59, 35.74s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 580/720 [5:32:41<1:22:03, 35.17s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0122, 'learning_rate': 3.971830985915493e-05, 'epoch': 3.22}\u001b[0m\n",
      "\u001b[34m81%|████████  | 580/720 [5:32:41<1:22:03, 35.17s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 581/720 [5:33:15<1:20:32, 34.77s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0178, 'learning_rate': 3.943661971830986e-05, 'epoch': 3.22}\u001b[0m\n",
      "\u001b[34m81%|████████  | 581/720 [5:33:15<1:20:32, 34.77s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m81%|████████  | 582/720 [5:33:49<1:19:19, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'learning_rate': 3.9154929577464786e-05, 'epoch': 3.23}\u001b[0m\n",
      "\u001b[34m81%|████████  | 582/720 [5:33:49<1:19:19, 34.49s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 583/720 [5:34:22<1:18:18, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.016, 'learning_rate': 3.887323943661972e-05, 'epoch': 3.23}\u001b[0m\n",
      "\u001b[34m81%|████████  | 583/720 [5:34:22<1:18:18, 34.29s/it]\u001b[0m\n",
      "\u001b[34m81%|████████  | 584/720 [5:34:56<1:17:25, 34.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0097, 'learning_rate': 3.859154929577465e-05, 'epoch': 3.24}\u001b[0m\n",
      "\u001b[34m81%|████████  | 584/720 [5:34:56<1:17:25, 34.16s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 585/720 [5:35:30<1:16:39, 34.07s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0146, 'learning_rate': 3.8309859154929575e-05, 'epoch': 3.25}\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 585/720 [5:35:30<1:16:39, 34.07s/it]\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 586/720 [5:36:04<1:15:56, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0102, 'learning_rate': 3.802816901408451e-05, 'epoch': 3.25}\u001b[0m\n",
      "\u001b[34m81%|████████▏ | 586/720 [5:36:04<1:15:56, 34.00s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 587/720 [5:36:38<1:15:15, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0124, 'learning_rate': 3.774647887323944e-05, 'epoch': 3.26}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 587/720 [5:36:38<1:15:15, 33.95s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 588/720 [5:37:12<1:14:37, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'learning_rate': 3.746478873239437e-05, 'epoch': 3.26}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 588/720 [5:37:12<1:14:37, 33.92s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 589/720 [5:37:46<1:14:00, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0136, 'learning_rate': 3.71830985915493e-05, 'epoch': 3.27}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 589/720 [5:37:46<1:14:00, 33.89s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 590/720 [5:38:19<1:13:23, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0109, 'learning_rate': 3.6901408450704226e-05, 'epoch': 3.27}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 590/720 [5:38:19<1:13:23, 33.87s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 591/720 [5:38:53<1:12:48, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0123, 'learning_rate': 3.661971830985916e-05, 'epoch': 3.28}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 591/720 [5:38:53<1:12:48, 33.86s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 592/720 [5:39:27<1:12:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0155, 'learning_rate': 3.633802816901409e-05, 'epoch': 3.28}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 592/720 [5:39:27<1:12:13, 33.85s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 593/720 [5:40:01<1:11:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0111, 'learning_rate': 3.6056338028169015e-05, 'epoch': 3.29}\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 593/720 [5:40:01<1:11:38, 33.85s/it]\u001b[0m\n",
      "\u001b[34m82%|████████▎ | 594/720 [5:40:35<1:11:04, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0102, 'learning_rate': 3.577464788732395e-05, 'epoch': 3.3}\u001b[0m\n",
      "\u001b[34m82%|████████▎ | 594/720 [5:40:35<1:11:04, 33.84s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 595/720 [5:41:09<1:10:29, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0122, 'learning_rate': 3.549295774647888e-05, 'epoch': 3.3}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 595/720 [5:41:09<1:10:29, 33.84s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 596/720 [5:41:42<1:09:55, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 3.5211267605633805e-05, 'epoch': 3.31}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 596/720 [5:41:42<1:09:55, 33.84s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 597/720 [5:42:16<1:09:21, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0121, 'learning_rate': 3.492957746478873e-05, 'epoch': 3.31}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 597/720 [5:42:16<1:09:21, 33.83s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 598/720 [5:42:50<1:08:47, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0136, 'learning_rate': 3.464788732394366e-05, 'epoch': 3.32}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 598/720 [5:42:50<1:08:47, 33.83s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 599/720 [5:43:24<1:08:13, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0104, 'learning_rate': 3.4366197183098594e-05, 'epoch': 3.32}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 599/720 [5:43:24<1:08:13, 33.83s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 600/720 [5:43:58<1:07:39, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0117, 'learning_rate': 3.408450704225352e-05, 'epoch': 3.33}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 600/720 [5:43:58<1:07:39, 33.83s/it]\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 601/720 [5:44:31<1:07:05, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0139, 'learning_rate': 3.380281690140845e-05, 'epoch': 3.33}\u001b[0m\n",
      "\u001b[34m83%|████████▎ | 601/720 [5:44:31<1:07:05, 33.83s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 602/720 [5:45:05<1:06:31, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0151, 'learning_rate': 3.352112676056338e-05, 'epoch': 3.34}\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 602/720 [5:45:05<1:06:31, 33.83s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 603/720 [5:45:39<1:05:58, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0122, 'learning_rate': 3.323943661971831e-05, 'epoch': 3.35}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 603/720 [5:45:39<1:05:58, 33.83s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 604/720 [5:46:13<1:05:24, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 3.295774647887324e-05, 'epoch': 3.35}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 604/720 [5:46:13<1:05:24, 33.83s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 605/720 [5:46:47<1:04:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 3.267605633802817e-05, 'epoch': 3.36}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 605/720 [5:46:47<1:04:51, 33.84s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 606/720 [5:47:21<1:04:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 3.23943661971831e-05, 'epoch': 3.36}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 606/720 [5:47:21<1:04:17, 33.84s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 607/720 [5:47:55<1:03:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 607/720 [5:47:55<1:03:43, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0123, 'learning_rate': 3.2112676056338034e-05, 'epoch': 3.37}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 608/720 [5:48:28<1:03:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0095, 'learning_rate': 3.183098591549296e-05, 'epoch': 3.37}\u001b[0m\n",
      "\u001b[34m84%|████████▍ | 608/720 [5:48:28<1:03:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 609/720 [5:49:02<1:02:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 3.154929577464789e-05, 'epoch': 3.38}\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 609/720 [5:49:02<1:02:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 610/720 [5:49:36<1:02:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 3.1267605633802824e-05, 'epoch': 3.38}\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 610/720 [5:49:36<1:02:02, 33.84s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 611/720 [5:50:10<1:01:28, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0136, 'learning_rate': 3.0985915492957744e-05, 'epoch': 3.39}\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 611/720 [5:50:10<1:01:28, 33.84s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 612/720 [5:50:44<1:00:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0098, 'learning_rate': 3.070422535211268e-05, 'epoch': 3.4}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 612/720 [5:50:44<1:00:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:15,861] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:15,869] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:15,869] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:15,873] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:18,367] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:18,368] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:20,930] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:23,492] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:26,054] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 22:40:28,646] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.01813352108001709, 'eval_runtime': 12.8829, 'eval_samples_per_second': 61.011, 'eval_steps_per_second': 30.506, 'epoch': 3.4}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 612/720 [5:50:57<1:00:54, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m85%|████████▌ | 613/720 [5:51:30<1:07:14, 37.71s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0105, 'learning_rate': 3.0422535211267606e-05, 'epoch': 3.4}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 613/720 [5:51:30<1:07:14, 37.71s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 614/720 [5:52:04<1:04:34, 36.55s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0113, 'learning_rate': 3.0140845070422537e-05, 'epoch': 3.41}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 614/720 [5:52:04<1:04:34, 36.55s/it]\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 615/720 [5:52:38<1:02:32, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0126, 'learning_rate': 2.9859154929577465e-05, 'epoch': 3.41}\u001b[0m\n",
      "\u001b[34m85%|████████▌ | 615/720 [5:52:38<1:02:32, 35.73s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 616/720 [5:53:12<1:00:57, 35.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.011, 'learning_rate': 2.9577464788732395e-05, 'epoch': 3.42}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 616/720 [5:53:12<1:00:57, 35.16s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 617/720 [5:53:46<59:40, 34.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0139, 'learning_rate': 2.9295774647887326e-05, 'epoch': 3.42}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 617/720 [5:53:46<59:40, 34.76s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 618/720 [5:54:20<58:37, 34.49s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0103, 'learning_rate': 2.9014084507042254e-05, 'epoch': 3.43}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 618/720 [5:54:20<58:37, 34.49s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 619/720 [5:54:53<57:43, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0137, 'learning_rate': 2.8732394366197185e-05, 'epoch': 3.43}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 619/720 [5:54:53<57:43, 34.29s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 620/720 [5:55:27<56:55, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0145, 'learning_rate': 2.8450704225352116e-05, 'epoch': 3.44}\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 620/720 [5:55:27<56:55, 34.15s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 621/720 [5:56:01<56:12, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 2.8169014084507046e-05, 'epoch': 3.45}\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 621/720 [5:56:01<56:12, 34.06s/it]\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 622/720 [5:56:35<55:31, 34.00s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0101, 'learning_rate': 2.7887323943661974e-05, 'epoch': 3.45}\u001b[0m\n",
      "\u001b[34m86%|████████▋ | 622/720 [5:56:35<55:31, 34.00s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 623/720 [5:57:09<54:52, 33.95s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 2.7605633802816905e-05, 'epoch': 3.46}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 623/720 [5:57:09<54:52, 33.95s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 624/720 [5:57:43<54:15, 33.92s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 2.7323943661971836e-05, 'epoch': 3.46}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 624/720 [5:57:43<54:15, 33.92s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 625/720 [5:58:16<53:39, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.016, 'learning_rate': 2.704225352112676e-05, 'epoch': 3.47}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 625/720 [5:58:16<53:39, 33.89s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 626/720 [5:58:50<53:04, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0103, 'learning_rate': 2.676056338028169e-05, 'epoch': 3.47}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 626/720 [5:58:50<53:04, 33.88s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 627/720 [5:59:24<52:29, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 2.6478873239436618e-05, 'epoch': 3.48}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 627/720 [5:59:24<52:29, 33.87s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 628/720 [5:59:58<51:54, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0128, 'learning_rate': 2.619718309859155e-05, 'epoch': 3.48}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 628/720 [5:59:58<51:54, 33.86s/it]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 629/720 [6:00:32<51:20, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0141, 'learning_rate': 2.591549295774648e-05, 'epoch': 3.49}\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 629/720 [6:00:32<51:20, 33.85s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 630/720 [6:01:06<50:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0113, 'learning_rate': 2.5633802816901408e-05, 'epoch': 3.5}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 630/720 [6:01:06<50:46, 33.85s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 631/720 [6:01:40<50:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'learning_rate': 2.535211267605634e-05, 'epoch': 3.5}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 631/720 [6:01:40<50:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 632/720 [6:02:13<49:37, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0109, 'learning_rate': 2.507042253521127e-05, 'epoch': 3.51}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 632/720 [6:02:13<49:37, 33.84s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 633/720 [6:02:47<49:03, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0149, 'learning_rate': 2.47887323943662e-05, 'epoch': 3.51}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 633/720 [6:02:47<49:03, 33.84s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 634/720 [6:03:21<48:29, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 2.4507042253521128e-05, 'epoch': 3.52}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 634/720 [6:03:21<48:29, 33.84s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 635/720 [6:03:55<47:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0097, 'learning_rate': 2.422535211267606e-05, 'epoch': 3.52}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 635/720 [6:03:55<47:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 636/720 [6:04:29<47:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0142, 'learning_rate': 2.3943661971830986e-05, 'epoch': 3.53}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 636/720 [6:04:29<47:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 637/720 [6:05:03<46:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0131, 'learning_rate': 2.3661971830985917e-05, 'epoch': 3.53}\u001b[0m\n",
      "\u001b[34m88%|████████▊ | 637/720 [6:05:03<46:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 638/720 [6:05:36<46:14, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 2.3380281690140845e-05, 'epoch': 3.54}\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 638/720 [6:05:36<46:14, 33.83s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 639/720 [6:06:10<45:40, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0114, 'learning_rate': 2.3098591549295775e-05, 'epoch': 3.55}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 639/720 [6:06:10<45:40, 33.84s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 640/720 [6:06:44<45:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 2.2816901408450706e-05, 'epoch': 3.55}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 640/720 [6:06:44<45:06, 33.84s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 641/720 [6:07:18<44:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0123, 'learning_rate': 2.2535211267605634e-05, 'epoch': 3.56}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 641/720 [6:07:18<44:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 642/720 [6:07:52<43:58, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0104, 'learning_rate': 2.2253521126760565e-05, 'epoch': 3.56}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 642/720 [6:07:52<43:58, 33.83s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 643/720 [6:08:26<43:24, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0108, 'learning_rate': 2.1971830985915496e-05, 'epoch': 3.57}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 643/720 [6:08:26<43:24, 33.83s/it]\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 644/720 [6:08:59<42:51, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0165, 'learning_rate': 2.1690140845070423e-05, 'epoch': 3.57}\u001b[0m\n",
      "\u001b[34m89%|████████▉ | 644/720 [6:08:59<42:51, 33.83s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 645/720 [6:09:33<42:17, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.01, 'learning_rate': 2.1408450704225354e-05, 'epoch': 3.58}\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 645/720 [6:09:33<42:17, 33.83s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 646/720 [6:10:07<41:43, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.011, 'learning_rate': 2.112676056338028e-05, 'epoch': 3.58}\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 646/720 [6:10:07<41:43, 33.83s/it]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 647/720 [6:10:41<41:09, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0141, 'learning_rate': 2.0845070422535212e-05, 'epoch': 3.59}\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 647/720 [6:10:41<41:09, 33.83s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 648/720 [6:11:15<40:35, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0106, 'learning_rate': 2.0563380281690143e-05, 'epoch': 3.6}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 648/720 [6:11:15<40:35, 33.83s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:46,852] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:46,859] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:46,859] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:46,863] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:49,358] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:49,359] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:51,921] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:54,483] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.82s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2023-10-28 23:00:57,045] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:00:59,638] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.018453557044267654, 'eval_runtime': 12.8836, 'eval_samples_per_second': 61.008, 'eval_steps_per_second': 30.504, 'epoch': 3.6}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 648/720 [6:11:28<40:35, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 649/720 [6:12:01<44:36, 37.70s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 649/720 [6:12:01<44:36, 37.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 2.028169014084507e-05, 'epoch': 3.6}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 650/720 [6:12:35<42:37, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 2e-05, 'epoch': 3.61}\u001b[0m\n",
      "\u001b[34m90%|█████████ | 650/720 [6:12:35<42:37, 36.54s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 651/720 [6:13:09<41:05, 35.73s/it]\u001b[0m\n",
      "\u001b[34m90%|█████████ | 651/720 [6:13:09<41:05, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0124, 'learning_rate': 1.971830985915493e-05, 'epoch': 3.61}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 652/720 [6:13:43<39:50, 35.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 1.943661971830986e-05, 'epoch': 3.62}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 652/720 [6:13:43<39:50, 35.16s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 653/720 [6:14:17<38:48, 34.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.015, 'learning_rate': 1.9154929577464788e-05, 'epoch': 3.62}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 653/720 [6:14:17<38:48, 34.76s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 654/720 [6:14:51<37:55, 34.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0137, 'learning_rate': 1.887323943661972e-05, 'epoch': 3.63}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 654/720 [6:14:51<37:55, 34.48s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 655/720 [6:15:24<37:08, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 1.859154929577465e-05, 'epoch': 3.63}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 655/720 [6:15:24<37:08, 34.29s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 656/720 [6:15:58<36:25, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0116, 'learning_rate': 1.830985915492958e-05, 'epoch': 3.64}\u001b[0m\n",
      "\u001b[34m91%|█████████ | 656/720 [6:15:58<36:25, 34.15s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 657/720 [6:16:32<35:45, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0122, 'learning_rate': 1.8028169014084508e-05, 'epoch': 3.64}\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 657/720 [6:16:32<35:45, 34.06s/it]\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 658/720 [6:17:06<35:07, 33.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.011, 'learning_rate': 1.774647887323944e-05, 'epoch': 3.65}\u001b[0m\n",
      "\u001b[34m91%|█████████▏| 658/720 [6:17:06<35:07, 33.99s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 659/720 [6:17:40<34:30, 33.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.01, 'learning_rate': 1.7464788732394366e-05, 'epoch': 3.66}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 659/720 [6:17:40<34:30, 33.94s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 660/720 [6:18:14<33:54, 33.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0107, 'learning_rate': 1.7183098591549297e-05, 'epoch': 3.66}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 660/720 [6:18:14<33:54, 33.91s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 661/720 [6:18:47<33:19, 33.89s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 661/720 [6:18:47<33:19, 33.89s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0138, 'learning_rate': 1.6901408450704224e-05, 'epoch': 3.67}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 662/720 [6:19:21<32:44, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 1.6619718309859155e-05, 'epoch': 3.67}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 662/720 [6:19:21<32:44, 33.87s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 663/720 [6:19:55<32:10, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0105, 'learning_rate': 1.6338028169014086e-05, 'epoch': 3.68}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 663/720 [6:19:55<32:10, 33.86s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 664/720 [6:20:29<31:35, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0116, 'learning_rate': 1.6056338028169017e-05, 'epoch': 3.68}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 664/720 [6:20:29<31:35, 33.86s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 665/720 [6:21:03<31:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 1.5774647887323945e-05, 'epoch': 3.69}\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 665/720 [6:21:03<31:01, 33.85s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▎| 666/720 [6:21:37<30:27, 33.85s/it]\u001b[0m\n",
      "\u001b[34m92%|█████████▎| 666/720 [6:21:37<30:27, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0094, 'learning_rate': 1.5492957746478872e-05, 'epoch': 3.69}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 667/720 [6:22:10<29:53, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0116, 'learning_rate': 1.5211267605633803e-05, 'epoch': 3.7}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 667/720 [6:22:10<29:53, 33.85s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 668/720 [6:22:44<29:19, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0113, 'learning_rate': 1.4929577464788732e-05, 'epoch': 3.71}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 668/720 [6:22:44<29:19, 33.84s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 669/720 [6:23:18<28:45, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0116, 'learning_rate': 1.4647887323943663e-05, 'epoch': 3.71}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 669/720 [6:23:18<28:45, 33.84s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 670/720 [6:23:52<28:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0126, 'learning_rate': 1.4366197183098592e-05, 'epoch': 3.72}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 670/720 [6:23:52<28:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 671/720 [6:24:26<27:38, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0109, 'learning_rate': 1.4084507042253523e-05, 'epoch': 3.72}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 671/720 [6:24:26<27:38, 33.84s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 672/720 [6:25:00<27:04, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0151, 'learning_rate': 1.3802816901408452e-05, 'epoch': 3.73}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 672/720 [6:25:00<27:04, 33.84s/it]\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 673/720 [6:25:33<26:30, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0132, 'learning_rate': 1.352112676056338e-05, 'epoch': 3.73}\u001b[0m\n",
      "\u001b[34m93%|█████████▎| 673/720 [6:25:33<26:30, 33.84s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 674/720 [6:26:07<25:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0099, 'learning_rate': 1.3239436619718309e-05, 'epoch': 3.74}\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 674/720 [6:26:07<25:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 675/720 [6:26:41<25:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0079, 'learning_rate': 1.295774647887324e-05, 'epoch': 3.74}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 675/720 [6:26:41<25:22, 33.84s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 676/720 [6:27:15<24:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0128, 'learning_rate': 1.267605633802817e-05, 'epoch': 3.75}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 676/720 [6:27:15<24:48, 33.84s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 677/720 [6:27:49<24:15, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0115, 'learning_rate': 1.23943661971831e-05, 'epoch': 3.76}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 677/720 [6:27:49<24:15, 33.84s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 678/720 [6:28:23<23:41, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0109, 'learning_rate': 1.211267605633803e-05, 'epoch': 3.76}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 678/720 [6:28:23<23:41, 33.84s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 679/720 [6:28:56<23:07, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0139, 'learning_rate': 1.1830985915492958e-05, 'epoch': 3.77}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 679/720 [6:28:56<23:07, 33.83s/it]\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 680/720 [6:29:30<22:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 1.1549295774647888e-05, 'epoch': 3.77}\u001b[0m\n",
      "\u001b[34m94%|█████████▍| 680/720 [6:29:30<22:33, 33.84s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 681/720 [6:30:04<21:59, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0107, 'learning_rate': 1.1267605633802817e-05, 'epoch': 3.78}\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 681/720 [6:30:04<21:59, 33.84s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 682/720 [6:30:38<21:25, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0147, 'learning_rate': 1.0985915492957748e-05, 'epoch': 3.78}\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 682/720 [6:30:38<21:25, 33.84s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 683/720 [6:31:12<20:52, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0129, 'learning_rate': 1.0704225352112677e-05, 'epoch': 3.79}\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 683/720 [6:31:12<20:52, 33.84s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 684/720 [6:31:46<20:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 1.0422535211267606e-05, 'epoch': 3.79}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 684/720 [6:31:46<20:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:17,845] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:17,853] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:17,854] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:17,857] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:20,352] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:20,353] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:22,915] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:25,477] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2023-10-28 23:21:28,039] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:21:30,632] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.01807444542646408, 'eval_runtime': 12.8845, 'eval_samples_per_second': 61.003, 'eval_steps_per_second': 30.502, 'epoch': 3.79}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 684/720 [6:31:59<20:18, 33.84s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 685/720 [6:32:32<21:59, 37.70s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 685/720 [6:32:32<21:59, 37.70s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0135, 'learning_rate': 1.0140845070422535e-05, 'epoch': 3.8}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 686/720 [6:33:06<20:42, 36.54s/it]\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 686/720 [6:33:06<20:42, 36.54s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0126, 'learning_rate': 9.859154929577465e-06, 'epoch': 3.81}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 687/720 [6:33:40<19:39, 35.73s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0133, 'learning_rate': 9.577464788732394e-06, 'epoch': 3.81}\u001b[0m\n",
      "\u001b[34m95%|█████████▌| 687/720 [6:33:40<19:39, 35.73s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 688/720 [6:34:14<18:45, 35.16s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0143, 'learning_rate': 9.295774647887325e-06, 'epoch': 3.82}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 688/720 [6:34:14<18:45, 35.16s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 689/720 [6:34:48<17:57, 34.76s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0141, 'learning_rate': 9.014084507042254e-06, 'epoch': 3.82}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 689/720 [6:34:48<17:57, 34.76s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 690/720 [6:35:22<17:14, 34.48s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0127, 'learning_rate': 8.732394366197183e-06, 'epoch': 3.83}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 690/720 [6:35:22<17:14, 34.48s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 691/720 [6:35:55<16:34, 34.29s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0113, 'learning_rate': 8.450704225352112e-06, 'epoch': 3.83}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 691/720 [6:35:55<16:34, 34.29s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 692/720 [6:36:29<15:56, 34.15s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 8.169014084507043e-06, 'epoch': 3.84}\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 692/720 [6:36:29<15:56, 34.15s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 693/720 [6:37:03<15:19, 34.06s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0154, 'learning_rate': 7.887323943661972e-06, 'epoch': 3.84}\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 693/720 [6:37:03<15:19, 34.06s/it]\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 694/720 [6:37:37<14:43, 33.99s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0133, 'learning_rate': 7.6056338028169015e-06, 'epoch': 3.85}\u001b[0m\n",
      "\u001b[34m96%|█████████▋| 694/720 [6:37:37<14:43, 33.99s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 695/720 [6:38:11<14:08, 33.94s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.011, 'learning_rate': 7.3239436619718316e-06, 'epoch': 3.86}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 695/720 [6:38:11<14:08, 33.94s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 696/720 [6:38:45<13:33, 33.91s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 696/720 [6:38:45<13:33, 33.91s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0145, 'learning_rate': 7.042253521126762e-06, 'epoch': 3.86}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 697/720 [6:39:18<12:59, 33.88s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0093, 'learning_rate': 6.76056338028169e-06, 'epoch': 3.87}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 697/720 [6:39:18<12:59, 33.88s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 698/720 [6:39:52<12:25, 33.87s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0124, 'learning_rate': 6.47887323943662e-06, 'epoch': 3.87}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 698/720 [6:39:52<12:25, 33.87s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 699/720 [6:40:26<11:51, 33.86s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0094, 'learning_rate': 6.19718309859155e-06, 'epoch': 3.88}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 699/720 [6:40:26<11:51, 33.86s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 700/720 [6:41:00<11:17, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0124, 'learning_rate': 5.915492957746479e-06, 'epoch': 3.88}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 700/720 [6:41:00<11:17, 33.85s/it]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 701/720 [6:41:34<10:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0105, 'learning_rate': 5.6338028169014084e-06, 'epoch': 3.89}\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 701/720 [6:41:34<10:43, 33.85s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 702/720 [6:42:08<10:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.009, 'learning_rate': 5.3521126760563385e-06, 'epoch': 3.89}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 702/720 [6:42:08<10:09, 33.84s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 703/720 [6:42:41<09:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0134, 'learning_rate': 5.070422535211268e-06, 'epoch': 3.9}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 703/720 [6:42:41<09:35, 33.84s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 704/720 [6:43:15<09:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0113, 'learning_rate': 4.788732394366197e-06, 'epoch': 3.91}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 704/720 [6:43:15<09:01, 33.84s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 705/720 [6:43:49<08:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0151, 'learning_rate': 4.507042253521127e-06, 'epoch': 3.91}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 705/720 [6:43:49<08:27, 33.84s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 706/720 [6:44:23<07:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0122, 'learning_rate': 4.225352112676056e-06, 'epoch': 3.92}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 706/720 [6:44:23<07:53, 33.84s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 707/720 [6:44:57<07:19, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 3.943661971830986e-06, 'epoch': 3.92}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 707/720 [6:44:57<07:19, 33.83s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 708/720 [6:45:31<06:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0119, 'learning_rate': 3.6619718309859158e-06, 'epoch': 3.93}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 708/720 [6:45:31<06:46, 33.84s/it]\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 709/720 [6:46:04<06:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0118, 'learning_rate': 3.380281690140845e-06, 'epoch': 3.93}\u001b[0m\n",
      "\u001b[34m98%|█████████▊| 709/720 [6:46:04<06:12, 33.84s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 710/720 [6:46:38<05:38, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0111, 'learning_rate': 3.098591549295775e-06, 'epoch': 3.94}\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 710/720 [6:46:38<05:38, 33.84s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 711/720 [6:47:12<05:04, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.013, 'learning_rate': 2.8169014084507042e-06, 'epoch': 3.94}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 711/720 [6:47:12<05:04, 33.84s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 712/720 [6:47:46<04:30, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0095, 'learning_rate': 2.535211267605634e-06, 'epoch': 3.95}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 712/720 [6:47:46<04:30, 33.83s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 713/720 [6:48:20<03:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0106, 'learning_rate': 2.2535211267605635e-06, 'epoch': 3.96}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 713/720 [6:48:20<03:56, 33.84s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 714/720 [6:48:54<03:22, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0133, 'learning_rate': 1.971830985915493e-06, 'epoch': 3.96}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 714/720 [6:48:54<03:22, 33.83s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 715/720 [6:49:27<02:49, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0128, 'learning_rate': 1.6901408450704225e-06, 'epoch': 3.97}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 715/720 [6:49:27<02:49, 33.83s/it]\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 716/720 [6:50:01<02:15, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.012, 'learning_rate': 1.4084507042253521e-06, 'epoch': 3.97}\u001b[0m\n",
      "\u001b[34m99%|█████████▉| 716/720 [6:50:01<02:15, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 717/720 [6:50:35<01:41, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0121, 'learning_rate': 1.1267605633802817e-06, 'epoch': 3.98}\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 717/720 [6:50:35<01:41, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 718/720 [6:51:09<01:07, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0132, 'learning_rate': 8.450704225352112e-07, 'epoch': 3.98}\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 718/720 [6:51:09<01:07, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 719/720 [6:51:43<00:33, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0111, 'learning_rate': 5.633802816901409e-07, 'epoch': 3.99}\u001b[0m\n",
      "\u001b[34m100%|█████████▉| 719/720 [6:51:43<00:33, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 720/720 [6:52:17<00:00, 33.83s/it]\u001b[0m\n",
      "\u001b[34m{'loss': 0.0105, 'learning_rate': 2.8169014084507043e-07, 'epoch': 3.99}\u001b[0m\n",
      "\u001b[34m100%|██████████| 720/720 [6:52:17<00:00, 33.83s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:48,754] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:48,762] [INFO] [axolotl.utils.dataloader.generate_batches:181] [PID:197] [RANK:0] generating packed batches#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:48,762] [INFO] [axolotl.utils.dataloader.generate_batches:187] [PID:197] [RANK:0] 56bcedc7505086c9ea4dc0cf83dd8be99917f944e643943c0bfe2b71a7416760#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:48,767] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:51,263] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:51,263] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m0%|          | 0/5 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:53,825] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m40%|████      | 2/5 [00:02<00:03,  1.28s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:41:56,388] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m60%|██████    | 3/5 [00:05<00:03,  1.81s/it]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[2023-10-28 23:41:58,950] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m80%|████████  | 4/5 [00:07<00:02,  2.09s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:42:01,543] [INFO] [axolotl.utils.dataloader._len_est:264] [PID:197] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 57782#033[39m\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'eval_loss': 0.017803680151700974, 'eval_runtime': 12.8854, 'eval_samples_per_second': 60.999, 'eval_steps_per_second': 30.5, 'epoch': 3.99}\u001b[0m\n",
      "\u001b[34m100%|██████████| 720/720 [6:52:29<00:00, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 5/5 [00:10<00:00,  2.27s/it]\u001b[0m\n",
      "\u001b[34m{'train_runtime': 24786.4228, 'train_samples_per_second': 12.554, 'train_steps_per_second': 0.029, 'train_loss': 0.03561719365987099, 'epoch': 3.99}\u001b[0m\n",
      "\u001b[34m100%|██████████| 720/720 [6:53:06<00:00, 33.83s/it]\u001b[0m\n",
      "\u001b[34m100%|██████████| 720/720 [6:53:06<00:00, 34.43s/it]\u001b[0m\n",
      "\u001b[34m[2023-10-28 23:42:38,071] [INFO] [axolotl.train.train:120] [PID:197] [RANK:0] Training Completed!!! Saving pre-trained model to /opt/ml/model#033[39m\u001b[0m\n",
      "\u001b[34m2023-10-28 23:42:42,302 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-10-28 23:42:42,302 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-10-28 23:42:42,302 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-10-28 23:43:29 Uploading - Uploading generated training model\n",
      "2023-10-28 23:43:29 Completed - Instances not retained as a result of warmpool resource limits being exceeded\n",
      "Training seconds: 25654\n",
      "Billable seconds: 25654\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"model\": s3_model_location, \"train\": s3_data})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Tensorboard report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-west-2-376678947624/llama2-7b-spider/tensorboard/2023-10-28-16-34-30'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"s3://{bucket}/{s3_prefix}/tensorboard/{str_time}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model performance before and after fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e87bb00cdca473f85f2561ebdbc13fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    local_model_path,\n",
    "    load_in_8bit=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(local_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
      "\n",
      "You must output the SQL query that answers the question.\n",
      "### Input:\n",
      "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\n",
      "\n",
      "### Response:\n",
      "SELECT * FROM table_name_12 WHERE frequency_mhz > 91.5 AND city_of_license = 'hyannis, nebraska'\n",
      "\n",
      "### Input:\n",
      "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "\n",
    "You must output the SQL query that answers the question.\n",
    "### Input:\n",
    "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
    "\n",
    "### Context:\n",
    "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "# {'question': 'Name the comptroller for office of prohibition', 'context': 'CREATE TABLE table_22607062_1 (comptroller VARCHAR, ticket___office VARCHAR)', 'answer': 'SELECT comptroller FROM table_22607062_1 WHERE ticket___office = \"Prohibition\"'}\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_path = estimator.model_data\n",
    "# lora_path = \"s3://sagemaker-us-west-2-376678947624/pytorch-training-2023-10-28-16-34-30-833/output/model.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "download: s3://sagemaker-us-west-2-376678947624/pytorch-training-2023-10-28-16-34-30-833/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp {lora_path} ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n",
      "tar: Ignoring unknown extended header keyword `LIBARCHIVE.creationtime'\n"
     ]
    }
   ],
   "source": [
    "!tar -xzf model.tar.gz -C lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "model = PeftModel.from_pretrained(model, \"lora\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
      "\n",
      "You must output the SQL query that answers the question.\n",
      "### Input:\n",
      "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
      "\n",
      "### Context:\n",
      "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\n",
      "\n",
      "### Response:\n",
      " SELECT class FROM table_name_12 WHERE frequency_mhz > 91.5 AND city_of_license = \"hyannis, nebraska\"\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = \"\"\"You are a powerful text-to-SQL model. Your job is to answer questions about a database. You are given a question and context regarding one or more tables.\n",
    "\n",
    "You must output the SQL query that answers the question.\n",
    "### Input:\n",
    "Which Class has a Frequency MHz larger than 91.5, and a City of license of hyannis, nebraska?\n",
    "\n",
    "### Context:\n",
    "CREATE TABLE table_name_12 (class VARCHAR, frequency_mhz VARCHAR, city_of_license VARCHAR)\n",
    "\n",
    "### Response:\n",
    "\"\"\"\n",
    "\n",
    "model_input = tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print(tokenizer.decode(model.generate(**model_input, max_new_tokens=100)[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
